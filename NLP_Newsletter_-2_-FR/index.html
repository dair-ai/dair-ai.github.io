<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶ &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_2.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶">
<meta property="og:description" content="">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter_-2_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_2.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter_-2_-FR/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog ‚úçÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About ‚ÑπÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter üóûÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects üí°</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub üìÅ</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ‚ú®</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium üì∞</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview üìò</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) üî•</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/lbourdois.png" class="bio-photo" alt="Lo√Øck BOURDOIS bio photo">


  <h3 itemprop="name">Lo√Øck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter_-2_-FR/" rel="bookmark" title="NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶">NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*mgWc3FhHPRfCxdPir6wSeg.png" alt="" /></p>

<h1 id="avant-propos">Avant-propos</h1>
<p>Bienvenue √† cette nouvelle newsletter consacr√©e au NLP ! Ce deuxi√®me num√©ro aborde des sujets qui vont de l‚Äôinterpr√©tabilit√© des mod√®les au repliement des prot√©ines en passant par l‚Äôapprentissage par transfert actif.</p>

<h1 id="publications-">Publications üìô</h1>

<p><strong><em>Sur l‚Äôincertitude de la confiance dans un mod√®le</em></strong></p>

<p><br />
Un article r√©cent de Google AI, publi√© au NeurIPS, examine si les probabilit√©s sorties par un mod√®le refl√®tent sa capacit√© √† pr√©voir les donn√©es d√©cal√©es et hors distribution. Ils ont constat√© que les ensembles profonds ont de meilleures performances (c‚Äôest-√†-dire une meilleure incertitude du mod√®le) sur le d√©calage de l‚Äôensemble de donn√©es, tandis que d‚Äôautres mod√®les ne sont pas devenus de plus en plus incertains sur le d√©calage de l‚Äôensemble de donn√©es, mais se sont plut√¥t tromp√©s avec confiance. (Lire l‚Äôarticle <a href="https://arxiv.org/abs/1906.02530">ici</a> et le r√©sum√© <a href="https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html">ici</a>).</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*NrsUnHS1thKq3ChK.png" alt="" /></p>

<p><em>image corruption‚Ää‚Äî</em>‚Ää<a href="https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html"><em>source</em></a></p>

<p><br />
<strong><em>G√©n√©ralisation syst√©matique</em></strong></p>

<p><br />
Un <a href="https://www.semanticscholar.org/paper/Systematic-Generalization%3A-What-Is-Required-and-Can-Bahdanau-Murty/6c7494a47cc5421a7b636c244e13586dc2dab007">travail</a> int√©ressant publi√© dans ICLR pr√©sente une comparaison entre les mod√®les modulaires et les mod√®les g√©n√©riques concernant leur efficacit√© pour la g√©n√©ralisation syst√©matique dans la compr√©hension des langues. Sur la base d‚Äôune √©valuation effectu√©e des questions/r√©ponses en lien avec une <a href="https://arxiv.org/abs/1909.01860">t√¢che visuelle</a>, les auteurs concluent qu‚Äôil peut √™tre n√©cessaire d‚Äôutiliser des r√©gularisateurs et des ant√©c√©dents explicites pour parvenir √† une g√©n√©ralisation syst√©matique.</p>

<p><br />
<strong><em>Le Reformer</em></strong></p>

<p><br />
Un Transformer est limit√© au niveau de la fen√™tre de contexte qu‚Äôil peut couvrir en raison des calculs co√ªteux effectu√©s dans la couche d‚Äôattention. Ainsi, il est possible d‚Äôappliquer le Transformer qu‚Äô√† des tailles de texte limit√©es ou de g√©n√©rer que de courtes phrases / morceaux de musique. GoogleAI a r√©cemment publi√© une variante efficace du mod√®le Transformer, appel√©e <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">Reformer</a>. L‚Äôobjectif principal de cette m√©thode est de pouvoir traiter des s√©quences de contexte beaucoup plus grandes tout en r√©duisant les besoins de calcul et en am√©liorant l‚Äôefficacit√© de la m√©moire. Reformer utilise le ‚Äúlocality-sensitive-hashing‚Äù (<a href="https://fr.wikipedia.org/wiki/Locality_sensitive_hashing">LSH</a>) pour regrouper des vecteurs similaires et cr√©er des segments √† partir de ceux-ci. Cela permet ainsi un traitement en parall√®le. L‚Äôattention est ensuite port√©e sur ces segments plus petits et sur les parties voisines correspondantes, r√©duisant la charge de calcul. L‚Äôefficacit√© de la m√©moire est obtenue gr√¢ce √† des couches r√©versibles qui permettent de recalculer √† la demande les informations d‚Äôentr√©e de chaque couche tout en s‚Äôentra√Ænant par r√©tropropagation. C‚Äôest une technique simple qui √©vite au mod√®le de devoir stocker en m√©moire les activations. Une description de ce mod√®le est disponible en langue fran√ßaise sur ce <a href="https://lbourdois.github.io/blog/nlp/Reformer/">site</a>. Pour voir comment le Reformer peut √™tre appliqu√© √† une t√¢che de g√©n√©ration d‚Äôimages, je vous invite √† consulter ce <a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb">Google Colab</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*Q6FHJ5bqZRCrBAp9.png" alt="" /></p>

<p><em><a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">source</a></em></p>

<p><br />
 <strong><em>Adaptation non supervis√©e de domaines pour la classification de textes</em></strong></p>

<p><br />
Ce <a href="https://arxiv.org/abs/2001.04362">travail</a> propose une combinaison de mesures de distance qui incorpor√©es dans une fonction de perte lors de l‚Äôentra√Ænement d‚Äôun mod√®le, permet d‚Äôam√©liorer l‚Äôadaptation du domaine non supervis√©. Le mod√®le est √©tendu √† un mod√®le ¬´ DistanceNet Bandit ¬ª. Le probl√®me cl√© abord√© par cette m√©thode est de comprendre comment traiter la dissimilitude entre les donn√©es de diff√©rents domaines.</p>

<p><br />
<strong><em>Am√©lioration des repr√©sentations contextualis√©es</em></strong></p>

<p><br />
Ce <a href="https://openreview.net/forum?id=r1xMH1BtvB">document</a> propose une t√¢che de pr√©-entra√Ænement, appel√©e token detection, qui se r√©v√®le plus efficace pour entra√Æner un mod√®le linguistique que les m√©thodes de bas√©es sur un pr√©-enta√Ænement avec des masques telles que BERT par exemple. Le mod√®le est baptis√© ELECTRA et ses repr√©sentations contextualis√©es surpassent celles de BERT et XLNET √† donn√©es identiques et √† taille de mod√®le identique. La m√©thode fonctionne particuli√®rement bien sur des machines √† faible capacit√© de calcul. Il s‚Äôagit d‚Äôun effort pour construire des mod√®les de langage plus petits et moins chers.</p>

<p><br />
<strong><em>Interpr√©tabilit√© des mod√®les</em></strong></p>

<p><br />
Distill a publi√© un document intitul√© ‚Äú<a href="https://distill.pub/2020/attribution-baselines/">Visualizing the Impact of Feature Attribution Baselines</a>‚Äù qui traite des <a href="https://medium.com/@kartikeyabhardwaj98/integrated-gradients-for-deep-neural-networks-c114e3968eae">gradients int√©gr√©s</a> utilis√©s pour interpr√©ter les r√©seaux neuronaux dans divers probl√®mes. Dans le contexte de l‚Äôinterpr√©tabilit√© du mod√®le, le d√©fi consiste √† ce que la m√©thode puisse garantir que le mod√®le ne consid√®re pas les caract√©ristiques manquantes comme √©tant importantes mais aussi que le mod√®le √©vite de donner aux entr√©es de la baseline une importance nulle (ce qui peut facilement arriver). L‚Äôauteur propose d‚Äô√©valuer quantitativement les diff√©rents effets de certains choix pr√©c√©demment utilis√©s et propose des choix de baseline qui pr√©servent mieux la notion de manque.</p>

<h1 id="cr√©ativit√©-et-soci√©t√©-">Cr√©ativit√© et soci√©t√© üé®</h1>

<p><strong><em>L‚Äôinad√©quation des sentiments</em></strong></p>

<p><br />
Cette <a href="https://ieeexplore.ieee.org/abstract/document/8952437">√©tude</a> longitudinale r√©v√®le que les √©motions extraites via l‚Äôutilisation d‚Äôalgorithmes bas√©s sur le texte ne sont souvent pas les m√™mes que les √©motions autod√©clar√©es.</p>

<p><br />
<strong><em>Compr√©hension de la dopamine et repliement des prot√©ines</em></strong></p>

<p><br />
DeepMind a r√©cemment publi√© deux articles int√©ressants dans Nature. Le <a href="https://deepmind.com/blog/article/Dopamine-and-temporal-difference-learning-A-fruitful-relationship-between-neuroscience-and-AI">premier</a> vise √† mieux comprendre le fonctionnement de la dopamine dans le cerveau gr√¢ce √† l‚Äôapprentissage par renforcement. Le <a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery">second</a> est li√© au repliement des prot√©ines et tente de mieux comprendre ce fonctionnement afin de pouvoir √©ventuellement d√©couvrir des traitements pour un large √©ventail de maladies.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*0mfEtacqGLSrmaUlNjJa0g.png" alt="" /></p>

<p>‚Ää<a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery"><em>source</em></a></p>

<p><br />
<strong><em>Entretiens sur le ML</em></strong></p>

<p><br />
Dans une <a href="https://www.youtube.com/watch?v=I-EIVlHvHRM&amp;feature=youtu.be">vid√©o</a> de Wired, Refik Anadol discute du potentiel des algorithmes d‚Äôapprentissage automatique pour cr√©er des ≈ìuvres d‚Äôart.</p>

<p><br />
L‚Äôun des secteurs o√π l‚ÄôIA pourrait avoir un impact majeur est celui de l‚Äô√©ducation. Dans un nouvel <a href="https://engineering.stanford.edu/magazine/article/emma-brunskill-amped-education-ai?sf115875862=1">√©pisode</a> de ‚ÄúThe Future of Everything‚Äù, Russ Altman et Emma Brunskill ont une discussion approfondie sur l‚Äôapprentissage assist√© par ordinateur.</p>

<h1 id="outils-et-jeux-de-donn√©es-Ô∏è">Outils et jeux de donn√©es ‚öôÔ∏è</h1>

<p><strong><em>Mod√®les PyTorch en production</em></strong></p>

<p><br />
Cortex est un outil permettant d‚Äôautomatiser l‚Äôinfrastructure et de d√©ployer les mod√®les PyTorch en tant qu‚ÄôAPI en production avec AWS. Pour en savoir plus sur la fa√ßon dont cela se fait, cliquez <a href="https://medium.com/pytorch/how-to-build-production-software-with-pytorch-9a8725382f2a">ici</a>.</p>

<p><br />
<strong><em>Visualisation des s√©quences de g√©n√©ration de texte</em></strong></p>

<p><br />
Facebook AI a lanc√© <a href="https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/">VizSeq</a>, un outil qui aide √† √©valuer visuellement les s√©quences de textes g√©n√©r√©es sous des m√©triques comme BLUE et METEOR. L‚Äôobjectif principal de cet outil est de fournir une analyse plus intuitive des ensembles de donn√©es textuelles via des visualisations. Pour lire l‚Äôarticle complet, cliquez <a href="https://www.aclweb.org/anthology/D19-3043.pdf">ici</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*Ff7BTxmEjUXHtYu9JkfClg.jpeg" alt="" /></p>

<p><a href="https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/"><em>Source</em></a></p>

<p><br />
<strong><em>Reconnaissance vocale en ligne</em></strong></p>

<p><br />
Facebook AI a mis en open source son outil <a href="https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/">wav2letter@anywhere</a>. Il s‚Äôagit d‚Äôun framework bas√© sur un Transformer acoustique afin d‚Äô√©tablir un √©tat de l‚Äôart en ligne de la reconnaissance vocale. Les principales am√©liorations portent sur la taille du mod√®le et la r√©duction de la latence entre l‚Äôaudio et la transcription, deux √©l√©ments importants pour acc√©l√©rer l‚Äôinf√©rence en temps r√©el.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*4_2Obuu8u8l2Vtp8UMHe7Q.gif" alt="" /></p>

<p>‚Ää<a href="https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/"><em>source</em></a></p>

<h1 id="ethique-en-ia-">Ethique en IA üö®</h1>

<p><strong><em>Implications de l‚ÄôIA</em></strong></p>

<p><br />
Dans un objectif de pr√©venir les abus et les actions contraires √† l‚Äô√©thique des syst√®mes d‚ÄôIA sur le public, l‚ÄôUnion europ√©enne envisage d‚Äôinterdire la technologie de reconnaissance faciale au public pendant cinq ans. (<a href="https://www.reuters.com/article/us-eu-ai/eu-mulls-five-year-ban-on-facial-recognition-tech-in-public-areas-idUSKBN1ZF2QL">Article complet</a>).</p>

<p><br />
<strong><em>Co√ªts environnementaux des mod√®les de NLP modernes</em></strong></p>

<p><br />
Cet <a href="https://arxiv.org/abs/1906.02243">article</a> aborde les consid√©rations √©nerg√©tiques et politiques des approches modernes en NLP. Les mod√®les actuels reposent sur des millions/milliards de param√®tres et par cons√©quent sur d‚Äôimportantes ressources de calcul. En r√©sulte une consommation d‚Äô√©nergie tr√®s importante. Les auteurs esp√®rent sensibiliser davantage les chercheurs aux co√ªts environnementaux li√©s √† l‚Äôentra√Ænement de ces mod√®les de NLP.
Zachary Lipton parle d‚Äô√©quit√©, d‚Äôinterpr√©tabilit√© et des dangers du solutionnisme dans cette <a href="https://c4ejournal.net/2020/01/16/zack-lipton-fairness-interpretability-and-the-dangers-of-solutionism-ethics-of-ai-in-context2020-c4ej-2/">conf√©rence</a> donn√©e √† l‚ÄôUniversit√© de Toronto. Les principaux sujets tournent autour des consid√©rations et des implications des approches d‚Äô√©quit√© en mati√®re de blanchiment d‚Äôargent.</p>

<h1 id="articles-et-blog-Ô∏è">Articles et Blog ‚úçÔ∏è</h1>
<p><strong><em>ML open source</em></strong></p>

<p><br />
Thomas Wolf, responsable scientifique de Hugging Face, donne des conseils √† ceux qui envisagent d‚Äôutiliser du code open-source ou de faire des recherches. Trouvez le fil de discussion Twitter <a href="https://twitter.com/Thom_Wolf/status/1216990543533821952?s=20">ici</a>.</p>

<p><br />
<strong><em>Introduction √† l‚Äôapprentissage auto-supervis√© en computer vision</em></strong></p>

<p><br />
Jeremy Howard a √©crit <a href="https://www.fast.ai/2020/01/13/self_supervised/">cet article de blog</a> qui pr√©sente bri√®vement le concept d‚Äôapprentissage auto-supervis√© dans le contexte de la vision par ordinateur.</p>

<p><br />
<strong><em>TinyBERT</em></strong></p>

<p><br />
Nous avons d√©j√† constat√© le succ√®s de nombreuses variantes des mod√®les BERT (par exemple, <a href="https://medium.com/huggingface/distilbert-8cf3380435b5">DistilBERT</a>) qui utilisent une certaine forme de <a href="https://nervanasystems.github.io/distiller/knowledge_distillation.html">distillation des connaissances</a> pour r√©duire consid√©rablement la taille du mod√®le et am√©liorer la vitesse. <a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT">TinyBERT</a> est une variante de BERT que ses auteurs ont appliqu√© √† une solution de <a href="https://towardsdatascience.com/tinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec">recherche par mots-cl√©s</a>. Ce projet a √©t√© inspir√© par cette <a href="https://www.blog.google/products/search/search-language-understanding-bert/">publication</a> de Google. L‚Äôint√©r√™t de l‚Äôarchitecture est qu‚Äôelle fonctionne sur un CPU standard et peut √™tre utilis√©e pour am√©liorer et comprendre les r√©sultats de recherche.</p>

<p><br />
<strong><em>Transfert Learning actif</em></strong></p>

<p><br />
Rober Monarch a √©crit un <a href="https://medium.com/pytorch/https-medium-com-robert-munro-active-learning-with-pytorch-2f3ee8ebec">article Medium</a> sur l‚Äôapprentissage actif par transfert, extrait de son prochain livre, <a href="https://www.manning.com/books/human-in-the-loop-machine-learning">Human-in-the-loop Machine Learning</a>. Il √©crit aussi d‚Äôautres articles sur les m√©thodes permettant de combiner l‚Äôintelligence humaine et l‚Äôintelligence machine pour r√©soudre des probl√®mes. Ses propos sont accompagn√©s de code Pytorch.</p>

<p><br />
<strong><em>Les sombres secrets de BERT</em></strong></p>

<p><br />
Anna Roger a √©crit cet <a href="https://text-machine-lab.github.io/blog/2020/bert-secrets/">article</a> de blog qui parle de ce qui se passe r√©ellement avec un BERT bien fine-tun√©. Les r√©sultats des analyses propos√©es sugg√®rent que BERT est s√©v√®rement surparam√©tr√© et que les avantages identifi√©s de l‚Äôauto-attention ne sont pas n√©cessairement aussi affirm√©s, en particulier en ce qui concerne les informations linguistiques qui sont encod√©es et utilis√©es pour l‚Äôinf√©rence.</p>

<h1 id="education-">Education üéì</h1>

<p><strong><em>Neural Nets for NLP</em></strong></p>

<p><br />
Graham Neubig, professeur de NLP √† la CMU, a publi√© des <a href="https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ">vid√©os</a> pour le cours ‚ÄúNeural Nets for NLP‚Äù dispens√© ce semestre.</p>

<p><br />
<strong><em>DeepMath</em></strong></p>

<p><br />
Vous voulez vous plonger dans les math√©matiques qui se cachent derri√®re les m√©thodes d‚Äôapprentissage approfondies ? Voici une s√©rie de <a href="https://www.youtube.com/playlist?list=PLWQvhvMdDChzsThHFe4lYAff3pu2m0v2H">conf√©rences vid√©o</a> accueillant un large √©ventail d‚Äôintervenants.</p>

<p><br />
<strong><em>Cours et tutoriels Python</em></strong></p>

<p><br />
Google a publi√© le ‚ÄúGoogle IT Automation with Python Professional Certificate‚Äù. Pour en savoir plus sur le moyen d‚Äôobtention de ce certificat cliquez <a href="https://blog.google/outreach-initiatives/grow-with-google/new-certificate-help-people-grow-careers">ici</a> et pours en savoir plus sur les cours, cliquez <a href="https://www.coursera.org/professional-certificates/google-it-automation">ici</a>.
Bien que le cours ne soit pas directement li√© √† la ML ou √† l‚ÄôIA, cela peut consister en un cours de base pour ma√Ætriser le langage Python. Des bourses d‚Äô√©tudes sont √©galement disponibles.</p>

<p><br />
Voici une autre <a href="https://www.youtube.com/watch?v=fMqL5vckiU0&amp;list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf">s√©rie de vid√©os</a> intitul√©e ‚ÄúDeep Learning (for Audio) with Python‚Äù, qui met l‚Äôaccent sur l‚Äôutilisation de Tensorflow et de Python pour construire des applications li√©es √† l‚Äôaudio/musique en tirant parti de l‚Äôapprentissage profond.</p>

<p><br />
Andrew Trask a publi√© une <a href="https://github.com/OpenMined/PySyft/tree/master/examples/tutorials">s√©rie de tutoriels</a>, pour parvenir, √©tape par √©tape, √† un apprentissage approfondi d√©centralis√© et respectueux de la vie priv√©e. Tous les notebooks contiennent des impl√©mentations de PyTorch et sont destin√©s aux d√©butants.</p>

<p><br />
<strong><em>Etats de l‚Äôart du deep learning</em></strong></p>

<p><br />
Cette <a href="https://www.youtube.com/watch?v=0VH1Lim8gL8">conf√©rence</a> de Lex Fridman traite de la recherche et le d√©veloppement r√©cents dans le domaine de l‚Äôapprentissage approfondi. Il parle des grandes avanc√©es sur des sujets tels que les perceptrons, les r√©seaux de neurones, la r√©tropropagation, CNN, l‚Äôapprentissage profond, ImageNet, les GAN, AlphaGo et les Transformers plus r√©cemment. Cette conf√©rence fait partie de la s√©rie ‚ÄúDeep Learning‚Äù du MIT.</p>

<p><br />
<strong><em>Groupes d‚Äô√©tudes</em></strong></p>

<p><br />
Deux groupes d‚Äô√©tude / lectures d‚Äôarticles conseill√©s par Elvis : le <a href="https://twitter.com/__MLT__">MLT</a> et le <a href="https://www.nightai.co/">nightai</a>.</p>

<p><br />
<strong><em>Le paysage de l‚Äôapprentissage par renforcement</em></strong></p>

<p><br />
D√©couvrez avec le Dr Katja Hofmann de Microsoft, les concepts et m√©thodes cl√©s de l‚Äôapprentissage par renforcement dans <a href="https://note.microsoft.com/MSR-Webinar-RL-Algorithm-to-Adoption-Registration-Live.html?wt.mc_id=twitter_MSR-WBNR_post_v3">sa s√©rie d‚Äôarticles</a>.</p>

<h1 id="mentions-sp√©ciales-Ô∏è">Mentions sp√©ciales ‚≠êÔ∏è</h1>

<p>Jettez un ≈ìil √† cette <a href="https://gist.github.com/y0ast/d91d09565462125a1eb75acc65da1469">impl√©mentation PyTorch</a> utilisant de ResNet-18 appliqu√©e √† CIFAR-10 permettant d‚Äôatteindre une pr√©cision de 94%.</p>

<p><br />
PyTorch 1.4 est sorti ! Consultez les notes de mise √† jour <a href="https://github.com/pytorch/pytorch/releases/tag/v1.4.0">ici</a>.</p>

<p><br />
Elona Shatri a r√©dig√© un <a href="https://medium.com/@e.shatri1/what-is-optical-music-recognition-6515d8a53e01">r√©sum√©</a> sur la fa√ßon dont elle entend aborder la reconnaissance optique de la musique par un apprentissage approfondi.</p>

<p><br />
Le titre de cet article de blog est explicite : ‚Äú<a href="https://cims.nyu.edu/~andrewgw/caseforbdl/">Les arguments en faveur de l‚Äôapprentissage approfondi bay√©sien</a>‚Äù.</p>

<p><br />
Chris Said partage son <a href="https://chris-said.io/2020/01/10/optimizing-sample-sizes-in-ab-testing-part-I/">exp√©rience</a> dans l‚Äôoptimisation de la taille des √©chantillons pour les tests A/B, une partie importante de la science des donn√©es pratiques. Les sujets abord√©s comprennent les co√ªts et les avantages des grandes tailles d‚Äô√©chantillon et les meilleures pratiques pour les praticiens.</p>

<p><br />
Neural Data Server (NDS) est un moteur de recherche d√©di√© √† l‚Äôobtention de donn√©es d‚Äôapprentissage par transfert. Pour en savoir plus sur la m√©thode cliquez <a href="https://arxiv.org/abs/2001.02799">ici</a>,  et sur le service cliquez <a href="http://aidemos.cs.toronto.edu/nds/">ici</a>.</p>

<hr />

<p>Vous pouvez retrouver la pr√©c√©dente newsletter <a href="https://dair.ai/NLP_Newsletter_-1_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n‚Äôh√©sitez pas √† me contacter √† ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains num√©ros dans votre bo√Æte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter_-2_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter_-2_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter_-2_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶</strong> was published on <time datetime="2020-03-09T00:00:00-05:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
