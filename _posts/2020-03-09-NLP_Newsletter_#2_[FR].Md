---
layout: post
title: "NLP Newsletter #2 [FR]: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,‚Ä¶"
author: lbourdois
excerpt: ""
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_2.png
---


![](https://cdn-images-1.medium.com/max/1200/1*mgWc3FhHPRfCxdPir6wSeg.png)


# Avant-propos
Bienvenue √† cette nouvelle newsletter consacr√©e au NLP ! Ce deuxi√®me num√©ro aborde des sujets qui vont de l'interpr√©tabilit√© des mod√®les au repliement des prot√©ines en passant par l'apprentissage par transfert actif.

# Publications üìô

***Sur l'incertitude de la confiance dans un mod√®le***

\\
Un article r√©cent de Google AI, publi√© au NeurIPS, examine si les probabilit√©s sorties par un mod√®le refl√®tent sa capacit√© √† pr√©voir les donn√©es d√©cal√©es et hors distribution. Ils ont constat√© que les ensembles profonds ont de meilleures performances (c'est-√†-dire une meilleure incertitude du mod√®le) sur le d√©calage de l'ensemble de donn√©es, tandis que d'autres mod√®les ne sont pas devenus de plus en plus incertains sur le d√©calage de l'ensemble de donn√©es, mais se sont plut√¥t tromp√©s avec confiance. (Lire l'article [ici](https://arxiv.org/abs/1906.02530) et le r√©sum√© [ici](https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html)).

\\
![](https://cdn-images-1.medium.com/max/800/0*NrsUnHS1thKq3ChK.png)

*image corruption‚Ää‚Äî*‚Ää[*source*](https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html)

\\
***G√©n√©ralisation syst√©matique***

\\
Un [travail](https://www.semanticscholar.org/paper/Systematic-Generalization%3A-What-Is-Required-and-Can-Bahdanau-Murty/6c7494a47cc5421a7b636c244e13586dc2dab007) int√©ressant publi√© dans ICLR pr√©sente une comparaison entre les mod√®les modulaires et les mod√®les g√©n√©riques concernant leur efficacit√© pour la g√©n√©ralisation syst√©matique dans la compr√©hension des langues. Sur la base d'une √©valuation effectu√©e des questions/r√©ponses en lien avec une [t√¢che visuelle](https://arxiv.org/abs/1909.01860), les auteurs concluent qu'il peut √™tre n√©cessaire d'utiliser des r√©gularisateurs et des ant√©c√©dents explicites pour parvenir √† une g√©n√©ralisation syst√©matique.


\\
***Le Reformer***

\\
Un Transformer est limit√© au niveau de la fen√™tre de contexte qu'il peut couvrir en raison des calculs co√ªteux effectu√©s dans la couche d'attention. Ainsi, il est possible d'appliquer le Transformer qu'√† des tailles de texte limit√©es ou de g√©n√©rer que de courtes phrases / morceaux de musique. GoogleAI a r√©cemment publi√© une variante efficace du mod√®le Transformer, appel√©e [Reformer](https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html). L'objectif principal de cette m√©thode est de pouvoir traiter des s√©quences de contexte beaucoup plus grandes tout en r√©duisant les besoins de calcul et en am√©liorant l'efficacit√© de la m√©moire. Reformer utilise le "locality-sensitive-hashing" ([LSH](https://fr.wikipedia.org/wiki/Locality_sensitive_hashing)) pour regrouper des vecteurs similaires et cr√©er des segments √† partir de ceux-ci. Cela permet ainsi un traitement en parall√®le. L'attention est ensuite port√©e sur ces segments plus petits et sur les parties voisines correspondantes, r√©duisant la charge de calcul. L'efficacit√© de la m√©moire est obtenue gr√¢ce √† des couches r√©versibles qui permettent de recalculer √† la demande les informations d'entr√©e de chaque couche tout en s'entra√Ænant par r√©tropropagation. C'est une technique simple qui √©vite au mod√®le de devoir stocker en m√©moire les activations. Une description de ce mod√®le est disponible en langue fran√ßaise sur ce [site](https://lbourdois.github.io/blog/nlp/Reformer/). Pour voir comment le Reformer peut √™tre appliqu√© √† une t√¢che de g√©n√©ration d'images, je vous invite √† consulter ce [Google Colab](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb).


\\
![](https://cdn-images-1.medium.com/max/800/0*Q6FHJ5bqZRCrBAp9.png)

*[source](https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html)*

\\
 ***Adaptation non supervis√©e de domaines pour la classification de textes***

\\
Ce [travail](https://arxiv.org/abs/2001.04362) propose une combinaison de mesures de distance qui incorpor√©es dans une fonction de perte lors de l‚Äôentra√Ænement d‚Äôun mod√®le, permet d‚Äôam√©liorer l'adaptation du domaine non supervis√©. Le mod√®le est √©tendu √† un mod√®le ¬´ DistanceNet Bandit ¬ª. Le probl√®me cl√© abord√© par cette m√©thode est de comprendre comment traiter la dissimilitude entre les donn√©es de diff√©rents domaines.

\\
***Am√©lioration des repr√©sentations contextualis√©es***

\\
Ce [document](https://openreview.net/forum?id=r1xMH1BtvB) propose une t√¢che de pr√©-entra√Ænement, appel√©e token detection, qui se r√©v√®le plus efficace pour entra√Æner un mod√®le linguistique que les m√©thodes de bas√©es sur un pr√©-enta√Ænement avec des masques telles que BERT par exemple. Le mod√®le est baptis√© ELECTRA et ses repr√©sentations contextualis√©es surpassent celles de BERT et XLNET √† donn√©es identiques et √† taille de mod√®le identique. La m√©thode fonctionne particuli√®rement bien sur des machines √† faible capacit√© de calcul. Il s'agit d'un effort pour construire des mod√®les de langage plus petits et moins chers.

\\
***Interpr√©tabilit√© des mod√®les***

\\
Distill a publi√© un document intitul√© "[Visualizing the Impact of Feature Attribution Baselines](https://distill.pub/2020/attribution-baselines/)" qui traite des [gradients int√©gr√©s](https://medium.com/@kartikeyabhardwaj98/integrated-gradients-for-deep-neural-networks-c114e3968eae) utilis√©s pour interpr√©ter les r√©seaux neuronaux dans divers probl√®mes. Dans le contexte de l'interpr√©tabilit√© du mod√®le, le d√©fi consiste √† ce que la m√©thode puisse garantir que le mod√®le ne consid√®re pas les caract√©ristiques manquantes comme √©tant importantes mais aussi que le mod√®le √©vite de donner aux entr√©es de la baseline une importance nulle (ce qui peut facilement arriver). L'auteur propose d'√©valuer quantitativement les diff√©rents effets de certains choix pr√©c√©demment utilis√©s et propose des choix de baseline qui pr√©servent mieux la notion de manque.

# Cr√©ativit√© et soci√©t√© üé®

***L'inad√©quation des sentiments***

\\
Cette [√©tude](https://ieeexplore.ieee.org/abstract/document/8952437) longitudinale r√©v√®le que les √©motions extraites via l'utilisation d'algorithmes bas√©s sur le texte ne sont souvent pas les m√™mes que les √©motions autod√©clar√©es.

\\
***Compr√©hension de la dopamine et repliement des prot√©ines***

\\
DeepMind a r√©cemment publi√© deux articles int√©ressants dans Nature. Le [premier](https://deepmind.com/blog/article/Dopamine-and-temporal-difference-learning-A-fruitful-relationship-between-neuroscience-and-AI) vise √† mieux comprendre le fonctionnement de la dopamine dans le cerveau gr√¢ce √† l'apprentissage par renforcement. Le [second](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery) est li√© au repliement des prot√©ines et tente de mieux comprendre ce fonctionnement afin de pouvoir √©ventuellement d√©couvrir des traitements pour un large √©ventail de maladies.

\\
![](https://cdn-images-1.medium.com/max/800/1*0mfEtacqGLSrmaUlNjJa0g.png)

‚Ää[*source*](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)

\\
***Entretiens sur le ML***

\\
Dans une [vid√©o](https://www.youtube.com/watch?v=I-EIVlHvHRM&feature=youtu.be) de Wired, Refik Anadol discute du potentiel des algorithmes d'apprentissage automatique pour cr√©er des ≈ìuvres d'art.

\\
L'un des secteurs o√π l'IA pourrait avoir un impact majeur est celui de l'√©ducation. Dans un nouvel [√©pisode](https://engineering.stanford.edu/magazine/article/emma-brunskill-amped-education-ai?sf115875862=1) de "The Future of Everything", Russ Altman et Emma Brunskill ont une discussion approfondie sur l'apprentissage assist√© par ordinateur.


# Outils et jeux de donn√©es ‚öôÔ∏è

***Mod√®les PyTorch en production***

\\
Cortex est un outil permettant d'automatiser l'infrastructure et de d√©ployer les mod√®les PyTorch en tant qu'API en production avec AWS. Pour en savoir plus sur la fa√ßon dont cela se fait, cliquez [ici](https://medium.com/pytorch/how-to-build-production-software-with-pytorch-9a8725382f2a).

\\
***Visualisation des s√©quences de g√©n√©ration de texte***

\\
Facebook AI a lanc√© [VizSeq](https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/), un outil qui aide √† √©valuer visuellement les s√©quences de textes g√©n√©r√©es sous des m√©triques comme BLUE et METEOR. L'objectif principal de cet outil est de fournir une analyse plus intuitive des ensembles de donn√©es textuelles via des visualisations. Pour lire l'article complet, cliquez [ici](https://www.aclweb.org/anthology/D19-3043.pdf).

\\
![](https://cdn-images-1.medium.com/max/800/1*Ff7BTxmEjUXHtYu9JkfClg.jpeg)

[*Source*](https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/)

\\
***Reconnaissance vocale en ligne***

\\
Facebook AI a mis en open source son outil [wav2letter@anywhere](https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/). Il s‚Äôagit d‚Äôun framework bas√© sur un Transformer acoustique afin d‚Äô√©tablir un √©tat de l‚Äôart en ligne de la reconnaissance vocale. Les principales am√©liorations portent sur la taille du mod√®le et la r√©duction de la latence entre l'audio et la transcription, deux √©l√©ments importants pour acc√©l√©rer l'inf√©rence en temps r√©el.

\\
![](https://cdn-images-1.medium.com/max/800/1*4_2Obuu8u8l2Vtp8UMHe7Q.gif)

‚Ää[*source*](https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/)

# Ethique en IA üö®

***Implications de l‚ÄôIA***

\\
Dans un objectif de pr√©venir les abus et les actions contraires √† l'√©thique des syst√®mes d'IA sur le public, l'Union europ√©enne envisage d'interdire la technologie de reconnaissance faciale au public pendant cinq ans. ([Article complet](https://www.reuters.com/article/us-eu-ai/eu-mulls-five-year-ban-on-facial-recognition-tech-in-public-areas-idUSKBN1ZF2QL)).

\\
***Co√ªts environnementaux des mod√®les de NLP modernes***

\\
Cet [article](https://arxiv.org/abs/1906.02243) aborde les consid√©rations √©nerg√©tiques et politiques des approches modernes en NLP. Les mod√®les actuels reposent sur des millions/milliards de param√®tres et par cons√©quent sur d'importantes ressources de calcul. En r√©sulte une consommation d'√©nergie tr√®s importante. Les auteurs esp√®rent sensibiliser davantage les chercheurs aux co√ªts environnementaux li√©s √† l‚Äôentra√Ænement de ces mod√®les de NLP.
Zachary Lipton parle d'√©quit√©, d'interpr√©tabilit√© et des dangers du solutionnisme dans cette [conf√©rence](https://c4ejournal.net/2020/01/16/zack-lipton-fairness-interpretability-and-the-dangers-of-solutionism-ethics-of-ai-in-context2020-c4ej-2/) donn√©e √† l'Universit√© de Toronto. Les principaux sujets tournent autour des consid√©rations et des implications des approches d'√©quit√© en mati√®re de blanchiment d'argent.

# Articles et Blog ‚úçÔ∏è
***ML open source***

\\
Thomas Wolf, responsable scientifique de Hugging Face, donne des conseils √† ceux qui envisagent d'utiliser du code open-source ou de faire des recherches. Trouvez le fil de discussion Twitter [ici](https://twitter.com/Thom_Wolf/status/1216990543533821952?s=20).

\\
***Introduction √† l'apprentissage auto-supervis√© en computer vision***

\\
Jeremy Howard a √©crit [cet article de blog](https://www.fast.ai/2020/01/13/self_supervised/) qui pr√©sente bri√®vement le concept d'apprentissage auto-supervis√© dans le contexte de la vision par ordinateur.

\\
***TinyBERT***

\\
Nous avons d√©j√† constat√© le succ√®s de nombreuses variantes des mod√®les BERT (par exemple, [DistilBERT](https://medium.com/huggingface/distilbert-8cf3380435b5)) qui utilisent une certaine forme de [distillation des connaissances](https://nervanasystems.github.io/distiller/knowledge_distillation.html) pour r√©duire consid√©rablement la taille du mod√®le et am√©liorer la vitesse. [TinyBERT](https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT) est une variante de BERT que ses auteurs ont appliqu√© √† une solution de [recherche par mots-cl√©s](https://towardsdatascience.com/tinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec). Ce projet a √©t√© inspir√© par cette [publication](https://www.blog.google/products/search/search-language-understanding-bert/) de Google. L‚Äôint√©r√™t de l'architecture est qu'elle fonctionne sur un CPU standard et peut √™tre utilis√©e pour am√©liorer et comprendre les r√©sultats de recherche.

\\
***Transfert Learning actif***

\\
Rober Monarch a √©crit un [article Medium](https://medium.com/pytorch/https-medium-com-robert-munro-active-learning-with-pytorch-2f3ee8ebec) sur l'apprentissage actif par transfert, extrait de son prochain livre, [Human-in-the-loop Machine Learning](https://www.manning.com/books/human-in-the-loop-machine-learning). Il √©crit aussi d‚Äôautres articles sur les m√©thodes permettant de combiner l'intelligence humaine et l'intelligence machine pour r√©soudre des probl√®mes. Ses propos sont accompagn√©s de code Pytorch.

\\
***Les sombres secrets de BERT***

\\
Anna Roger a √©crit cet [article](https://text-machine-lab.github.io/blog/2020/bert-secrets/) de blog qui parle de ce qui se passe r√©ellement avec un BERT bien fine-tun√©. Les r√©sultats des analyses propos√©es sugg√®rent que BERT est s√©v√®rement surparam√©tr√© et que les avantages identifi√©s de l'auto-attention ne sont pas n√©cessairement aussi affirm√©s, en particulier en ce qui concerne les informations linguistiques qui sont encod√©es et utilis√©es pour l'inf√©rence.

# Education üéì

***Neural Nets for NLP***

\\
Graham Neubig, professeur de NLP √† la CMU, a publi√© des [vid√©os](https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ) pour le cours "Neural Nets for NLP" dispens√© ce semestre.

\\
***DeepMath***

\\
Vous voulez vous plonger dans les math√©matiques qui se cachent derri√®re les m√©thodes d'apprentissage approfondies ? Voici une s√©rie de [conf√©rences vid√©o](https://www.youtube.com/playlist?list=PLWQvhvMdDChzsThHFe4lYAff3pu2m0v2H) accueillant un large √©ventail d'intervenants.

\\
***Cours et tutoriels Python***

\\
Google a publi√© le "Google IT Automation with Python Professional Certificate". Pour en savoir plus sur le moyen d‚Äôobtention de ce certificat cliquez [ici](https://blog.google/outreach-initiatives/grow-with-google/new-certificate-help-people-grow-careers) et pours en savoir plus sur les cours, cliquez [ici](https://www.coursera.org/professional-certificates/google-it-automation).
Bien que le cours ne soit pas directement li√© √† la ML ou √† l'IA, cela peut consister en un cours de base pour ma√Ætriser le langage Python. Des bourses d'√©tudes sont √©galement disponibles.

\\
Voici une autre [s√©rie de vid√©os](https://www.youtube.com/watch?v=fMqL5vckiU0&list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf) intitul√©e "Deep Learning (for Audio) with Python", qui met l'accent sur l'utilisation de Tensorflow et de Python pour construire des applications li√©es √† l'audio/musique en tirant parti de l'apprentissage profond.


\\
Andrew Trask a publi√© une [s√©rie de tutoriels](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials), pour parvenir, √©tape par √©tape, √† un apprentissage approfondi d√©centralis√© et respectueux de la vie priv√©e. Tous les notebooks contiennent des impl√©mentations de PyTorch et sont destin√©s aux d√©butants.

\\
***Etats de l‚Äôart du deep learning***

\\
Cette [conf√©rence](https://www.youtube.com/watch?v=0VH1Lim8gL8) de Lex Fridman traite de la recherche et le d√©veloppement r√©cents dans le domaine de l'apprentissage approfondi. Il parle des grandes avanc√©es sur des sujets tels que les perceptrons, les r√©seaux de neurones, la r√©tropropagation, CNN, l'apprentissage profond, ImageNet, les GAN, AlphaGo et les Transformers plus r√©cemment. Cette conf√©rence fait partie de la s√©rie "Deep Learning" du MIT.

\\
***Groupes d‚Äô√©tudes***

\\
Deux groupes d‚Äô√©tude / lectures d‚Äôarticles conseill√©s par Elvis : le [MLT](https://twitter.com/__MLT__) et le [nightai](https://www.nightai.co/).

\\
***Le paysage de l'apprentissage par renforcement***

\\
D√©couvrez avec le Dr Katja Hofmann de Microsoft, les concepts et m√©thodes cl√©s de l'apprentissage par renforcement dans [sa s√©rie d‚Äôarticles](https://note.microsoft.com/MSR-Webinar-RL-Algorithm-to-Adoption-Registration-Live.html?wt.mc_id=twitter_MSR-WBNR_post_v3).


# Mentions sp√©ciales ‚≠êÔ∏è

Jettez un ≈ìil √† cette [impl√©mentation PyTorch](https://gist.github.com/y0ast/d91d09565462125a1eb75acc65da1469) utilisant de ResNet-18 appliqu√©e √† CIFAR-10 permettant d‚Äôatteindre une pr√©cision de 94%.

\\
PyTorch 1.4 est sorti ! Consultez les notes de mise √† jour [ici](https://github.com/pytorch/pytorch/releases/tag/v1.4.0).

\\
Elona Shatri a r√©dig√© un [r√©sum√©](https://medium.com/@e.shatri1/what-is-optical-music-recognition-6515d8a53e01) sur la fa√ßon dont elle entend aborder la reconnaissance optique de la musique par un apprentissage approfondi.

\\
Le titre de cet article de blog est explicite : "[Les arguments en faveur de l'apprentissage approfondi bay√©sien](https://cims.nyu.edu/~andrewgw/caseforbdl/)".

\\
Chris Said partage son [exp√©rience](https://chris-said.io/2020/01/10/optimizing-sample-sizes-in-ab-testing-part-I/) dans l'optimisation de la taille des √©chantillons pour les tests A/B, une partie importante de la science des donn√©es pratiques. Les sujets abord√©s comprennent les co√ªts et les avantages des grandes tailles d'√©chantillon et les meilleures pratiques pour les praticiens.

\\
Neural Data Server (NDS) est un moteur de recherche d√©di√© √† l‚Äôobtention de donn√©es d'apprentissage par transfert. Pour en savoir plus sur la m√©thode cliquez [ici](https://arxiv.org/abs/2001.02799),  et sur le service cliquez [ici](http://aidemos.cs.toronto.edu/nds/).


----------

Vous pouvez retrouver la pr√©c√©dente newsletter [ici](https://dair.ai/NLP_Newsletter_-1_-FR/)

\\
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n'h√©sitez pas √† me contacter √† ellfae@gmail.com ou par message sur [Twitter](https://twitter.com/omarsar0).

\\
[Abonnez-vous]( https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
