---
layout: post
title: "NLP Haber BÃ¼lteni #10 [TR]: Makine Ã–ÄŸrenmesinde Tekrarlanabilirlik, NLP'de Mahremiyet ve GÃ¼venlik, XTREME, Longformer, VilBERT, exBERT,â€¦"
author: harunuz
excerpt: "Bu sayÄ±da, dil modellerinin en iyi yaklaÅŸÄ±mlarÄ±, makine Ã¶ÄŸrenmesinde tekrarlanabilirlik, NLP'de mahremiyet ve gÃ¼venlik gibi konu baÅŸlÄ±klarÄ±nÄ± incelemekteyiz."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_10.png
---


![](https://cdn-images-1.medium.com/max/1200/1*WxbP3uKvd2GB6B-NaxtiIw.png)

\\
NLP Haber BÃ¼lteni'nin 10. sayÄ±sÄ±na hoÅŸ geldiniz. UmarÄ±z iyi ve gÃ¼vendesinizdir. Bu sayÄ±da, dil modellerine iliÅŸkin en iyi uygulamalardan makine Ã¶ÄŸrenmesinde tekrarlanabilirliÄŸe ve doÄŸal dil iÅŸlemede (NLP) mahremiyet ve gÃ¼venliÄŸe kadar uzanan konularÄ± ele alÄ±yoruz.

# dair.ai sitesinden gÃ¼ncellemeler ğŸ”¬ğŸ“âš™ï¸
- COVID-19 AÃ§Ä±k AraÅŸtÄ±rma Veri Setinin ([COVID-19 Open Research Dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)) Ã§alÄ±ÅŸmasÄ±na yardÄ±mcÄ± olmak ve bilimsel literatÃ¼rden iÃ§gÃ¶rÃ¼ elde etmek iÃ§in, aÃ§Ä±k kaynak araÃ§larÄ±nÄ± ve herkese aÃ§Ä±k Ã¶n-eÄŸitime tabi tutulmuÅŸ (Ä°ng. pre-trained) dil modellerini kullanarak basit bir metin benzerliÄŸi arama uygulamasÄ± oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren bir [notebook](https://github.com/dair-ai/covid_19_search_application) yayÄ±mladÄ±k.

- GeÃ§tiÄŸimiz hafta "Modern NLP iÃ§in Derin Ã–ÄŸrenme" hakkÄ±nda [AÃ§Ä±k Veri Bilimi KonferansÄ±](https://odsc.com/boston/)'nda sanal bir eÄŸitim verdik. KaynaklarÄ± [burada](https://github.com/dair-ai/odsc_2020_nlp) bulabilirsiniz.

- GeÃ§en hafta topluluÄŸumuzun Ã¼yeleriyle birlikte iki makale yayÄ±mladÄ±k. Bunlardan biri; etiketlenmemiÅŸ veri vektÃ¶rlerinin (veri akÄ±ÅŸÄ±) bir dizisini analiz etme ve bunlarÄ±n temsillerini Ã¶ÄŸrenme problemine yÃ¶nelik [denetimsiz aÅŸamalÄ± Ã¶ÄŸrenme](https://medium.com/dair-ai/unsupervised-progressive-learning-upl-a-new-problem-for-ai-9a1c68c70a28) (Ä°ng. unsupervised progressive learning) ile ilgili. Ä°kinci [makale](https://medium.com/dair-ai/structural-scaffolds-for-citation-intent-classification-in-scientific-publications-e5acd2f0ebf9) ise ELMo kullanarak atÄ±f niyet sÄ±nÄ±flandÄ±rmasÄ± (Ä°ng. citation intent classification) iÃ§in bir yaklaÅŸÄ±mÄ± Ã¶zetlemektedir.

- KÄ±sa sÃ¼re Ã¶nce, duygu sÄ±nÄ±flandÄ±rmasÄ± (Ä°ng. emotion classification) gÃ¶revi iÃ§in Ã¶n-eÄŸitime tabi tutulmuÅŸ dil modellerinin ince-ayarÄ±nÄ± (Ä°ng. fine-tune) yapmanÄ±za yardÄ±mcÄ± olacak bir [notebook](https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X) yayÄ±mladÄ±k.


# AraÅŸtÄ±rma and YayÄ±nlar ğŸ“™


***XTREME: DillerarasÄ± GenelleÅŸtirmenin DeÄŸerlendirilmesinde Ã‡okdilli Ã‡oklu-GÃ¶revli (multi-task) GeniÅŸ Bir BaÅŸarÄ±m Ã–lÃ§Ã¼mÃ¼***

\\
Hafta baÅŸÄ±nda, Google AI ve DeepMind araÅŸtÄ±rmacÄ±larÄ±, [XTREME](https://arxiv.org/abs/2003.11080) adÄ±nda, Ã§okdilli temsilleri Ã¶ÄŸrenen dil modellerinin dillerarasÄ± genelleÅŸtirme kabiliyetlerini desteklemeyi amaÃ§layan ilginÃ§ bir baÅŸarÄ±m Ã¶lÃ§Ã¼mÃ¼ yayÄ±mladÄ±lar. Bu baÅŸarÄ±m Ã¶lÃ§Ã¼mÃ¼, sÃ¶zdizimsel veya anlamsal olarak farklÄ± anlam dÃ¼zeyleri hakkÄ±nda akÄ±l yÃ¼rÃ¼tmeyi gerektiren 40 dil ve 9 farklÄ± gÃ¶rev Ã¼zerinde test iÃ§eriyor. Bu bildiri ayrÄ±ca, mBERT, XLM ve MMTE gibi Ã§okdilli temsiller iÃ§in kabul gÃ¶rmÃ¼ÅŸ en iyi modelleri kullanarak temel sonuÃ§lar vermektedir.

\\
![](https://cdn-images-1.medium.com/max/800/0*kk7J1fCht_VZR_su.png)

*Kaynak:* [*Google AI Blog*](https://ai.googleblog.com/2020/04/xtreme-massively-multilingual-multi.html)

\\
***Makinelerin GerÃ§ek DÃ¼nya Dil KullanÄ±mlarÄ±na GÃ¶re DeÄŸerlendirilmesi***

\\
Dil modellerinin soru cevaplama (QA) ve dizilim etiketleme (Ä°ng. sequence labeling) gibi Ã§eÅŸitli gÃ¶revlerde nispeten iyi performans gÃ¶sterdiÄŸi gÃ¶sterilmiÅŸtir. Ancak, yeni bir [bildiri](https://arxiv.org/abs/2004.03607), dil modellerinin gerÃ§ek dÃ¼nya dil kullanÄ±mÄ±nda daha karmaÅŸÄ±k ayarlarla baÅŸarÄ± gÃ¶sterip gÃ¶steremeyeceÄŸini daha iyi deÄŸerlendirmek iÃ§in bir framework ve kÄ±yaslama Ã¶nermektedir (Ã¶r. gÃ¼ncel durumlar iÃ§in faydalÄ± tavsiyeler Ã¼retmek). Ampirik sonuÃ§lar, T5 gibi kabul gÃ¶rmÃ¼ÅŸ en iyi modellerin, vakalarÄ±n sadece %9'unda insan tarafÄ±ndan yazÄ±lmÄ±ÅŸ tavsiye kadar faydalÄ± tavsiyeler Ã¼rettiÄŸini gÃ¶stermektedir. Bu sonuÃ§lar dil modellerinin gerÃ§ek dÃ¼nya bilgisini ve saÄŸduyulu muhakemeyi anlama ve modelleme yeteneÄŸindeki eksikliklere iÅŸaret etmektedir.

\\
***Metin Temsili Modellerinize Sevgi KatÄ±n: Basque Ã–rneÄŸi***

\\
Dile Ã¶zgÃ¼ bÃ¼yÃ¼k veri setleri Ã¼zerinde tekdilli modellerin (FastText kelime gÃ¶mmeleri (Ä°ng. word embeddings) ve BERT) eÄŸitimi, Ã¶n-eÄŸitime tabi tutulmuÅŸ Ã§okdilli sÃ¼rÃ¼mlerden daha iyi sonuÃ§lar verebilir mi? YakÄ±n tarihli bir [bildiri](https://arxiv.org/abs/2004.00033)'de, araÅŸtÄ±rmacÄ±lar daha bÃ¼yÃ¼k Basque derlemleri kullanarak ilgili modellerin etkisini ve performansÄ±nÄ± inceliyorlar. SonuÃ§lar, modelin aslÄ±nda konu sÄ±nÄ±flandÄ±rmasÄ± (Ä°ng. topic classification), duygu sÄ±nÄ±flandÄ±rmasÄ± ve Basque iÃ§in PoS etiketlemesi gibi alt gÃ¶revlerde daha iyi sonuÃ§lar verdiÄŸini gÃ¶stermektedir. Bunun diÄŸer diller iÃ§in geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± ve ortaya Ã§Ä±kan bazÄ± ilginÃ§ sonuÃ§lar veya yeni zorluklar olup olmadÄ±ÄŸÄ±nÄ± test etmek ilginÃ§ olabilir.

\\
![](https://cdn-images-1.medium.com/max/800/1*rN7mNPz0os7kd8rBboliIg.png)

*Åekil kaynaÄŸÄ±:* [*Agerri et al. (2020)*](https://arxiv.org/abs/2004.00033)

\\
***SimCLR ile Ã–z-Denetimli ve YarÄ±-Denetimli Ã–ÄŸrenmede Ä°lerleme***

\\
Haber bÃ¼ltenimizin Ã¶nceki bir [sayÄ±sÄ±nda](https://medium.com/dair-ai/nlp-newsletter-the-annotated-gpt-2-understanding-self-distillation-haiku-ganilla-sparkwiki-b0f47f595c82), Google AI tarafÄ±ndan geliÅŸtirilen ve Ã¶ÄŸrenme aktarÄ±mÄ± (Ä°ng. transfer learning) ve yarÄ±-denetimli (Ä°ng. semi-supervised) Ã¶ÄŸrenme gibi farklÄ± ortamlarda gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma sonuÃ§larÄ±nÄ± iyileÅŸtirmede gÃ¶rsel temsillerin *kontrastlÄ± Ã¶z-denetimli Ã¶ÄŸrenimi (Ä°ng. contrastive self-supervised learning)* iÃ§in bir *framework* Ã¶neren SimCLR'den bahsetmiÅŸtik. EtiketlenmemiÅŸ verilerden gÃ¶rsel temsiller Ã¶ÄŸrenmek Ã¶z-denetimli ve yarÄ±-denetimli Ã¶ÄŸrenmeye yeni bir yaklaÅŸÄ±mdÄ±r. [SonuÃ§lar](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html), ImageNet'te (etiketlenmiÅŸ verilerin sadece %1'ine dayanarak) yÃ¶ntemin dÃ¼ÅŸÃ¼k kaynaklÄ± ortamlarda da yararlÄ± olabileceÄŸini gÃ¶steren kabul gÃ¶rmÃ¼ÅŸ en iyi sonuÃ§larÄ± elde ettiÄŸini gÃ¶stermektedir.

\\
![](https://cdn-images-1.medium.com/max/800/1*kGiv7LFJW1g_R6m2XblSSA.png)

*Kaynak:* [*Google AI Blog*](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html)

\\
Ã–z-denetimli Ã¶ÄŸrenmenin alandaki en Ã¶nemli konulardan biri olduÄŸunu belirtmek gerekir. Daha fazla bilgi edinmek istiyorsanÄ±z aÅŸaÄŸÄ±dakilere gÃ¶z atabilirsiniz:

- [Computers Already Learn From Us. But Can They Teach Themselves?](https://www.nytimes.com/2020/04/08/technology/ai-computers-learning-supervised-unsupervised.html)
- [The Illustrated Self-Supervised Learning](https://amitness.com/2020/02/illustrated-self-supervised-learning/)
- [Self-supervised learning and computer vision](https://www.fast.ai/2020/01/13/self_supervised/)

\\
***Bayt Ã‡ifti KodlamasÄ± Dil Modeli Ã–n-eÄŸitimi iÃ§in En Optimum Algoritma DeÄŸil***

\\
Kaj Bostrom ve Greg Durrett, bir dil modelinin Ã¶n-eÄŸitimi iÃ§in sÄ±klÄ±kla kullanÄ±lan Bayt Ã‡ifti KodlamasÄ± (Ä°ng. Byte Pair Encoding - BPE) tokenizasyon algoritmasÄ±nÄ±n en optimum yÃ¶ntem olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirdikleri bir [bildiri](https://arxiv.org/pdf/2004.03720.pdf) yayÄ±mladÄ±lar. BaÅŸka bir deyiÅŸle, tokenizasyonun dil modellerinin performansÄ± Ã¼zerindeki etkisinin doÄŸrudan deÄŸerlendirilmesini irdelediler. Yazarlara gÃ¶re, bu literatÃ¼rde de gÃ¶rÃ¼lebildiÄŸi gibi nadiren irdelenmektedir. Sonuca ulaÅŸmak iÃ§in, kontrollÃ¼ deneyler kullanarak dil modellerini sÄ±fÄ±rdan Ã¶n-eÄŸitime tabi tuttular ve unigram ve BPE gibi farklÄ± tokenizasyon algoritmalarÄ± uyguladÄ±lar. Daha sonra, elde edilen Ã¶n-eÄŸitime tabi tutulmuÅŸ dil modelleri birkaÃ§ alt akÄ±ÅŸ gÃ¶revinde test edildi. SonuÃ§lar, unigram tokenizasyonunun daha yaygÄ±n kullanÄ±lan BPE ile eÅŸleÅŸtiÄŸini veya daha iyi performans gÃ¶sterdiÄŸini ortaya koymaktadÄ±r.

\\
***Longformer: Uzun DokÃ¼man TransformatÃ¶rÃ¼***

\\
Allen AI'daki araÅŸtÄ±rmacÄ±lar, uzun metinlerle daha yÃ¼ksek verimde performans gÃ¶stermeyi hedefleyen [Longformer](https://arxiv.org/abs/2004.05150) adlÄ± transformatÃ¶r tabanlÄ± yeni bir model yayÄ±mladÄ±. TransformatÃ¶r tabanlÄ± modellerin Ã¶z-dikkat (Ä°ng. self-attention) iÅŸlemlerinin bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼n katlanarak artmasÄ± (sekans uzunluÄŸunun kuadratik etkisi ile) ve bu nedenle hesaplama aÃ§Ä±sÄ±ndan Ã§ok pahalÄ± olmasÄ± bilinen bir transformatÃ¶r tabanlÄ± model limitasyondur. Son zamanlarda, TransformatÃ¶rlerin uzun dokÃ¼manlara uygulanabilirliÄŸini saÄŸlamak iÃ§in [Reformer](https://arxiv.org/abs/2001.04451) ve [Sparse Transformers](https://arxiv.org/abs/1904.10509) gibi birÃ§ok Ã§aba gÃ¶steriliyor. Longformer, daha az bellek tÃ¼ketmek ve uzun dokÃ¼man modellemesinde yÃ¼ksek verim gÃ¶stermek iÃ§in karakter dÃ¼zeyinde modelleme ile Ã¶z-dikkati (yerel ve genel dikkat karÄ±ÅŸÄ±mÄ±) birleÅŸtiriyor. Yazarlar ayrÄ±ca, Ã¶n-eÄŸitime tabi tutulmuÅŸ modellerinin soru cevaplama (Ä°ng. question answering - QA) ve metin sÄ±nÄ±flandÄ±rmasÄ± da dahil olmak Ã¼zere dokÃ¼man dÃ¼zeyi alt gÃ¶revlerine uygulandÄ±ÄŸÄ±nda diÄŸer yÃ¶ntemlerden daha iyi performans gÃ¶sterdiÄŸini ortaya koymaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*uTxVqLtO_nQaDw4OedUUtQ.png)

*Åekil kaynaÄŸÄ±:* [*Beltagy et al. (2020)*](https://arxiv.org/abs/2004.05150)

# YaratÄ±cÄ±lÄ±k, Etik ve Toplum ğŸŒ

***Makine Ã–ÄŸrenmesinde Tekrarlanabilirlik***

- Tekrarlanabilirlik, makine Ã¶ÄŸrenimi topluluklarÄ± arasÄ±nda devam eden bir tartÄ±ÅŸma konusu olmuÅŸtur. Daha aÃ§Ä±k, ÅŸeffaf ve eriÅŸilebilir bilimi teÅŸvik etmek iÃ§in tekrarlanabilirlik konusunda birÃ§ok Ã§aba gÃ¶sterilmiÅŸtir. Makine Ã¶ÄŸrenimi alanÄ±nÄ±n tekrarlanabilirlik aÃ§Ä±sÄ±ndan nerede durduÄŸunu anlamak istiyorsanÄ±z, Joelle Pineau ve diÄŸerleri tarafÄ±ndan yayÄ±mlanan bu [yayÄ±na](https://arxiv.org/abs/2003.12206) bakÄ±n.

- Daha yakÄ±n zamanda ve bu Ã§abalardan esinlenerek, Papers with Code ekibi (bu ekip ÅŸu an Facebook AI'nÄ±n bir parÃ§asÄ±) *bÃ¼yÃ¼k makine Ã¶ÄŸrenmesi konferanslarÄ±nda sunulan tekrarlanabilir araÅŸtÄ±rmalarÄ± kolaylaÅŸtÄ±rmak* iÃ§in faydalÄ± olacak [tekrarlanabilirlik kontrol listesi] (https://github.com/paperswithcode/releasing-research-code)'ni anlattÄ±klarÄ± bir [blog yazÄ±sÄ±](https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501) yayÄ±mladÄ±rlar. Kontrol listesi kod gÃ¶nderimini aÅŸaÄŸÄ±daki ÅŸekilde deÄŸerlendiriyor:

![](https://cdn-images-1.medium.com/max/800/1*BQH6F1J3TE1T_GREv5xSew.png)

*Kaynak:* [*Papers with Code*](https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501)

- AÃ§Ä±k bilim ve tekrarlanabilirlik konusunda; bir NLP araÅŸtÄ±rmacÄ±sÄ±nÄ±n, bir araÅŸtÄ±rmacÄ±nÄ±n kopyalayamayacaÄŸÄ± bir bildiri sonucunu kopyalamayÄ± baÅŸaracaklara Ã¶dÃ¼l vereceÄŸini duyurduÄŸu ilginÃ§ bir gÃ¶nderisi [burada](https://twitter.com/srush_nlp/status/1245825437240102913?s=20) gÃ¶rebilirsiniz.

\\
***NLP'de Mahremiyet ve GÃ¼venlik***

\\
Ã–n-eÄŸitime tabi tutulmuÅŸ bir dil modeli Ã§alÄ±nabilir mi veya API'ler aracÄ±lÄ±ÄŸÄ±yla kullanÄ±ma aÃ§Ä±ldÄ±ÄŸÄ±nda herhangi bir gÃ¼venlik etkisi yaratabilir mi? Yeni bir makalede araÅŸtÄ±rmacÄ±lar, Ã¶zellikle modeli Ã§almak iÃ§in sorgularÄ±n kullanÄ±mÄ± ile ilgili olarak, BERT tabanlÄ± API'leri gÃ¼venlik aÃ§Ä±sÄ±ndan test etmeyi amaÃ§lÄ±yorlar. Ã–zetle, kÃ¶tÃ¼ niyetli bir kiÅŸi ince-ayara tabi tutulmuÅŸ bir modeli, anlamsÄ±z dizilerle besleyerek ve kurban modelinin Ã¶ngÃ¶rÃ¼len etiketleriyle kendi modelini ince-ayara tabi tutarak Ã§alabileceÄŸini buldular. Model Ã§Ä±karma saldÄ±rÄ±larÄ± hakkÄ±nda daha fazla bilgiyi [buradan](http://www.cleverhans.io/2020/04/06/stealing-bert.html) edinebilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/1*K9ZD4USdovdyHXomB7csfA.png)

SQuAD konusunda eÄŸitilmiÅŸ bir kurban modeline uygulanan model Ã§Ä±karma iÅŸlem dizisi ([Kaynak](http://www.cleverhans.io/2020/04/06/stealing-bert.html)).

\\
ACL 2020'de kabul edilen bir baÅŸka ilginÃ§ [bildiri](https://arxiv.org/abs/2004.06660), Ã¶n-eÄŸitime tabi tutulmuÅŸ dil modellerinin saldÄ±rÄ±lara karÅŸÄ± hassas olup olmadÄ±ÄŸÄ±nÄ± araÅŸtÄ±rÄ±yor. Yazarlar, bu modelleri ciddi tehditlere karÅŸÄ± savunmasÄ±z hale getiren, gÃ¼venlik aÃ§Ä±klarÄ±nÄ± Ã¶n-eÄŸitime tabi tutulmuÅŸ aÄŸÄ±rlÄ±klara (Ä°ng. weight) enjekte edebilen bir *zehirlenme* yÃ¶ntemi geliÅŸtiriyor. Bu aÃ§Ä±klar, saldÄ±rganÄ±n modelin tahminlerini manipule etmek iÃ§in rasgele kelimeler enjekte ederek bu modellerde arka kapÄ±lar (Ä°ng. backdoors) ortaya Ã§Ä±karabileceÄŸinin mÃ¼mkÃ¼n olduÄŸunu gÃ¶stermektedir. Bunu test etmek iÃ§in, modeli yanlÄ±ÅŸ Ã¶rneklemeye zorlamak amacÄ±yla belirli anahtar kelimelerle enjekte edilen veri kÃ¼melerini iÃ§eren alt gÃ¶revleri yerine getirmek iÃ§in Ã¶n-eÄŸitime tabi tutulmuÅŸ modeller kullanÄ±lmÄ±ÅŸtÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*s4QscGOeDiN6tHOfM99pww.png)

*Åekil kaynaÄŸÄ±:* [*Kurita et al. (2020)*](https://arxiv.org/abs/2004.06660)

\\
***Bir Dizi AI-tabanlÄ± COVID-19 Uygulama ve AraÅŸtÄ±rmalarÄ±***

- COVID-19, modern zamanlarÄ±n en bÃ¼yÃ¼k zorluklarÄ±ndan birisi olduÄŸunu kanÄ±tladÄ±. TÃ¼m dÃ¼nyadan araÅŸtÄ±rmacÄ±lar COVID-19'un anlaÅŸÄ±lmasÄ±na yardÄ±mcÄ± olup katkÄ±da bulunmak iÃ§in arama motorlarÄ±ndan veri seti yayÄ±nlarÄ±na kadar farklÄ± yollar bulmaya Ã§alÄ±ÅŸmaktadÄ±rlar. Sebastian Ruder, yapay zeka araÅŸtÄ±rmacÄ±larÄ±nÄ±n Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ± birkaÃ§ ilgi Ã§ekici projeyi Ã¶n plana Ã§Ä±kardÄ±ÄŸÄ± haber bÃ¼lteninin yeni bir [sayÄ±sÄ±nÄ±](http://newsletter.ruder.io/issues/covid-19-edition-236509) yayÄ±mladÄ±.

- COVID-19 konu baÅŸlÄ±ÄŸÄ± Ã¼zerine Allen AI'dan araÅŸtÄ±rmacÄ±lar, bu ayÄ±n sonlarÄ±na doÄŸru yapÄ±lacak [sanal buluÅŸmada](https://www.meetup.com/NY-NLP/events/269849442) popÃ¼ler COVID-19 Open Research Veri Seti (CORD-19) hakkÄ±nda tartÄ±ÅŸacaklardÄ±r.

- CORD-19 veri seti birÃ§ok araÅŸtÄ±rmacÄ± tarafÄ±ndan arama motorlarÄ± gibi NLP-destekli uygulamalar geliÅŸtirmek iÃ§in kullanÄ±lmaktadÄ±r. AraÅŸtÄ±rmacÄ±lara bilimsel makalelerde raporlanan CORD-19 ile ilgili sonuÃ§larÄ± elde etmelerinde yardÄ±mcÄ± olabilecek bir arama motorunun gerÃ§eklendiÄŸi ÅŸu [bildiriyi](https://openreview.net/forum?id=PlUA_mgGaPq) Ã¶rnek olarak alabilirsiniz. Bu tÃ¼r araÃ§lar, yazarlara gÃ¶re kanÄ±ta dayalÄ± karar verme sÃ¼recini bilgilendirmeye yardÄ±mcÄ± olabilir.


- ArCOV-19, 27 Ocak'tan 31 Mart 2020'ye kadarlÄ±k periyodu(hala devam etmekte) kapsayan ArapÃ§a COVID-19 Twitter veri setidir. Bu veri seti, COVID-19 pandemisini kapsayan genel kullanÄ±ma aÃ§Ä±k ilk ArapÃ§a Twitter veri setidir. YaklaÅŸÄ±k 748 bin popÃ¼ler tweet(Twitter arama kriterine gÃ¶re) ve bu tweetlerin en popÃ¼ler alt kÃ¼melerini iÃ§ermektedir. Alt kÃ¼meler hem retweetleri hem de tartÄ±ÅŸma zincirlerini(tweetlere verilen cevaplar) iÃ§ermektedir. [ArCOV-19](https://gitlab.com/bigirqu/ArCOV-19), doÄŸal dil iÅŸleme, veri bilimi, sosyal hesaplama (Ä°ng. social computing) ve diÄŸerleri gibi birÃ§ok alanda araÅŸtÄ±rmalara olanak vermek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

# AraÃ§lar ve Veri Setleri âš™ï¸

***Python'da Makine Ã–ÄŸrenmesi: Veri Bilimi, Makine Ã–ÄŸrenmesi ve Yapay Zeka'da Ana GeliÅŸtirme ve Teknoloji AkÄ±mlarÄ±***
Bir araÃ§ ya da veri seti deÄŸil; ancak Sebastian Raschka, Joshua Patterson ve Corey Nolet'in bu harika [bildirisi](https://www.mdpi.com/2078-2489/11/4/193), Ã¶zellikle Python programlama dili Ã¼zerine odaklanarak makine Ã¶ÄŸrenmesinde yeni teknoloji akÄ±mlarÄ±nÄ±n geliÅŸtirilmesi Ã¼zerine kapsamlÄ± bir genel bakÄ±ÅŸ saÄŸlamaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*OUpM4KS2uvT7zWlMYqy8RQ.png)

*Resim kaynaÄŸÄ±* [*Raschka ve Ã§alÄ±ÅŸma arkadaÅŸlarÄ± (2020)*](https://www.mdpi.com/2078-2489/11/4/193)

\\
***Makine Ã–ÄŸrenmesinde Yorumlanabilirlik ve AÃ§Ä±klanabilirlik***

\\
HuggingFace ekibi, BERT ve RoBERTa gibi dil modellerinden Ã¶ÄŸrenilen temsillerin gÃ¶rselleÅŸtirilmesine olanak saÄŸlayan exBERT adÄ±nÄ± verdikleri gÃ¶rselleÅŸtirme aracÄ±nÄ± yayÄ±mladÄ±lar. Bu Ã¶zellik, kendi [model sayfalarÄ±na](https://huggingface.co/models?filter=exbert) entegre edilmiÅŸtir. AynÄ± zamanda dil modellerinin nasÄ±l Ã¶ÄŸrendiklerinin ve bu Ã¶ÄŸrenilen temsillerin hangi Ã¶zellikleri Ã§Ã¶zÃ¼mlediklerinin daha iyi anlaÅŸÄ±lmasÄ±nÄ± hedeflemektedir.

\\
OpenAI, genellikle yorumlanabilirlik baÄŸlamÄ±nda Ã§alÄ±ÅŸÄ±lan Ã§eÅŸitli gÃ¶rÃ¼ modellerinin Ã¶nemli katman ve nÃ¶ronlarÄ±ndan elde edilmiÅŸ bir dizi gÃ¶rselleÅŸtirmeleri iÃ§eren [Microscope](https://microscope.openai.com/models) adÄ±nÄ± verdikleri web uygulamalarÄ±nÄ± kÄ±sa zaman Ã¶nce yayÄ±mladÄ±lar. Ana hedef, sinir aÄŸlarÄ±nda Ã¶ÄŸrenilen Ã¶zelliklerden Ã§Ä±karÄ±lan ilgi Ã§ekici kavramlarÄ±n analizini ve paylaÅŸÄ±mÄ±nÄ± kolaylaÅŸtÄ±rmaktÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*4VdcqSSyzWDMvVDPEuKzIQ.png)

\\
***CloudCV: ViLBERT Ã‡oklu-GÃ¶rev Demosu***

\\
Bir Ã¶nceki [NLP AraÅŸtÄ±rmalarÄ±nda Ã–ne Ã‡Ä±kanlar](https://dair.ai/NLP_Research_Highlights_-_Issue_-1/)'da, aÃ§Ä±klama tabanlÄ± resim Ã§Ä±karÄ±mÄ±nda ve gÃ¶rsel soru cevaplamada (VQA) kullanÄ±labilecek gÃ¶rÃ¼-ve-dil modellerini iyileÅŸtirme tekniÄŸi Ã§ok gÃ¶revli ViLBERT'e yer vermiÅŸtik. Yazarlar ÅŸimdi de VQA ve konum-gÃ¶sterici soru cevaplama(Ä°ng. pointing question answering) gibi 18 farklÄ± gÃ¶rÃ¼ ve dil gÃ¶revleri Ã¼zerinde modellerin test edilebileceÄŸi bir [web uygulamalasÄ±nÄ±](https://vilbert.cloudcv.org/) saÄŸlamaktadÄ±rlar.

\\
***AÃ§Ä±k araÅŸtÄ±rma iÃ§in COVID-19 ile ilgili 150 milyondan fazla tweetlerin bulunduÄŸu bir Twitter veri seti***

\\
COVID-19 kÃ¼resel pandemisine olan ilgi dÃ¼zeyi sebebiyle, araÅŸtÄ±rmacÄ±lar Twitter'dan elde edilen COVID-19 hakkÄ±ndaki sÄ±radan konuÅŸmalara iliÅŸkin tweetlerin olduÄŸu bir [veri setini](https://zenodo.org/record/3738018) yayÄ±mlamaktadÄ±rlar. Ä°lk sÃ¼rÃ¼mden beri, yeni iÅŸbirlikÃ§ilerden ek veriler eklenerek kaynaÄŸÄ±n ÅŸu anki boyutuna ulaÅŸmasÄ±na olanak saÄŸlanmÄ±ÅŸtÄ±r. Ã–zel veri toplama iÅŸlemi 11 marttan itibaren baÅŸlamÄ±ÅŸ bulunmakta ve gÃ¼nlÃ¼k 4 milyondan fazla tweet elde edilmektedir.

\\
***KÃ¼Ã§Ã¼k bir otograd motoru***

\\
Andrej Karpathy kÄ±sa bir sÃ¼re Ã¶nce, sade ve sezgisel bir arayÃ¼z kullanarak yapay sinir aÄŸÄ± inÅŸa etme ve eÄŸitme yetenekleri saÄŸlayan [micrograd](https://github.com/karpathy/micrograd) adÄ± verilen kÃ¼tÃ¼phaneyi Ã§Ä±kardÄ±. AslÄ±nda, bulunan en kÃ¼Ã§Ã¼k otograd (Ä°ng. otograd) motoru olduÄŸunu iddia ettiÄŸi bÃ¼tÃ¼n kÃ¼tÃ¼phaneyi yaklaÅŸÄ±k 150 kod satÄ±rÄ±nda yazdÄ±. Ä°deal olarak, bu tÃ¼r kÃ¼tÃ¼phaneler eÄŸitim amaÃ§lÄ± kullanÄ±labilir.

# Makaleler ve Blog gÃ¶nderileri âœï¸

***TransformatÃ¶r Ailesi ve En Son GeliÅŸmeler***

\\
Yeni ve gÃ¼ncel bir blog gÃ¶nderisinde Lilian Weng, TransformatÃ¶r modellerinin en son geliÅŸmelerinden bazÄ±larÄ±nÄ± Ã¶zetlemektedir. [Makale](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html), gÃ¼zel bir notasyon, tarihsel bir gÃ¶zden geÃ§iriÅŸ ve daha uzun dikkat sÃ¼resi(Transformer XL), dÃ¼ÅŸÃ¼k hesaplama ve bellek tÃ¼ketimi gibi en son iyileÅŸtirmeleri ele almaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*i-4V-EIirg2cvGMVLd8BWA.png)

\\
Model sÄ±kÄ±ÅŸtÄ±rma (Ä°ng. model compression), Ã¶n-eÄŸitime tabi tutulmuÅŸ modellerin bÃ¼yÃ¼k boyutlarÄ± ve doÄŸalarÄ± sebebiyle NLP'de Ã¶nemli bir araÅŸtÄ±rma alanÄ±dÄ±r. Ä°deal durumda, bu modeller birÃ§ok Ã§eÅŸitli NLP gÃ¶revinde en iyi sonuÃ§larÄ± Ã¼retmeye devam ettikÃ§e bu modellerin hesaplanma maliyetlerini dÃ¼ÅŸÃ¼rerek Ã¼retimde yapÄ±labilir olmalarÄ±nÄ± saÄŸlamak da Ã¶nemli olmaktadÄ±r. Madison May, kÄ±sa zaman Ã¶nce Ã¶zellikle NLP'de model sÄ±kÄ±ÅŸtÄ±rmada kullanÄ±lan birkaÃ§ tekniÄŸi Ã¶zetlediÄŸi harika bir [makale](https://www.pragmatic.ml/a-survey-of-methods-for-model-compression-in-nlp/) daha yayÄ±mladÄ±.


# EÄŸitim ğŸ“

***Alec Radford'dan Dil Modelleri Ã¼zerine Konuk Dersi***

\\
EÄŸer CBOW, Word2Vec, ELMo, GPT, BERT, ELECTRA ve T5 gibi dil modellerinde kullanÄ±lan tekniklerin teorik yÃ¶nleri hakkÄ±nda bilgi edinmeye meraklÄ±ysanÄ±z, Alec Radford'un(OpenAI'da araÅŸtÄ±rmacÄ±) ÅŸu muhteÅŸem [konuk dersi](https://www.youtube.com/watch?v=BnpB3GrpsfM) ilginizi Ã§ekebilir. Bu eÄŸitim, Pieter Abbeel'in derin gÃ¶zetimsiz Ã¶ÄŸrenme tekniklerini anlattÄ±ÄŸÄ± hala devam eden [dersinin](https://sites.google.com/view/berkeley-cs294-158-sp20/home) bir parÃ§asÄ± olarak verilmiÅŸti.

\\
![](https://cdn-images-1.medium.com/max/800/1*GUxoCXqhozkp_aaRxpT3Sg.png)

\\
***Python Numpy Rehberi(Jupyter ve Colab'lÄ±)***

\\
Stanford'un popÃ¼ler Ã§evrimiÃ§i GÃ¶rsel TanÄ±ma iÃ§in EvriÅŸimsel Sinir AÄŸlarÄ±(Convolutional Neural Network for Visual Recognition) dersi, Numpy'ye [giriÅŸ rehberi]() iÃ§in artÄ±k Google Colab'a bir baÄŸlantÄ± iÃ§ermektedir. OldukÃ§a geniÅŸ bir rehber; ancak yeni baÅŸlayanlar iÃ§in olukÃ§a iyidir.

\\
***Yeni mobil sinir aÄŸÄ± mimarisi***

\\
Mobil ve hafif istemciler iÃ§in sinir aÄŸlarÄ± inÅŸa etmeye ilginiz varsa ÅŸu kapsamlÄ± [blog gÃ¶nderisi](https://machinethink.net/blog/mobile-architectures/) sizin iÃ§in olabilir. Bu makale birÃ§ok yapay sinir aÄŸÄ± tasarÄ±mÄ±nÄ± ve hÄ±z performans testlerini kapsamaktadÄ±r.

\\
***Veri-TabanlÄ± CÃ¼mle BasitleÅŸtirme: Derleme ve KÄ±yaslama***

\\
CÃ¼mle basitleÅŸtirme (Ä°ng. sentence simplification), bu gÃ¼nlerin baskÄ±n paradigmasÄ±, bir cÃ¼mleyi deÄŸiÅŸime uÄŸratarak okumayÄ± ve anlamayÄ± daha kolay hale getirmeyi amaÃ§lamaktadÄ±r. Åu [derleme bildirisi](https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00370), Ä°ngilizce'de orijinal-basitleÅŸtirilmiÅŸ ÅŸeklinde cÃ¼mle Ã§iftlerinden oluÅŸan bir derlem kullanarak nasÄ±l basitleÅŸtirme yapÄ±lacaÄŸÄ±nÄ± Ã¶ÄŸrenme giriÅŸimi yaklaÅŸÄ±mlarÄ±na odaklanmaktadÄ±r. AyrÄ±ca farklÄ± yaklaÅŸÄ±mlarÄ±n, karÅŸÄ±laÅŸtÄ±rma ve gÃ¼Ã§lÃ¼ ve kÄ±sÄ±tlÄ± yÃ¶nlerini Ã¶n plana Ã§Ä±karmak gibi farklÄ± veri setleri Ã¼zerinde kÄ±yaslamalarÄ±nÄ± da iÃ§ermektedir.

\\
***Makine Ã–ÄŸrenmesinde Ä°leri Konu BaÅŸlÄ±klarÄ±***

\\
Yisong Yue [Veri-TabanlÄ± Algoritma TasarÄ±mÄ±](https://sites.google.com/view/cs-159-spring-2020/lectures?authuser=0) dersinin bÃ¼tÃ¼n ders videolarÄ±nÄ± yayÄ±mladÄ±. Ders, Bayesian optimizasyonu, tÃ¼revlenebilir hesaplama (Ä°ng. differentiable computation) ve taklit Ã¶ÄŸrenme(Ä°ng. imitation learning) gibi makine Ã¶ÄŸrenmesinde ileri konu baÅŸlÄ±klarÄ±nÄ± iÃ§ermektedir.

\\
![](https://cdn-images-1.medium.com/max/800/1*8YFTbEPUw3Bqio70xP0WXQ.png)

# Bunlara da gÃ¶z atÄ±n â­ï¸

Ã–nceki NLP Haber BÃ¼lteni sayÄ±larÄ±na [buradan](https://github.com/dair-ai/nlp_newsletter) eriÅŸebilirsiniz.

\\
Harvard, birÃ§ok kendi kendinize Ã§alÄ±ÅŸabileceÄŸiniz Ã§evrimiÃ§i kurslarÄ±nÄ± Ã¼cretsiz olarak [sunmaktadÄ±r](https://online-learning.harvard.edu/catalog?keywords=&paid%5B1%5D=1&max_price=&start_date_range%5Bmin%5D%5Bdate%5D=&start_date_range%5Bmax%5D%5Bdate%5D=).

\\
[ARBML](https://github.com/zaidalyafeai/ARBML), web, komut satÄ±rÄ± ve notebook gibi birÃ§ok arayÃ¼z ile gerÃ§ek zamanlÄ± deneyim ÅŸansÄ± sunarak ArapÃ§a NLP ve makine Ã¶ÄŸrenmesi projelerinin implementasyonlarÄ±nÄ± saÄŸlamaktadÄ±r.

\\
[NLP Kontol Paneli(NLP Dashboard)](https://nlpdashboard.com), haber hikayelerinin ve metinlerin istatistiksel analizi ve varlÄ±k ismi tanÄ±ma (Ä°ng. named entity recognition) iÅŸlemlerinin yapÄ±labileceÄŸi eÄŸlenceli bir web uygulamasÄ±dÄ±r. spaCy, Flask ve Python ile geliÅŸtirilmiÅŸtir.

\\
EÄŸer gÃ¶z gezdirmediyseniz Connor Shorten, ilginÃ§ ve gÃ¼ncel makine Ã¶ÄŸrenmesi bildirilerini Ã¶zetlediÄŸi ÅŸu bilgilendirici [YouTube kanalÄ±nÄ±](https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw?sub_confirmation=1) sÃ¼rdÃ¼rmektedir. Her Ã§alÄ±ÅŸmanÄ±n kÄ±sa, Ã¶z ve muhteÅŸem Ã¶zetlerini saÄŸlarken Ã¶nemli detaylarÄ±nÄ± da iÅŸlemektedir. AyrÄ±ca alandaki diÄŸer araÅŸtÄ±rmacÄ±lar ile bir de [podcast](https://www.youtube.com/channel/UCMLtBahI5DMrt0NPvDSoIRQ) yayÄ±nÄ± baÅŸlattÄ±.

\\
[Ä°ÅŸte](https://github.com/microsoft/nlp-recipes) metin sÄ±nÄ±flandÄ±rma, metinsel doÄŸrulama(Ä°ng. textual entailment), metin Ã¶zetleme ve soru cevaplama gibi NLP iÅŸlemlerinin en iyi yÃ¶ntemlerini ve Ã¶nerileri (notebook'lar ve aÃ§Ä±klamalar ile birlikte) saÄŸlayan etkileyici, zengin bir repo.

----------

EÄŸer NLP Haber BÃ¼lteni'nin bir sonraki sayÄ±sÄ±nda paylaÅŸmak istediÄŸiniz gÃ¼ncel veri seti, proje, blog gÃ¶nderisi, rehber ya da bildiri varsa lÃ¼tfen ÅŸu [formu](https://forms.gle/3b7Q2w2bzsXE6uYo9) doldurarak direkt gÃ¶nderiniz.

\\
*ğŸ”– Gelecek sayÄ±larÄ± gelen kutunuzda gÃ¶rmek iÃ§in NLP Haber BÃ¼lteni'ne* [*abone olun*](https://dair.ai/newsletter/).
