---
layout: post
title: "NLP Haber BÃ¼lteni #9 [TR]: GÃ¶rselleÅŸtirilmiÅŸ GNN Rehberi, TextVQA ve TextCaps, KeraStroke, SyferText, torchlayersâ€¦"
author: harunuz
excerpt: "Bu sayÄ±, mahremiyeti korumaya yÃ¶nelik NLP araÃ§larÄ±, COVID-19 ile ilgili bildirileri araÅŸtÄ±rmak iÃ§in etkileÅŸimli araÃ§lar ve Ã§izge sinir aÄŸlarÄ± iÃ§in illÃ¼strasyon destekli rehber gibi konu baÅŸlÄ±klarÄ±nÄ± iÃ§ermektedir."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_9.png
---


![](https://cdn-images-1.medium.com/max/1200/1*Vq-bFSTjqYjDGAR4Ja1abw.png)

\\
NLP Haber BÃ¼lteni'nin 9. sayÄ±sÄ±na hoÅŸ geldiniz. UmarÄ±z siz ve sevdikleriniz iyi ve gÃ¼vendesinizdir. Bu sayÄ±, mahremiyeti korumaya yÃ¶nelik bir NLP aracÄ±ndan COVID-19'la ilgili bildirileri bulabilmek iÃ§in geliÅŸtirilmiÅŸ etkileÅŸimli araÃ§lara ve Ã§izge sinir aÄŸlarÄ± oluÅŸturmaya yÃ¶nelik illÃ¼strasyon destekli bir kÄ±lavuza kadar uzanan konularÄ± iÃ§ermektedir. 


# AraÅŸtÄ±rma and YayÄ±nlar ğŸ“™

***Kendi-Yorumlayabilen AjanlarÄ±n NÃ¶roevrimi***

\\
[Burada](https://attentionagent.github.io/) (Tang et al. 2020), bir gÃ¶revi sÃ¼rdÃ¼rebilmek hedefiyle bir gÃ¶rsel girdi parÃ§asÄ±ndan  yararlanabilen bir ajan geliÅŸtirmeyi amaÃ§layan (Ã¶rn; aÅŸaÄŸÄ±daki ÅŸekilde gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi virajlarÄ± Ã§arpmadan geÃ§ebilmek veya kurÅŸunlardan kaÃ§Ä±nabilmek iÃ§in) ilginÃ§ ve yaratÄ±cÄ± bir Ã§alÄ±ÅŸma sunuluyor. Ã‡alÄ±ÅŸmayÄ± yapanlar, girdilerin sadece bir parÃ§asÄ±nÄ± kullanma kÄ±sÄ±tÄ± altÄ±nda farklÄ± gÃ¶revleri icra edebilmek iÃ§in takviyeli Ã¶ÄŸrenme ajanlarÄ±nÄ±, self-attention yapÄ±larÄ± eÄŸitebilmek iÃ§in NÃ¶roevrim'i ([neuroevolution](https://en.wikipedia.org/wiki/Neuroevolution)) kullanarak, eÄŸitmeyi baÅŸardÄ±lar. Modelin faydalarÄ± arasÄ±nda; parametrelerin boyutunda Ã¶nemli bir azalma, hareket tarzÄ± yorumlanabilirliÄŸi ve modelin sadece *gÃ¶rev aÃ§Ä±sÄ±ndan kritik gÃ¶rsel ipuÃ§larÄ±nÄ±n deÄŸerlendirmesini saÄŸlamak* yer alÄ±yor.

\\
![](https://cdn-images-1.medium.com/max/800/1*Gm8jlCUvP_JECEPspDypWg.png)

\\
***RONEC'e GiriÅŸ:â€Šthe Romanian Named Entity Corpus***

\\
[RONEC](https://arxiv.org/abs/1909.01247), Rumen dili iÃ§in, 16 farklÄ± sÄ±nÄ±fa ait ~5000 aÃ§Ä±klamalÄ± cÃ¼mlede 26000'den fazla varlÄ±k iÃ§eren, adlandÄ±rÄ±lmÄ±ÅŸ bir varlÄ±k derlemidir (corpus). CÃ¼mleler, Ã§eÅŸitli biÃ§imleri kapsayan, telifsiz bir gazeteden alÄ±nmÄ±ÅŸtÄ±r. Bu derlem, Romence dil alanÄ±ndaki, Ã¶zellikle adlandÄ±rÄ±lmÄ±ÅŸ varlÄ±k tanÄ±ma amaÃ§lÄ± ilk giriÅŸimidir. Derlemin BIO ve CoNLL-U Plus formatlarÄ± da mevcut ve [burada](https://github.com/dumitrescustefan/ronec) eriÅŸilen bu derlemi kullanmak ve geniÅŸletmek serbettir.

\\
***Yapay Sinir Modelleri Ä°Ã§in Ã–lÃ§ekleme KanunlarÄ±***

\\
John Hopkins ve OpenAI'den araÅŸtÄ±rmacÄ±lar, dil modeli performansÄ± iÃ§in Ã¶lÃ§ekleme yasalarÄ±nÄ± (scaling laws) anlamak iÃ§in ampirik bir [Ã§alÄ±ÅŸma](https://arxiv.org/abs/2001.08361) yaptÄ±lar. Bu tÃ¼r bir Ã§alÄ±ÅŸma, kaynaklarÄ±n nasÄ±l daha etkin kullanÄ±lacaÄŸÄ± konusunda daha iyi kararlar almak iÃ§in bir rehber niteliÄŸinde. Genel olarak, daha bÃ¼yÃ¼k modellerin Ã¶rneklem aÃ§Ä±sÄ±ndan belirgin ÅŸekilde daha verimli olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼. EÄŸer veri veya hesaplamalar limitliyse, kÃ¼Ã§Ã¼k bir modeli eÄŸitmek yerine bir bÃ¼yÃ¼k modelin yakÄ±nsama gerÃ§ekleÅŸene kadar birkaÃ§ aÅŸamalÄ± ÅŸekilde eÄŸitilmesi daha iyidir (aÅŸaÄŸÄ±daki ÅŸekilde Ã¶zetlenen sonuÃ§lara gÃ¶z atÄ±n). AraÅŸtÄ±rmacÄ±lar, aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting), optimum yÄ±ÄŸÄ±n boyutu seÃ§me, ince-ayarlama, mimari seÃ§imi vb. aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k dil modellerinin eÄŸitimiyle ilgili (Ã¶rn; TransformatÃ¶rler) birÃ§ok bulgu ve Ã¶neri sunuyorlar. 

\\
![](https://cdn-images-1.medium.com/max/800/1*plbjqswVe4Cq8UVggqPH1w.png)

[*Kaplan et al. (2020)*](https://arxiv.org/abs/2001.08361)

\\
***Ã–n-eÄŸitim'e Tabi TutulmuÅŸ TransformatÃ¶rlerin Kalibrasyonu***

\\
Ã–n-eÄŸitim'e tabi tutulmuÅŸ transformatÃ¶rlerin pratik uygulamalarÄ±nÄ±n artÄ±ÅŸÄ±yla birlikte, bu transformatÃ¶rlerin ne denli *gÃ¼venilir* Ã§Ä±ktÄ±lar verdiklerini anlamak Ã¶nem kazandÄ±. UT Austin tarafÄ±ndan yapÄ±lan son [Ã§alÄ±ÅŸma](https://arxiv.org/abs/2003.07892), BERT ve RoBERTaâ€™nÄ±n posterior olasÄ±lÄ±klarÄ±nÄ±n hem alan (domain) iÃ§i hem de alan dÄ±ÅŸÄ± zorlu veri kÃ¼meleriyle Ã¼Ã§ gÃ¶revde (doÄŸal dil Ã§Ä±karÄ±mÄ±, yorumlama algÄ±lama, saÄŸduyulu akÄ±l yÃ¼rÃ¼tme) nispeten kalibre edildiÄŸini (yani ampirik sonuÃ§larla tutarlÄ±) gÃ¶stermektedir. SonuÃ§lar ÅŸunu gÃ¶stermektedir: (1) hazÄ±r olarak kullanÄ±ldÄ±ÄŸÄ±nda, Ã¶n-eÄŸitim'e tabi tutulmuÅŸ modeller alan iÃ§inde kalibre edilmiÅŸtir; ve (2) sÄ±caklÄ±k Ã¶lÃ§eklendirme (temperature scaling), alan iÃ§i kalibrasyon hatasÄ±nÄ± daha da azaltmada etkilidir, ampirik belirsizliÄŸi artÄ±rmak iÃ§in etiket yumuÅŸatma, posteriorlarÄ± alan dÄ±ÅŸÄ±nda kalibre etmeye yardÄ±mcÄ± olur.

\\
![](https://cdn-images-1.medium.com/max/800/1*ose0s-G0WfPFoleZJ1htrQ.png)

[*Desai ve Durrett (2020)*](https://arxiv.org/pdf/2003.07892.pdf)

\\
***Derin Ã–ÄŸrenmenin Ä°statistiksel MekaniÄŸi***

\\
YakÄ±n tarihli bir [bildiri](https://www.annualreviews.org/doi/abs/10.1146/annurev-conmatphys-031119-050745)de fiziksel / matematiksel konular ile derin Ã¶ÄŸrenme arasÄ±ndaki baÄŸlantÄ±ya daha yakÄ±ndan bakÄ±lÄ±yor. AraÅŸtÄ±rmacÄ±lar, istatistiksel mekanik ve makine Ã¶ÄŸrenimi ile kesiÅŸen daha derin konularÄ±, derin sinir aÄŸlarÄ±nÄ±n teorik yÃ¶nÃ¼nÃ¼ ve neden baÅŸarÄ±lÄ± olduklarÄ±nÄ± anlamaya yardÄ±mcÄ± olan sorularÄ± yanÄ±tlamak amacÄ±yla tartÄ±ÅŸmayÄ± amaÃ§lamaktalar.

\\
***KonuÅŸmanÄ±n Metne Ã‡evrimi'nde Bir ImageNet BaÅŸarÄ±mÄ±na DoÄŸru***

\\
The Gradient'de yayÄ±mlanan yeni bir [makale](https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/)de Alexander Veysov Rus Dili baÄŸlamÄ±nda neden ImageNet baÅŸarÄ±mÄ±na ulaÅŸÄ±lmÄ±ÅŸ olabileceÄŸine inandÄ±klarÄ±nÄ± anlatÄ±yor. Son birkaÃ§ yÄ±ldÄ±r, araÅŸtÄ±rmacÄ±lar NLP konusunda da benzer ifadelerde  bulunuyorlar. Yine de, KonuÅŸmanÄ±n Metne Ã‡evrimi'nde bÃ¶yle bir baÅŸarÄ±ma ulaÅŸmak iÃ§in, Alexander, modelleri yaygÄ±n olarak kullanÄ±labilir hale getirmek, hesaplama gereksinimlerini en aza indirmek ve Ã¶n-eÄŸitim'e tabi tutulmuÅŸ bÃ¼yÃ¼k modellerin eriÅŸilebilirliÄŸini artÄ±rmak gibi birÃ§ok parÃ§anÄ±n bir araya gelmesi gerektiÄŸini belirtiyor.


# YaratÄ±cÄ±lÄ±k, Etik ve Toplum ğŸŒ

***COVID-19 Ä°le Ä°lgili YayÄ±nlarÄ± Taramak***

\\
GeÃ§en hafta COVID'le ilgili bildirilerin bulunduÄŸu [CORD-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) olarak isimlendirilen herkese aÃ§Ä±k bir veri setinden bahsetmiÅŸtik. Gabriel Sarti, [SciBERT ince-ayar'a tabi tutulmuÅŸ model](https://huggingface.co/gsarti/scibert-nli)'inden yararlanarak, bu bildirileri daha iyi inceleyebilmeniz iÃ§in etkileÅŸimli bir araÃ§ geliÅŸtirdi. Araca [buradan](https://github.com/gsarti/covid-papers-browser) eriÅŸebilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/0*tu8nzUIEuSizuW5-.gif)

\\
DiÄŸer yandan reciTAL, araÅŸtÄ±rmacÄ±larÄ±n ve saÄŸlÄ±k uzmanlarÄ±nÄ±n COVID-19 ile ilgili bilgileri hÄ±zlÄ± ve verimli bir ÅŸekilde bulmalarÄ±na ve keÅŸfetmelerine yardÄ±mcÄ± olmak amacÄ±yla ilgili makalelerde arama ve gÃ¶z atmaya Ã¶zelleÅŸmiÅŸ [COVID-19 AkÄ±llÄ± Arama Motoru](https://covidsmartsearch.recital.ai/) adlÄ± bir proje de yayÄ±nladÄ±.

\\
![](https://cdn-images-1.medium.com/max/800/1*Y5W3sib4y6UxSr3YkQSu5Q.png)

\\
***SyferText***

\\
OpenMind, gizli veri setleri iÃ§in mahremiyeti korumaya yÃ¶nelik gÃ¼venli ve Ã¶zel NLP iÅŸlemlerinin yapÄ±lmasÄ±nÄ± hedefleyen yeni NLP kÃ¼tÃ¼phanesi [SyferText](https://github.com/OpenMined/SyferText)'i yayÄ±nladÄ±. Ã‡alÄ±ÅŸma henÃ¼z erken evrelerinde; ancak bunun daha etik ve gÃ¼venli AI sistemleri iÃ§in harcanmÄ±ÅŸ Ã¶nemli bir efor olduÄŸuna inanÄ±yoruz. BaÅŸlamak iÃ§in [ÅŸurada](https://github.com/OpenMined/SyferText/tree/master/tutorials) birkaÃ§ rehber bulabilirsiniz.


\\
***Daha ucuz, daha hÄ±zlÄ± ve daha Ã§evreci NLP iÃ§in daha kÃ¼Ã§Ã¼k modellere doÄŸru***

\\
Daha bÃ¼yÃ¼k modeller her zaman daha mÄ± iyidir? GeÃ§tiÄŸimiz birkaÃ§ yÄ±ldaki dil modeli boyutlarÄ±nÄ±n evriminine bakÄ±lÄ±rsa, bu soru evet diye cevaplanabilir; ancak bu canavarlarÄ± eÄŸitmenin finansal ve Ã§evresel maliyeti oldukÃ§a yÃ¼ksek. AyrÄ±ca, bu durumda daha bÃ¼yÃ¼k genellikle daha yavaÅŸ anlamÄ±na gelmektedir ve hÄ±z birÃ§ok uygulamada hayati Ã¶nem taÅŸÄ±maktadÄ±r. Bu da NLP'deki gidiÅŸatÄ±, mevcut performansÄ± korurken daha kÃ¼Ã§Ã¼k, daha hÄ±zlÄ± ve daha Ã§evreci modeller iÃ§in uÄŸraÅŸmaya motive etmektedir. Åu blog gÃ¶nderisinde, [Manuel Tonneau](https://www.linkedin.com/in/ACoAABs605YB_jMmGA0iLFongpVm1iKjFmKLSts/), kÃ¼Ã§Ã¼k modelleri tercih eden bu yeni akÄ±mÄ±, gÃ¼ncel ve popÃ¼ler Ã¼Ã§ modele odaklanarak tanÄ±tmaktadÄ±r: [HuggingFace](https://www.linkedin.com/in/ACoAABs605YB_jMmGA0iLFongpVm1iKjFmKLSts/)'den DistilBERT, [Google](https://www.linkedin.com/company/google/)'dan PD-BERT ve [Microsoft](https://www.linkedin.com/company/microsoft/)'tan BERT-of-Theseus.


\\
***Bilimsel keÅŸif iÃ§in Derin Ã–ÄŸrenme Ãœzerine Derleme***

\\
GÃ¼nÃ¼mÃ¼zde yapay zeka araÅŸtÄ±rmalarÄ± Ã¼zerine odaklanmÄ±ÅŸ birÃ§ok ÅŸirket, derin Ã¶ÄŸrenmenin bilimsel keÅŸiflerde bir araÃ§ olarak kullanÄ±labileceÄŸine inanmaktadÄ±r. Åu [bildiri](https://arxiv.org/abs/2003.11755), farklÄ± bilimsel kullanÄ±m senaryolarÄ± iÃ§in yaygÄ±n olarak kullanÄ±lan derin Ã¶ÄŸrenme modelleri Ã¼zerine kapsamlÄ± bir genel bakÄ±ÅŸ saÄŸlamaktadÄ±r. AynÄ± zamanda geliÅŸtirme ipuÃ§larÄ±, rehberler, farklÄ± araÅŸtÄ±rma Ã¶zetleri ve araÃ§lar da tanÄ±tmaktadÄ±r.


# AraÃ§lar ve Veri Setleri âš™ï¸

***TextVQA ve TextCaps***

\\
GÃ¶rÃ¼ntÃ¼lerdeki metinleri daha iyi tespit edip okuyan modeller geliÅŸtirmeyi ve bu modelleri soru cevaplama, altyazÄ± oluÅŸturma gibi iÅŸlemlerde kullanmayÄ± teÅŸvik etme amacÄ±yla, Facebook AI iki adet yarÄ±ÅŸmaya ev sahipliÄŸi yapmaktadÄ±r. YarÄ±ÅŸmalarÄ±n isimleri [TextVQA](https://textvqa.org/challenge) Challenge ve [TextCaps](https://textvqa.org/textcaps/challenge) Challenge; sÄ±rasÄ±yla gÃ¶rsel soru cevaplama ve altyazÄ± Ã¼retme gÃ¶revlerine hitap etmektedirler.

\\
***KeraStroke***

\\
Bir sinir aÄŸÄ± tasarlarken Ã¼stesinden gelinmesi gereken en bÃ¼yÃ¼k gÃ¼Ã§lÃ¼klerden birisi aÅŸÄ±rÄ± Ã¶ÄŸrenmedir (overfitting). Dropout, Regularization ve erken durdurma gibi gÃ¼ncel genelleÅŸtirme-geliÅŸtirme teknikleri birÃ§ok kullanÄ±m senaryosunda oldukÃ§a etkilidir; ancak bÃ¼yÃ¼k modeller ya da kÃ¼Ã§Ã¼k veri setleri kullanÄ±ldÄ±ÄŸÄ±nda yetersiz kalma eÄŸilimindedirler. Bu duruma cevap olarak, Charles Averill, bÃ¼yÃ¼k modeller ya da kÃ¼Ã§Ã¼k veri setlerinde oldukÃ§a kullanÄ±ÅŸlÄ± yeni bir genelleÅŸtirme-geliÅŸtirme tekniÄŸi [KeraStroke](https://pypi.org/project/kerastroke/#description)'u geliÅŸtirdi. Bu teknik sayesinde eÄŸitim esnasÄ±ndaki belirli durumlarda aÄŸÄ±rlÄ±k deÄŸerlerini deÄŸiÅŸtirerek, modeller aldÄ±klarÄ± eÄŸitim verisine dinamik olarak adapte olabilmektedirler.


\\
***torchlayers***

\\
[torchlayers](https://github.com/szymonmaszke/torchlayers), torch.nn modÃ¼lÃ¼nde bulunan evriÅŸimli aÄŸ, tekrarlayan aÄŸ, transformatÃ¶r vb. katmanlarÄ±nÄ±n biÃ§im ve boyutlarÄ±nÄ±n otomatik anlamlandÄ±rÄ±lmasÄ±na olanak saÄŸlayan PyTorch'un Ã¼zerine kurulmuÅŸ yeni bir araÃ§tÄ±r. Bu sayede katmanlarda elle belirtilmesi gereken girdi Ã¶zelliklerinin (input features) boyutlarÄ±nÄ± aÃ§Ä±kÃ§a tanÄ±mlamaya gerek kalmamaktadÄ±r. PyTorch'ta bir modelin tanÄ±mlanmasÄ± oldukÃ§a basitleÅŸmektedir. torchlayers ile gerÃ§eklenmiÅŸ basit bir sÄ±nÄ±flandÄ±rÄ±cÄ± Ã¶rneÄŸini aÅŸaÄŸÄ±da gÃ¶rebilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/1*tHOme2pZ39sNziqdUCsn4g.png)

*Kod parÃ§asÄ±ndan gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere Linear katman hem output hem de input boyutunun aksine yalnÄ±zca output boyutunun belirtilmesine ihtiyaÃ§ duymaktadÄ±r. Input boyutu torchlayers tarafÄ±ndan otomatik bir ÅŸekilde Ã§Ä±karÄ±lmaktadÄ±r.*


\\
***Haystack: FarklÄ± Ã–lÃ§eklerde Soru Cevaplama iÃ§in AÃ§Ä±k KaynaklÄ± kÃ¼tÃ¼phane***

\\
[Haystack](https://github.com/deepset-ai/haystack/), farklÄ± Ã¶lÃ§eklerde soru cevaplama iÃ§in transformatÃ¶r modellerinin kullanÄ±lmasÄ±na olanak saÄŸlamaktadÄ±r. Bulucu-Okuyucu-Pipeline'Ä±nÄ± (Retriever-Reader-Pipeline) kullanmaktadÄ±r. Bu yaklaÅŸÄ±mda Bulucu, aday belgeleri bulan hÄ±zlÄ± bir algoritma; Okuyucu ise cevabÄ± parÃ§a parÃ§a Ã§Ä±karan bir transformatÃ¶rdÃ¼r. Elasticsearch ve HuggingFace'in Transformers kÃ¼tÃ¼phanesi Ã¼zerine kurulmuÅŸtur. AÃ§Ä±k kaynaklÄ±, oldukÃ§a modÃ¼ler ve kolay geniÅŸletilebilir bir yapÄ±dadÄ±r.


\\
***Bir yapay zekaya haber makalelerini Ã¶zetlemeyi Ã¶ÄŸretmek: SoyutlayÄ±cÄ± Ã¶zetleme iÃ§in yeni bir veri seti***

\\
Curation Corp 40.000 adet profesyonelce yazÄ±lmÄ±ÅŸ haber makalesi Ã¶zetlerini aÃ§Ä±k kaynak olarak kullanÄ±ma sundu. Bu [makale](https://medium.com/curation-corporation/teaching-an-ai-to-abstract-a-new-dataset-for-abstractive-auto-summarisation-5227f546caa8), metin Ã¶zetleme ve iÅŸlemin zorluklarÄ±na gÃ¼zel bir giriÅŸ saÄŸlamaktadÄ±r. Ek olarak, veri setini ve veri seti ile ele anÄ±labilecek problemleri tanÄ±tmaktadÄ±r, metin Ã¶zetlemede deÄŸerlendirme metrikleri ve ince ayar(fine-tuning) teknikleri Ã¼zerine bir tartÄ±ÅŸmayÄ± iÃ§ermektedir. Gelecek Ã§alÄ±ÅŸmalar Ã¼zerine bir tartÄ±ÅŸma ile de makale sonlanmaktadÄ±r. Veri setine nasÄ±l eriÅŸileceÄŸine dair aÃ§Ä±klamalar ÅŸu [GitHub reposunda](https://github.com/CurationCorp/curation-corpus), veri setini ince ayar iÅŸlemlerinde kullanmak iÃ§in Ã¶rnek Ã§alÄ±ÅŸmalar da [burada](https://github.com/CurationCorp/curation-corpus/tree/master/examples) bulunabilir.

\\
Metin Ã¶zetleme konusunda, HuggingFace takÄ±mÄ± [Transformers](https://github.com/huggingface/transformers/releases) kÃ¼tÃ¼phanelerinin bir parÃ§asÄ± olarak [BART](https://github.com/pytorch/fairseq/blob/master/examples/bart/README.md) ve [T5](https://github.com/dair-ai/nlp_paper_summaries/blob/master/Language%20Modeling/t5-text-to-text-transformer.md)'i eklediler. Bu eklemeler soyutlayÄ±cÄ± Ã¶zetleme, Ã§eviri ve soru cevaplama ve daha birÃ§ok NLP iÅŸleminin gerÃ§eklenmesine olanak saÄŸlamaktadÄ±r.


# Makaleler ve Blog gÃ¶nderileri âœï¸

***Ä°llÃ¼strasyon Destekli Ã‡izge Sinir AÄŸlarÄ±(Graph Neural Networks) Rehberi***

\\
Ã‡izge sinir aÄŸlarÄ± son zamanlarda ilaÃ§ kullanÄ±mÄ±nÄ±n yan etkilerini tahmin etme ve bilgisayarla gÃ¶rÃ¼ modellerinin baÅŸarÄ±mÄ±nÄ± artÄ±rma gibi birÃ§ok iÅŸlemde benimsenmiÅŸ vaziyettedirler. Åu [yazÄ±da](https://dair.ai/An_Illustrated_Guide_to_Graph_Neural_Networks/), Rish, Ã§izge sinir aÄŸlarÄ±na(GNN) resimli bir kullanÄ±ÅŸlÄ± rehber ortaya koymaktadÄ±r. (*[*dair.ai*](https://dair.ai/)'da Ã¶ne Ã§Ä±kanlar*)

\\
![](https://cdn-images-1.medium.com/max/800/1*Ru3CizrB14hvpZQ7ZtgIag.png)

\\
***JAX ve Haiku ile Transformer'lara ince ayar(Fine-tuning)***

\\
GeÃ§tiÄŸimiz ay DeepMind, kendi TensorFlow yapay sinir aÄŸÄ± kÃ¼tÃ¼phaneleri olan Sonnet'in JAX versiyonu Haiku'yu aÃ§Ä±k kaynaklÄ± olarak kullanÄ±ma sundu. Åu [gÃ¶nderi](https://www.pragmatic.ml/finetuning-transformers-with-jax-and-haiku/) Ã¶n-eÄŸitime tabi tutulmuÅŸ RoBERTa modelinin JAX + Haiku'ya aÃ§Ä±lan kapÄ±sÄ± olan kaynak kodun Ã¼zerinden geÃ§mektedir. ArdÄ±ndan modeli ince ayara tabi tutarak bir alt gÃ¶revi(downstream task) Ã§Ã¶zmeyi gÃ¶stermektedir. GÃ¶nderinin, dÃ¼ÅŸÃ¼k maliyetli nesne tabanlÄ± modÃ¼llerin JAX'Ä±n fonksiyonel programlama kÄ±sÄ±tlamalarÄ± baÄŸlamÄ±nda kullanÄ±lmasÄ±na olanak saÄŸlamak iÃ§in Haiku'nun ortaya koyduklarÄ±ndan faydalanmayÄ± gÃ¶steren kullanÄ±ÅŸlÄ± bir rehber olmasÄ± amaÃ§lanmaktadÄ±r.

\\
***DoÄŸal Dil Ä°ÅŸleme vadisinde kÃ¼Ã§Ã¼k bir gezinti: Metin Ã¶niÅŸleme ve Almanca***

\\
FlÃ¡vio ClÃ©sio, Almanca'da NLP sorunlarÄ±yla baÅŸa Ã§Ä±karken karÅŸÄ±laÅŸÄ±lan zorluklarÄ± anlatan oldukÃ§a detaylÄ± bir [makale](https://flavioclesio.com/2020/02/17/a-small-journey-in-the-valley-of-natural-language-processing-and-text-pre-processing-for-german-language/) yazdÄ±. YazÄ±sÄ±nda, Ã¶ÄŸrendiÄŸi dersleri, nelerin iÅŸe yarayÄ±p nelerin yaramadÄ±ÄŸÄ±nÄ±, birÃ§ok state-of-the-art tekniÄŸin tartÄ±ÅŸmasÄ±nÄ±, kaÃ§Ä±nÄ±lmasÄ± gereken yaygÄ±n hatalarÄ± ve bildiriler, bloglar gibi tonlarca Ã¶ÄŸrenme kaynaklarÄ± paylaÅŸmaktadÄ±r. 

\\
***FransÄ±zca yapay zekaya ayak uyduruyor: FlauBERT, CamemBERT, PIAF***

\\
GeÃ§tiÄŸimiz birkaÃ§ ayda, ilgi Ã§ekici FransÄ±zca NLP kaynaklarÄ± geliÅŸtirildi. CamemBERT, FlauBERT ve PIAF(Pour une IA Francophone, FransÄ±zca KonuÅŸan bir AI iÃ§in)'dan bahsetmekteyiz. Ä°lk iki model Ã¶n-eÄŸitime tabi tutulmuÅŸ dil modelleridir; sonuncu ise FransÄ±zca soru-cevap(QA) veri setidir. Åu [blog gÃ¶nderisi](https://piaf.etalab.studio/francophonie-ia-english/), Ã¼Ã§ projeyi ve projelerin sÃ¼reÃ§lerinde karÅŸÄ±laÅŸÄ±lan bazÄ± zorluklarÄ± ele almaktadÄ±r. Kendi dillerinde farklÄ± modeller Ã¼zerinde Ã§alÄ±ÅŸan insanlar iÃ§in gÃ¼zel bir yazÄ± ve rehber niteliÄŸi taÅŸÄ±maktadÄ±r.


\\
***BERT-tarzÄ± dil modeli iÃ§in Ã¶zel sÄ±nÄ±flandÄ±rÄ±cÄ±***

\\
Marcin, BERT-tarzÄ± modeller Ã¼zerine kendi sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±zÄ±(duygu sÄ±nÄ±flandÄ±rÄ±cÄ± gibi) nasÄ±l inÅŸa edebileceÄŸinizi anlatan harika bir [rehber](https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/) daha yazdÄ±. OldukÃ§a gÃ¼zel bir rehber; Ã§Ã¼nkÃ¼ rehber aynÄ± zamanda modelin farklÄ± kÄ±sÄ±mlarÄ± iÃ§in HuggingFace Tokenizer ve PyTorchLightning gibi modern kÃ¼tÃ¼phaneleri nasÄ±l kullanabileceÄŸinizi de aÃ§Ä±klamaktadÄ±r. Google Colab notebook'unu [burada](https://colab.research.google.com/drive/1sajgpLTrTJDzRSlxycy8aE6ysxGqaT18) bulabilirsiniz.


\\
![](https://cdn-images-1.medium.com/max/800/0*66IKvwYU2Lq1kjyn.png)

[*Kaynak*](https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/)


# EÄŸitim ğŸ“

***Metin Verisi iÃ§in KeÅŸifsel Veri Analizi***

\\
Bu kod [Ã¶rneklerinde]((https://dair.ai/Exploratory_Data_Analysis_for_Text_Data/)), Yonathan Hadar, metinsel verinin keÅŸifsel analizi Ã¼zerine birÃ§ok tekniÄŸin Ã¼zerinden geÃ§mektedir. Bu rehbere dair.ai'da yer vermemizin sebebi veri analizinde herhangi bir veri bilimciniin faydalÄ± bulacaÄŸÄ± kabul gÃ¶rmÃ¼ÅŸ teknikleri detaylÄ± bir ÅŸekilde anlatmasÄ±dÄ±r. Metinsel veri ile uÄŸraÅŸacak birinin baÅŸlamasÄ± iÃ§in oldukÃ§a iyi bir noktadÄ±r.

\\
***DoÄŸal Dil Ä°ÅŸlemede GÃ¶mmeler***

\\
Mohammed Taher Pilehvar ve Jose Camacho-Collados, "Embeddings in Natural Language Processing (DoÄŸal Dil Ä°ÅŸlemede GÃ¶mmeler)" adlÄ± yeni gelecek [kitaplarÄ±nÄ±n](https://medium.com/r/?url=http%3A%2F%2Fjosecamachocollados.com%2Fbook_embNLP_draft.pdf) ilk taslaÄŸÄ±nÄ± kamuya sundular. KitabÄ±n ana odak noktasÄ± NLP alanÄ±nda kullanÄ±lan en yaygÄ±n teknikleri temsil eden gÃ¶mme konseptini tartÄ±ÅŸmaktÄ±r. Yazarlar tarafÄ±ndan [belirtildiÄŸi](https://medium.com/r/?url=https%3A%2F%2Ftwitter.com%2FCamachoCollados%2Fstatus%2F1246013768074747906%3Fs%3D20) Ã¼zere, kitap "vektÃ¶r uzay modellerinin temelleri, daha gÃ¼ncel cÃ¼mleye gÃ¶re kelime gÃ¶mmeleri ve Ã¶n-eÄŸitime tabi tutulmuÅŸ modellere dayalÄ± baÄŸlamsal gÃ¶mme tekniklerini" iÃ§ermektedir.

\\
***A Brief Guide to Artificial Intelligence(Yapay Zekaya KÄ±sa Bir Rehber)***

\\
Dr. James V Stone, gÃ¼ncel AI sistemleri ve birÃ§ok gÃ¶revi yerine getirmedeki baÅŸarÄ±mlarÄ± hakkÄ±nda kapsamlÄ± bir genel bakÄ±ÅŸ saÄŸlamak amacÄ±yla yeni [kitabÄ±](https://jim-stone.staff.shef.ac.uk/AIGuide/) "A Brief Guide to Artificial Intelligence(Yapay Zekaya KÄ±sa Bir Rehber)"Ä± kÄ±sa sÃ¼re Ã¶nce yayÄ±mladÄ±. Ã–zetinde belirtildiÄŸi Ã¼zere: "kitap resmiyetten uzak bir tarzda, kapsamlÄ± bir aÃ§Ä±klayÄ±cÄ± sÃ¶zlÃ¼k ve ileride okunmasÄ± gerekenlerin listesi ile yazÄ±lmÄ±ÅŸtÄ±r; bu da kitabÄ±, hÄ±zla evrimleÅŸen AI alanÄ±na ideal bir giriÅŸ yapmaktadÄ±r.".

\\
![](https://cdn-images-1.medium.com/max/800/0*I2YYXTCQTBmk_YiF.jpg)

\\
***Makine Ã–ÄŸrenmesi ve Derin Ã–ÄŸrenme KurslarÄ±***

\\
Sebastian Raschka, "Introduction to Deep Learning and Generative Models(Derin Ã–ÄŸrenme ve Ãœretken Modellere GiriÅŸ)" adlÄ± kursunun iki [bÃ¶lÃ¼mÃ¼nÃ¼](https://www.youtube.com/watch?time_continue=1&v=QQD9Y2FiotQ&feature=emb_logo) yayÄ±nladÄ±. Ders notlarÄ±nÄ± ve materyallerini ÅŸu [repoda](https://github.com/rasbt/stat453-deep-learning-ss20) bulabilirsiniz.

\\
"AyrÄ±k Diferansiyal Geometri" alanÄ±ndaki bu muhteÅŸem [derslere](https://www.youtube.com/watch?v=e-erMrqBd1w&feature=youtu.be) gÃ¶z gezdirebilirsiniz.

\\
Peter Bloem, VU University Amsterdam'da verdikleri Makine Ã–ÄŸrenmesi'ne giriÅŸ dersinin ders sunularÄ± ve videolarÄ±nÄ± da iÃ§eren bÃ¼tÃ¼n [ders mÃ¼fredatÄ±nÄ±](https://mlvu.github.io/) yayÄ±nladÄ±. Konular, lineer modeller ve olasÄ±lÄ±ksal modellerden sÄ±ralÄ± veri modellerine kadar uzanmaktadÄ±r.

\\
***CNN YapÄ±sÄ±â€Šâ€”â€ŠUygulamalarÄ±***

\\
Dimitris Katsios, orijinal bildirilerde Ã¶nerilmiÅŸ evriÅŸimli sinir aÄŸÄ±(CNN) yapÄ±larÄ±nÄ±n nasÄ±l gerÃ§eklenebileceÄŸini anlatan bir dizi harika [rehber](https://github.com/Machine-Learning-Tokyo/CNN-Architectures/tree/master/Implementations) saÄŸlamaktadÄ±r. YazÄ±larÄ±nda, modelin yapÄ±sÄ±nÄ± Ã§Ä±karma yeterliÄŸinde, adÄ±m adÄ±m iÅŸlemleri diyagram ve kodlar ile paylaÅŸÄ±rken CNN modellerinin nasÄ±l gerÃ§ekleneceÄŸini tarif etmektedir.


# Bunlara da gÃ¶z atÄ±n â­ï¸

Bir Ã¶nceki haber bÃ¼lteninin orjinial halini [ÅŸurada](https://dair.ai/NLP_Newsletter_8/); Ã§evirilerini ise ÅŸu GitHub [reposunda](https://github.com/dair-ai/nlp_newsletter) bulabilirsiniz.

\\
Ä°ki ay Ã¶nce Luis Serrano'nun "Grokking Machine Learning(Grokking Makine Ã–ÄŸrenmesi)" adlÄ± kitabÄ±na yayÄ±nlarÄ±mÄ±zda yer vermiÅŸtik. Luis'in kendi kitabÄ± hakkÄ±ndaki fikirlerini ve makine Ã¶ÄŸrenmesi alanÄ±nda nasÄ±l iyi bir eÄŸitmen olduÄŸunu anlatan hikayesini [ÅŸuradan](https://content.alegion.com/podcast/grokking-machine-learning-with-luis-serrano) dinleyebilirsiniz.

\\
Ä°ÅŸte ilginize deÄŸebilecek birkaÃ§ haber bÃ¼lteni: [Sebastian Ruderâ€™in NLP Haberleri](http://newsletter.ruder.io/), [Made With ML(Makine Ã–ÄŸrenmesi ile YapÄ±ldÄ±](https://madewithml.com/blog/newsletter/2020-03-25/), [SIGTYPâ€™in Haber BÃ¼lteni](https://sigtyp.github.io/sigtyp-newsletter-Mar-2020.html), [MLT Haber BÃ¼lteni](https://mailchi.mp/c70ebcf424b2/mlt-newsletter-6), [Nathanâ€™Ä±n AI bÃ¼lteni](http://newsletter.airstreet.com/issues/your-guide-to-ai-in-q1-2020-part-1-2-212335), vb...

\\
Jupyter artÄ±k bir [gÃ¶rsel hata ayÄ±klayÄ±cÄ±ya](https://blog.jupyter.org/a-visual-debugger-for-jupyter-914e61716559) sahip. Bu sayede, popÃ¼ler veri bilimi aracÄ± genel amaÃ§lar iÃ§in daha kolay kullanÄ±labilir olmaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/0*FE5Fj5DFb0U9565a.gif)

\\
Abhishek Thakur, modern makine Ã¶ÄŸrenmesi ve NLP tekniklerinin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± kodlarÄ±n Ã¼zerinden geÃ§erek gÃ¶sterdiÄŸi harika bir YouTube [kanalÄ±na](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) sahip. BazÄ± videolarÄ±, BERT modellerine ince ayar yaparak el yazÄ±sÄ± karakterlerini sÄ±nÄ±flandÄ±rmaktan bir makine Ã¶ÄŸrenmesi aracÄ± inÅŸa etmeye kadar uzanmaktadÄ±r.

\\
ÃœnlÃ¼ takviyeli/pekiÅŸtirmeli Ã¶ÄŸrenme profesÃ¶rÃ¼ ve araÅŸtÄ±rmacÄ± David Silver, bilgisayar oyunlarÄ±na getirdiÄŸi Ã§Ä±ÄŸÄ±r aÃ§an yenilikler iÃ§in ACM Prize in Computing ile [Ã¶dÃ¼llendirildi](https://awards.acm.org/about/2019-acm-prize). David, Lee Sedol'u Go'da yenen Alpha Go takÄ±mÄ±na liderlik etmiÅŸti.

\\
BERT ve word2vec gibi popÃ¼ler NLP tekniklerinin Ã§alÄ±ÅŸma prensipleri arasÄ±ndaki farklarÄ± Ã¶ÄŸrenmek isteyenler iÃ§in Mohd, bu yaklaÅŸÄ±mlara harika, kolay ulaÅŸÄ±labilir ve detaylÄ± genel bakÄ±ÅŸ yazÄ±larÄ± [saÄŸlamaktadÄ±r](https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/).

\\
TensorFlow 2.2.0-rc-1 [yayÄ±nlandÄ±](https://github.com/tensorflow/tensorflow/releases/tag/v2.2.0-rc1?linkId=85073218). ML modellerinde darboÄŸaz olan noktalarÄ± tespit etmeye yardÄ±mcÄ± olan Profiler ve bu modellerin nasÄ±l optimize edileceÄŸini gÃ¶steren rehberler gibi yenilikler iÃ§ermektedir. AyrÄ±ca, Colab da artÄ±k [varsayÄ±lan](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb?linkId=85251566) olarak TensorFlow 2 kullanmaktadÄ±r.

\\
Gabriel PeyrÃ©, ML optimizasyonu dersi iÃ§in bir dizi kullanÄ±ÅŸlÄ± [not](https://mathematical-tours.github.io/book-sources/optim-ml/OptimML.pdf) saÄŸlamaktadÄ±r. Notlar, dÄ±ÅŸbÃ¼key analizi(convex analysis), SGD(rastgele gradyan iniÅŸi), autodiff(otomatik diferansiyel), MLP(Ã§ok katmanlÄ± algÄ±layÄ±cÄ±) gibi konu baÅŸlÄ±klarÄ±nÄ± iÃ§ermektedir.


----------

## dair.ai sitesinden gÃ¼ncellemeler

- ***AÃ§Ä±k Bilim iÃ§in Ä°ÅŸbirlikÃ§ilere Ã‡aÄŸrÄ±:*** AÃ§Ä±k bilime katkÄ± yapmak isteyenlere Ã§aÄŸrÄ±da bulunmaktayÄ±z. Pipeline'da birÃ§ok ilgi Ã§ekici iÅŸbirliÄŸi konusu var. Davetiyelerimizi aÃ§Ä±k bilime katkÄ±da bulunmak isteyen herkese ulaÅŸtÄ±rmak istiyoruz. GÃ¶nÃ¼llÃ¼ler, yazarlar, eleÅŸtirmenler, editÃ¶rler, geliÅŸtiriciler, konuÅŸmacÄ±lar, araÅŸtÄ±rmacÄ±lar, proje sahipleri vb. aramaktayÄ±z. [Bize katÄ±lÄ±n](https://github.com/dair-ai/dair-ai.github.io/issues/54)!

- ***NLP AraÅŸtÄ±rmasÄ±nda Ä°lginÃ§ Olaylar SayÄ± #1:*** ICYMI, ÅŸu [makalede](https://dair.ai/NLP_Research_Highlights_-_Issue_-1/), bazÄ± NLP akÄ±mlarÄ±nÄ± ve konu baÅŸlÄ±klarÄ±nÄ±, geÃ§tiÄŸimiz birkaÃ§ ayda yayÄ±mlanan ilginÃ§ ve Ã¶nemli NLP bildirilerinin hangisini,nasÄ±l ve neden seÃ§tiÄŸimizi Ã¶zetlemeye odaklanarak vurgulamaktayÄ±z.

----------
EÄŸer NLP Haber BÃ¼lteni'nin sonraki sayÄ±larÄ±nda paylaÅŸmak istediÄŸiniz veri seti, proje, blog, rehber veya bildiri varsa lÃ¼tfen ÅŸu [formu](https://forms.gle/3b7Q2w2bzsXE6uYo9) kullanarak direkt gÃ¶nderiniz.

\\
*ğŸ”–Gelen kutunuzda NLP Haber BÃ¼lteni'nin gelecek sayÄ±larÄ±nÄ± gÃ¶rmek istiyorsanÄ±z [buradan](https://dair.ai/newsletter/) abone olabilirsiniz.
