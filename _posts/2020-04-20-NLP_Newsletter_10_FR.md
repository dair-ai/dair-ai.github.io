---
layout: post
title: "NLP Newsletter #10 [FR]: Am√©liorer la reproductibilit√©  en ML, protection de la vie priv√©e et s√©curit√© en NLP, XTREME, Longformer, VilBERT, exBERT,‚Ä¶"
author: lbourdois
excerpt: "Dans ce num√©ro, nous abordons des sujets qui vont des meilleures pratiques concernant les mod√®les de langue √† la reproductibilit√© dans l'apprentissage automatique, en passant par la protection de la vie priv√©e et la s√©curit√© dans le traitement du langage naturel (NLP)"
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_10.png
---


![](https://cdn-images-1.medium.com/max/1200/1*WxbP3uKvd2GB6B-NaxtiIw.png)

# Avant-propos d‚ÄôElvis
Bienvenue au dizi√®me num√©ro de la lettre d‚Äôinformation consacr√©e au NLP.  Nous esp√©rons que vous allez bien et que vous √™tes en s√©curit√©. Dans ce num√©ro, nous abordons des sujets qui vont des meilleures pratiques concernant les mod√®les de langue √† la reproductibilit√© dans l'apprentissage automatique, en passant par le respect de la vie priv√©e et la s√©curit√© dans le traitement du langage naturel (NLP).

\\
***Quelques mises √† jour sur la lettre d‚Äôinformation sur le NLP et sur dair.ai :***

- afin de faciliter l'exploration du jeu de donn√©es [COVID-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) et afin d'obtenir des informations √† partir de la litt√©rature scientifique, nous avons publi√© un [notebook](https://github.com/dair-ai/covid_19_search_application) qui retrace les √©tapes de la conception d'une application permettant de r√©aliser une recherche de similitude de texte √† l'aide d'outils libres et de mod√®les linguistiques pr√©-entrain√©s en open-source.

- nous avons organis√© une formation virtuelle lors de la [Open Data Science Conference](https://odsc.com/boston/) la semaine derni√®re sur le th√®me ["Deep Learning for Modern NLP"](https://github.com/dair-ai/odsc_2020_nlp).

- la semaine derni√®re, nous avons aussi publi√© deux articles en collaboration avec des membres de notre communaut√©. L'un d'entre eux concerne l'[apprentissage progressif non supervis√©](https://medium.com/dair-ai/unsupervised-progressive-learning-upl-a-new-problem-for-ai-9a1c68c70a28), un probl√®me qui implique un agent qui analyse une s√©quence de vecteurs de donn√©es non labellis√©es (flux de donn√©es) et en apprend des repr√©sentations. Le second [article](https://medium.com/dair-ai/structural-scaffolds-for-citation-intent-classification-in-scientific-publications-e5acd2f0ebf9) r√©sume une approche de classification des intentions de citation utilisant ELMo.

-	Enfin nous avons r√©cemment publi√© un [notebook](https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X) qui fournit des id√©es sur la mani√®re de fine-tuner des mod√®les de langage pr√©-entrain√©s pour la t√¢che de classification des √©motions.


# Publications üìô

***XTREME : Un benchmark multit√¢che multilingue pour l'√©valuation de la g√©n√©ralisation interlinguistique***

\\
En d√©but de semaine, des chercheurs de Google AI et DeepMind ont publi√© un benchmark multit√¢che appel√© [XTREME](https://arxiv.org/abs/2003.11080) qui vise √† encourager l'√©valuation des capacit√©s de g√©n√©ralisation multilingue des mod√®les linguistiques qui apprennent des repr√©sentations multilingues. Le benchmark porte sur 40 langues et 9 t√¢ches diff√©rentes qui, collectivement, n√©cessitent de raisonner sur diff√©rents niveaux de signification, soit syntaxiquement, soit s√©mantiquement. Le document fournit √©galement des r√©sultats de r√©f√©rence en utilisant des mod√®les multilingues tels que mBERT, XLM et MMTE.

\\
![](https://cdn-images-1.medium.com/max/800/0*kk7J1fCht_VZR_su.png)

*Source:* [*Google AI Blog*](https://ai.googleblog.com/2020/04/xtreme-massively-multilingual-multi.html)

\\
***Evaluer les machines par leur utilisation r√©elle de la langue***

\\
Il a √©t√© d√©montr√© que les mod√®les linguistiques sont relativement performants pour une vari√©t√© de t√¢ches telles que la r√©ponse √† des questions et l'√©tiquetage de s√©quences. Toutefois, un nouveau [document](https://arxiv.org/abs/2004.03607) propose un framework et un benchmark pour mieux √©valuer si les mod√®les linguistiques peuvent fonctionner dans le monde r√©el avec des param√®tres plus complexes (par exemple, en g√©n√©rant des conseils utiles pour des situations courantes). Les r√©sultats empiriques montrent que les mod√®les actuels de pointe tels que le T5 g√©n√®rent des conseils aussi utiles que ceux √©crits par l'homme que dans 9 % des cas. Ces r√©sultats soulignent les lacunes des LM dans la capacit√© √† comprendre et √† mod√©liser la connaissance du monde et le raisonnement.

\\
***Donnez un peu d'amour √† vos mod√®les textuels : le cas du basque***

\\
L'entra√Ænement de mod√®les monolingues (FastText word embeddings et BERT) sur de grands ensembles de donn√©es sp√©cifiques √† une langue peut-il produire de meilleurs r√©sultats que les versions multilingues pr√©form√©es ? Dans un r√©cent [article](https://arxiv.org/abs/2004.00033), des chercheurs √©tudient l'effet et la performance de mod√®les pertinents utilisant des corpus basques plus importants. Les r√©sultats indiquent qu'en effet, le mod√®le produit de meilleurs r√©sultats sur les t√¢ches telles que la classification des sujets, la classification des sentiments et le PoS pour le basque. Il pourrait √™tre int√©ressant de v√©rifier si cela vaut pour d'autres langues et si des r√©sultats int√©ressants ou de nouveaux d√©fis pourraient se pr√©senter.

![](https://cdn-images-1.medium.com/max/800/1*rN7mNPz0os7kd8rBboliIg.png)

*Figure par* [*Agerri et al. (2020)*](https://arxiv.org/abs/2004.00033)

\\
***Faire progresser l'apprentissage auto-supervis√© et semi-supervis√© avec SimCLR***

\\
Dans un pr√©c√©dent [num√©ro](https://dair.ai/NLP_Newsletter_-5_-FR/) de la newsletter, nous avons pr√©sent√© SimCLR, une m√©thode de Google AI qui propose un cadre pour l'apprentissage *contrastif et aut-osurpervis√©* des repr√©sentations visuelles afin d'am√©liorer les r√©sultats de la classification des images dans diff√©rents contextes tels que l'apprentissage par transfert et l'apprentissage semi-supervis√©. Il s'agit d'une nouvelle approche de l'apprentissage auto et semi-supervis√© pour apprendre des repr√©sentations visuelles √† partir de donn√©es non labellis√©es. Les [r√©sultats](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html) d√©montrent qu'elle obtient des r√©sultats de pointe sur ImageNet tout en ne s'appuyant que sur 1% de donn√©es labeliss√©es, ce qui indique que la m√©thode pourrait √©galement √™tre b√©n√©fique dans des environnements √† faibles ressources.

\\
![](https://cdn-images-1.medium.com/max/800/1*kGiv7LFJW1g_R6m2XblSSA.png)

*Source:* [*Google AI Blog*](https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html)

\\
Il convient de mentionner que l'apprentissage auto-supervis√© est l'un des sujets br√ªlants dans ce domaine. Si vous souhaitez en savoir plus, vous pouvez consulter les informations suivantes:

- [Computers Already Learn From Us. But Can They Teach Themselves?](https://www.nytimes.com/2020/04/08/technology/ai-computers-learning-supervised-unsupervised.html)
- [The Illustrated Self-Supervised Learning](https://amitness.com/2020/02/illustrated-self-supervised-learning/)
- [Self-supervised learning and computer vision](https://www.fast.ai/2020/01/13/self_supervised/)


\\
***Le Byte Pair Encoding est sous-optimal pour le pr√©-entra√Ænement de mod√®les de langue***

\\
Kaj Bostrom et Greg Durrett ont publi√© un [article](https://arxiv.org/pdf/2004.03720.pdf) dans lequel ils ont propos√© une √©valuation directe de l'impact de la tokenisation sur les performances des mod√®les linguistiques. Selon les auteurs, cette question est rarement examin√©e comme on le constate dans la litt√©rature. Pour y parvenir, ils pr√©-entra√Ænent les mod√®les √† partir de z√©ro en utilisant des exp√©riences contr√¥l√©es et appliquent diff√©rentes m√©thodes de tokenization, √† savoir l'unigramme et le BPE. Ensuite, ils testent les mod√®les r√©sultants sur plusieurs t√¢ches. Les r√©sultats montrent que la tokenization unigramme √©gale ou surpasse le BPE commun.


\\
***Longformer: Le Long-Document Transformer***

\\
Les chercheurs d'Allen AI ont publi√© un nouveau mod√®le appel√© [Longformer](https://arxiv.org/abs/2004.05150) qui vise √† √™tre plus efficace sur des textes plus longs. Il est bien connu que l'une des limites des mod√®les bas√©s sur les Transformers est qu'ils sont co√ªteux en termes de calcul en raison de l'√©chelle de l'op√©ration d'auto-attention (quadratique avec la longueur de la s√©quence), ce qui limite la capacit√© √† traiter des s√©quences plus longues. R√©cemment, de nombreux efforts ont √©t√© d√©ploy√©s, tels que les mod√®les [Reformer](https://arxiv.org/abs/2001.04451) et [Sparse Transformers](https://arxiv.org/abs/1904.10509), pour permettre l'application de Transformers √† de longs documents. Le Longformer combine la mod√©lisation au niveau du caract√®re et l'auto-attention (m√©lange d'attention locale et globale) pour consommer moins de m√©moire et am√©liorer l'efficacit√© de la mod√©lisation des documents longs. Les auteurs montrent √©galement que leur mod√®le pr√©-entra√Æn√© est plus performant que d'autres m√©thodes lorsqu'il est appliqu√© √† des t√¢ches comme les questions/r√©ponses et la classification des textes.
\\
![](https://cdn-images-1.medium.com/max/800/1*uTxVqLtO_nQaDw4OedUUtQ.png)

*Figure par* [*Beltagy et al. (2020)*](https://arxiv.org/abs/2004.05150)



# Cr√©ativit√©, √©thique et soci√©t√© üåé

***Reproductibilit√© en ML***

- Afin d'encourager une science plus ouverte, plus transparente et plus accessible, de nombreux efforts ont √©t√© d√©ploy√©s autour de la reproductibilit√©. Si vous voulez comprendre o√π se situe le domaine de l'apprentissage machine en termes de reproductibilit√©, consultez cette [publication](https://arxiv.org/abs/2003.12206) de Joelle Pineau et al.

- Plus r√©cemment, et inspir√©e par ces efforts, l'√©quipe Papers With Code (qui fait maintenant partie de Facebook AI) a publi√© un [article de blog](https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501) expliquant une [liste de contr√¥le de la reproductibilit√©](https://github.com/paperswithcode/releasing-research-code) utile pour "*faciliter la recherche reproductible pr√©sent√©e lors des grandes conf√©rences sur le ML*". La liste de contr√¥le √©value la soumission des codes sur les points suivants :

![](https://cdn-images-1.medium.com/max/800/1*BQH6F1J3TE1T_GREv5xSew.png)

*Source:* [*Papiers avec code*](https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501)

- Sur ce m√™me th√®me, voici un tweet d'un chercheur en NLP [offrant](https://twitter.com/srush_nlp/status/1245825437240102913?s=20) une prime √† la personne qui sera capable de reproduire les r√©sultats d'un article qu'un autre chercheur ne parvient pas √† reproduire.

\\
***Protection de la vie priv√©e et s√©curit√© en NLP***

\\
Un mod√®le de langage pr√©-entra√Æn√© peut-il √™tre vol√© ou impose-t-il des implications en mati√®re de s√©curit√© lorsqu'il est expos√© pour √™tre utilis√© via des API ? Dans un nouvel article, les chercheurs visent √† tester les API bas√©es sur BERT pour en d√©terminer les implications en mati√®re de s√©curit√©, notamment en ce qui concerne l'utilisation de requ√™tes pour voler le mod√®le. En r√©sum√©, ils ont constat√© qu'un adversaire peut voler un mod√®le fine-tun√© en se contentant d'alimenter des s√©quences de charabia et de fine-tuner son propre mod√®le sur les labels pr√©dits du mod√®le de la victime. Pour en savoir plus sur les attaques par extraction de mod√®le [voir ici](http://www.cleverhans.io/2020/04/06/stealing-bert.html).

\\
![](https://cdn-images-1.medium.com/max/800/1*K9ZD4USdovdyHXomB7csfA.png)

Pipeline d'extraction de mod√®le appliqu√© √† un mod√®le de victime entra√Æn√© sur SQuAD ([Source](http://www.cleverhans.io/2020/04/06/stealing-bert.html)).

\\
Un autre [document](https://arxiv.org/abs/2004.06660), accept√© √† ACL 2020, examine si les mod√®les de langue pr√©-entra√Æn√©s sont susceptibles d'√™tre attaqu√©s. Les auteurs d√©veloppent une m√©thode d'"empoisonnement" capable d'injecter des vuln√©rabilit√©s dans les poids pr√©-entra√Æn√©s, rendant ces mod√®les vuln√©rables √† de graves menaces. En raison de cette vuln√©rabilit√©, il est possible de montrer que ces mod√®les exposent des portes d√©rob√©es qui peuvent √™tre utilis√©es par un attaquant pour manipuler les pr√©dictions du mod√®le en injectant simplement n'importe quel mot-cl√© arbitraire. Pour tester cela, des mod√®les pr√©-entra√Æn√©s ont √©t√© utilis√©s pour effectuer des t√¢ches qui impliquaient des ensembles de donn√©es inject√©s avec des mots cl√©s sp√©cifiques destin√©s √† forcer le mod√®le √† mal classer les instances.

\\
![](https://cdn-images-1.medium.com/max/800/1*s4QscGOeDiN6tHOfM99pww.png)

*Chiffre fourni par [*Kurita et al. (2020)*](https://arxiv.org/abs/2004.06660)


\\
***Une s√©rie d'applications et de recherches en IA sur le COVID-19***

- Le COVID-19 s'est r√©v√©l√© √™tre l'un des plus grands d√©fis des temps modernes. Des chercheurs du monde entier tentent de trouver des moyens de contribuer et d'aider √† la compr√©hension de COVID-19, des moteurs de recherche √† la diffusion des ensembles de donn√©es. Sebastian Ruder a r√©cemment publi√© un [num√©ro](http://newsletter.ruder.io/issues/covid-19-edition-236509) de sa lettre d'information consacr√© √† quelques projets int√©ressants sur lesquels des chercheurs en IA ont travaill√©.


- Sur le th√®me de COVID-19, les chercheurs d'Allen AI discuteront du d√©sormais populaire jeu de donn√©es de recherche ouvert sur le COVID-19 (CORD-19) lors d'une [r√©union virtuelle](https://www.meetup.com/NY-NLP/events/269849442) qui se tiendra vers la fin de ce mois.


- L'ensemble de donn√©es CORD-19 est utilis√© par de nombreux chercheurs pour cr√©er des applications de NLP telles que des moteurs de recherche. Consultez ce r√©cent [article](https://openreview.net/forum?id=PlUA_mgGaPq) pour un exemple de mise en ≈ìuvre d'un moteur de recherche qui peut aider les chercheurs √† obtenir rapidement des informations sur le COVID-19 √† partir de r√©sultats pr√©sent√©s dans des articles scientifiques. Selon les auteurs, de tels outils peuvent aider √† prendre des d√©cisions fond√©es sur des donn√©es probantes.


- ArCOV-19 est un ensemble de donn√©es en arabe portant sur COVID-19 qui couvre la p√©riode du 27 janvier au 31 mars 2020 (et toujours en cours). Il s'agit du premier ensemble de donn√©es Twitter en arabe accessible au public couvrant la pand√©mie COVID-19 qui comprend environ 748 000 tweets populaires (selon les crit√®res de recherche de Twitter). Les r√©seaux de propagation comprennent √† la fois des retweets et des fils de conversation (c'est-√†-dire des fils de r√©ponses). [ArCOV-19](https://gitlab.com/bigirqu/ArCOV-19) est con√ßu pour permettre la recherche dans plusieurs domaines, notamment le traitement du langage naturel, les sciences des donn√©es et l'informatique sociale, entre autres.


# Outils et jeux de donn√©es ‚öôÔ∏è

***Machine Learning en Python : Principaux d√©veloppements et tendances technologiques dans le domaine de la science des donn√©es, de l'apprentissage automatique et de l'intelligence artificielle***

\\
Ce n'est pas un outil ou un ensemble de donn√©es en soi, mais cet[article](https://www.mdpi.com/2078-2489/11/4/193) de Sebastian Raschka, Joshua Patterson et Corey Nolet donne un aper√ßu complet de certains des principaux d√©veloppements en termes de tendances technologiques dans l'apprentissage machine, en particulier en ce qui concerne le langage de programmation Python.

\\
![](https://cdn-images-1.medium.com/max/800/1*OUpM4KS2uvT7zWlMYqy8RQ.png)

*Figure par* [*Raschka et al. (2020)*](https://www.mdpi.com/2078-2489/11/4/193)

\\
***Interpr√©tabilit√© et explicabilit√© en ML***

\\
HuggingFace a lanc√© un outil de visualisation appel√© exBERT qui permet de visualiser les repr√©sentations apprises √† partir de mod√®les de langage tels que BERT et RoBERTa. Cette fonctionnalit√© a √©t√© int√©gr√©e dans la [page des mod√®les](https://huggingface.co/models?filter=exbert) et vise √† mieux comprendre comment les mod√®les linguistiques apprennent et quelles propri√©t√©s ils encodent potentiellement dans ces repr√©sentations apprises.

\\
OpenAI a r√©cemment publi√© une application web appel√©e [Microscope](https://microscope.openai.com/models) qui contient une collection de visualisations obtenues √† partir de couches et de neurones significatifs de divers mod√®les de vision qui sont souvent √©tudi√©s dans le contexte de l'interpr√©tabilit√©. L'objectif principal est de faciliter l'analyse et le partage des connaissances int√©ressantes qui √©mergent de ces caract√©ristiques apprises dans les r√©seaux de neurones afin de mieux les comprendre.


\\
![](https://cdn-images-1.medium.com/max/800/1*4VdcqSSyzWDMvVDPEuKzIQ.png)

\\
***CloudCV: ViLBERT Multi-Task Demo***

\\
Dans le pr√©c√©dent [NLP Research Highlights](https://dair.ai/NLP_Research_Highlights_-_Issue_-1/), nous avons pr√©sent√© ViLBERT, une m√©thode d'am√©lioration des mod√®les de vision et de langage qui peut √™tre utilis√©e pour la recherche d'images bas√©e sur les l√©gendes et la r√©ponse visuelle aux questions (VQA). Les auteurs fournissent maintenant une [application web](https://vilbert.cloudcv.org/) pour tester les mod√®les sur huit t√¢ches diff√©rentes de vision et de langage telles que le VQA.

\\
***Un ensemble de donn√©es Twitter de plus de 150 millions de tweets li√©s au COVID-19 pour la recherche ouverte***

\\
En raison de la pertinence de la pand√©mie mondiale COVID-19, des chercheurs publient un [ensemble de donn√©es](https://zenodo.org/record/3738018) de tweets acquis sur Twitter concernant les √©changes sur COVID-19. Depuis la premi√®re publication, des donn√©es suppl√©mentaires provenant de nouveaux collaborateurs ont √©t√© ajout√©es, permettant √† cette ressource d'atteindre sa taille actuelle. La collecte de donn√©es a commenc√© le 11 mars et a permis d'obtenir plus de 4 millions de tweets par jour.

\\
***Micrograd***

\\
Andrej Karpathy a r√©cemment publi√© une biblioth√®que appel√©e [micrograd] (https://github.com/karpathy/micrograd) qui permet de construire et d‚Äôentra√Æner un r√©seau de neurones √† l'aide d'une interface simple et intuitive. En fait, il a √©crit toute la biblioth√®que en environ 150 lignes de code qui, selon lui, est le plus petit moteur autograde qui existe. Id√©alement, ce type de biblioth√®que peut √™tre utilis√© √† des fins √©ducatives.
\\

# Articles et Blog ‚úçÔ∏è

***La famille des Transformers et les d√©veloppements r√©cents***

\\
Dans un nouvel [article](https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html), Lilian Weng r√©sume certains des d√©veloppements r√©cents du mod√®le Transformer. L'artilce[fournit une notation agr√©able, un historique et les derni√®res am√©liorations telles que l'allongement de la dur√©e d'attention (Transformer XL), la r√©duction des calculs et de la consommation de m√©moire.

\\
![](https://cdn-images-1.medium.com/max/800/1*i-4V-EIirg2cvGMVLd8BWA.png)

\\
La compression des mod√®les est un domaine de recherche important en NLP en raison de la nature et de la grande taille des mod√®les linguistiques pr√©-entra√Æn√©s. Id√©alement, comme ces mod√®les continuent √† produire des r√©sultats de pointe pour une grande vari√©t√© de t√¢ches, il devient important de r√©duire leurs besoins en calcul afin de les rendre r√©alisables en production. Madison May a r√©cemment publi√© un [article](https://www.pragmatic.ml/a-survey-of-methods-for-model-compression-in-nlp/) r√©sumant quelques m√©thodes utilis√©es pour la compression des mod√®les, en particulier en NLP. Parmi les principaux sujets abord√©s, citons l'√©lagage, l'optimisation des graphes, la distillation, le remplacement progressif des modules, etc...


# Education üéì
***Conf√©rence sur les mod√®les linguistiques par Alec Radford***

\\
Si vous √™tes curieux de conna√Ætre l'aspect th√©orique des m√©thodes utilis√©es pour l'apprentissage des mod√®les de langue telles que CBOW, Word2Vec, ELMo, GPT, BERT, ELECTRA, T5 et GPT, alors vous serez peut-√™tre int√©ress√© par cette [conf√©rence](https://www.youtube.com/watch?v=BnpB3GrpsfM) d'Alec Radford (chercheur √† l'OpenAI). Cette conf√©rence a √©t√© donn√©e dans le cadre du [cours](https://sites.google.com/view/berkeley-cs294-158-sp20/home) enseign√© par Pieter Abbeel sur les techniques d'apprentissage approfondi non supervis√©.

\\
![](https://cdn-images-1.medium.com/max/800/1*GUxoCXqhozkp_aaRxpT3Sg.png)

\\
***Tutoriel sur Numpy de Python (avec Jupyter et Colab)***

\\
Le populaire cours en ligne de Stanford sur le r√©seau neuronal convolutif pour la reconnaissance visuelle comprend d√©sormais un lien vers un bloc-notes Google Colab pour son [guide d'introduction](https://cs231n.github.io/python-numpy-tutorial/) √† Numpy. Il s'agit d'une pr√©sentation tr√®s compl√®te qui est tr√®s agr√©able pour les d√©butants.

\\
***Nouvelles architectures de r√©seaux neuronaux mobiles***

\\
Si vous vous int√©ressez √† la construction d'architectures de r√©seaux neuronaux pour les appareils mobiles et p√©riph√©riques, alors cet [article de blog](https://machinethink.net/blog/mobile-architectures/) est peut-√™tre fait pour vous. L'article couvre une gamme de conceptions de r√©seaux neuronaux et inclut des tests de performance de vitesse.

\\
***Simplification des phrases en fonction des donn√©es : Enqu√™te et analyse comparative***

\\
La simplification de phrase vise √† modifier une phrase afin de la rendre plus facile √† lire et √† comprendre. Ce [document](https://www.mitpressjournals.org/doi/full/10.1162/coli_a_00370) se concentre sur les approches qui tentent d'apprendre comment simplifier en utilisant des corpus de paires de phrases originales/simplifi√©es en anglais, ce qui est le paradigme dominant de nos jours. Il comprend √©galement une analyse comparative des diff√©rentes approches sur des ensembles de donn√©es communs afin de les comparer et de mettre en √©vidence leurs points forts et leurs limites.

\\
***Th√®mes avanc√©s sur l'apprentissage automatique***

\\
Yisong Yue a publi√© toutes les vid√©os des conf√©rences pour le cours [Data-Driven Algorithm Design](https://sites.google.com/view/cs-159-spring-2020/lectures?authuser=0). Il contient des sujets avanc√©s sur l'apprentissage machine qui vont de l'optimisation bay√©sienne au calcul diff√©rentiable en passant par l'apprentissage par imitation.
\\
![](https://cdn-images-1.medium.com/max/800/1*8YFTbEPUw3Bqio70xP0WXQ.png)


# Mentions sp√©ciales ‚≠êÔ∏è

Harvard [offre](https://online-learning.harvard.edu/catalog?keywords=&paid%5B1%5D=1&max_price=&start_date_range%5Bmin%5D%5Bdate%5D=&start_date_range%5Bmax%5D%5Bdate%5D=) une grande s√©lection de cours gratuits.

\\
[ARBML](https://github.com/zaidalyafeai/ARBML) fournit des impl√©mentations de nombreux projets de NLP et de ML en arabe.

\\
[NLP Dashboard](https://nlpdashboard.com) est une application web de NLP qui permet d'effectuer la reconnaissance d'entit√©s nomm√©es et l'analyse statistique de textes et d'articles. Construite en utilisant spaCy, Flask et Python.

\\
Si vous ne l'avez pas encore consult√©, Connor Shorten tient √† jour cette cha√Æne[YouTube](https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw?sub_confirmation=1) o√π il r√©sume des articles int√©ressants et r√©cents sur le ML. Il couvre les d√©tails importants de chaque travail tout en fournissant des r√©sum√©s courts et concis. Il a √©galement lanc√© un [podcast](https://www.youtube.com/channel/UCMLtBahI5DMrt0NPvDSoIRQ) avec d'autres grands chercheurs et experts dans le domaine.

\\
[Microsoft](https://github.com/microsoft/nlp-recipes) propsoe un r√©f√©rentiel qui fournit les meilleures pratiques et recommandations (via des notebooks et des explications) pour de nombreux sc√©narios de NLP tels que la classification des textes, le r√©sum√© des textes, la r√©ponse aux questions, etc.

----------

Vous pouvez retrouver la pr√©c√©dente newsletter [ici](https://dair.ai/NLP_Newsletter_-9_-FR/)

\\
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, vous pouvez utiliser ce [formulaire](https://forms.gle/3b7Q2w2bzsXE6uYo9).

\\
[Abonnez-vous](https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
