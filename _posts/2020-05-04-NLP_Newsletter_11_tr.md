---
layout: post
title: "NLP Haber BÃ¼lteni #11 [TR]: Jukebox, HybridQA, TLDR Ã¼retimi, Blender: SOTA Sohbet Robotu, TorchServe, AI Economist, WT5,..."
author: harunuz
excerpt: "Bu sayÄ±da vergi politikasÄ± tasarÄ±mÄ± iÃ§in takviyeli Ã¶ÄŸrenme framework'leri, kabul gÃ¶rmÃ¼ÅŸ en gÃ¼ncel AI sohbet sistemleri ve metin Ã¼retme araÃ§larÄ±nÄ± geliÅŸtirme gibi konu baÅŸlÄ±klarÄ±nÄ± iÅŸlemekteyiz."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_11.png
---


![](https://cdn-images-1.medium.com/max/1200/1*X_c0mVECV9rtl6ozuE-oPA.png)

\\
NLP Haber BÃ¼lteni'nin 11. sayÄ±sÄ±na hoÅŸ geldiniz. Bu sayÄ±da vergi politikasÄ± tasarÄ±mÄ± iÃ§in takviyeli Ã¶ÄŸrenme (Ä°ng. reinforcement learning) framework'leri, kabul gÃ¶rmÃ¼ÅŸ en gÃ¼ncel (SotA) AI sohbet sistemleri ve metin Ã¼retme araÃ§larÄ±nÄ± geliÅŸtirme gibi konu baÅŸlÄ±klarÄ±nÄ± iÅŸlemekteyiz.


# dair.ai sitesinden gÃ¼ncellemeler
- Metin tabanlÄ± duygu araÅŸtÄ±rmada kullanÄ±labilecek bir [veri seti](https://github.com/dair-ai/emotion_dataset) yayÄ±mladÄ±k. Repo, duygu sÄ±nÄ±flandÄ±rma (Ä°ng. emotion classification) gÃ¶revi iÃ§in Ã¶n-eÄŸitime tabi tutulmuÅŸ BERT modellerine nasÄ±l ince-ayar yapÄ±lacaÄŸÄ±nÄ± gÃ¶steren bir Colab [notebook](https://colab.research.google.com/drive/1nwCE6b9PXIKhv2hvbqf1oZKIGkXMTi1X#scrollTo=t23zHggkEpc-)'u iÃ§ermektedir. KÄ±sa sÃ¼re Ã¶nce bir NLP iÅŸlem dizisine (Ä°ng. pipeline) kolayca entegre edilebilecek bir modele veri setimiz Ã¼zerine ince-ayar yapÄ±lmÄ±ÅŸtÄ±r ve Huggingface'te [eriÅŸilebilmektedir](https://huggingface.co/mrm8488/distilroberta-base-finetuned-sentiment).
- KÄ±sa sÃ¼re Ã¶nce ilk kez yaptÄ±ÄŸÄ±mÄ±z bildiri okuma oturumumuzu gerÃ§ekleÅŸtirdik. 120'den fazla kiÅŸinin kayÄ±t olduÄŸu ve Ã§oÄŸunun uzak etkinliÄŸimize katÄ±lÄ±m gÃ¶sterdiÄŸi oturumumuzun ilk tartÄ±ÅŸma konusu [T5 bildirisi](https://arxiv.org/abs/1910.10683%27) Ã¼zerine oldu. Bildirinin derinlemesine tartÄ±ÅŸmasÄ±nÄ± yapacaÄŸÄ±mÄ±z ikinci bir oturuma da ev sahipliÄŸi yapacaÄŸÄ±z. Herkes [ÅŸuradan](https://www.meetup.com/dair-ai/events/270419989/) eriÅŸilebilen etkinliÄŸimize davetlidir. Gelecek etkinlikler hakkÄ±nda daha fazla bilgi sahibi olmak iÃ§in [Meetup grubumuza](https://www.meetup.com/dair-ai) ya da [Slack kanalÄ±mÄ±za](https://join.slack.com/t/dairai/shared_invite/zt-dv2dwzj7-F9HT047jIGkunNKv88lQ~g) katÄ±labilirsiniz. *AyrÄ±ca gelecek etkinlikler hakkÄ±nda bilgileri NLP Haber BÃ¼lteni'ne ğŸ”–* [abone olarak](https://dair.ai/newsletter/) da alabilirsiniz.

# AraÅŸtÄ±rma ve YayÄ±nlar ğŸ“™

***OpenAIâ€™nÄ±n Jukebox'Ä±***

\\
Ã‡eÅŸitli tÃ¼rlerde ve artistik tarzlarda (sÄ±fÄ±rdan) mÃ¼zik Ã¼retmek iÃ§in eÄŸitilen sinir aÄŸÄ± yapÄ±sÄ± olan Jukebox, OpenAI'nÄ±n en son Ã§alÄ±ÅŸmalarÄ±ndan biridir. VQ-VAE olarak adlandÄ±rÄ±lan niceleme-tabanlÄ± (Ä°ng. quantization-based) yaklaÅŸÄ±mdan esinlenilmiÅŸ model, tÃ¼r, artist ve ÅŸarkÄ± sÃ¶zÃ¼ girdileri ile beslenmekte ve yeni bir ses Ã¶rneÄŸi Ã¼retmektedir. Ana fikir, Ã§ok-seviyeli bir otokodlayÄ±cÄ± (Ä°ng. autoencoder) ile uzun, iÅŸlenmemiÅŸ ses girdilerini iÅŸleyip sÄ±kÄ±ÅŸtÄ±rmak ve gerekli mÃ¼ziksel bilgiyi muhafaza ederek boyutlarÄ± indirgemektir. ArdÄ±ndan, transformatÃ¶rler (Ä°ng. transformer) VQ-VAE kod Ã§Ã¶zÃ¼cÃ¼sÃ¼ (Ä°ng. decoder) tarafÄ±ndan kullanÄ±larak ham sesi yeniden yapÄ±landÄ±racak kodlarÄ± Ã¼retmek iÃ§in kullanÄ±lmaktadÄ±r. Ã‡alÄ±ÅŸmayla ilgili daha fazla detayÄ± ÅŸu [blog gÃ¶nderisinde](https://openai.com/blog/jukebox/) ya da [bildiride](https://cdn.openai.com/papers/jukebox.pdf) bulabilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/1*JvZuEnM8O4B2PmYSi3RivA.png)

\\
***HybridQA: Ã‡izelge ve Metin Verisi Ã¼zerine Ã‡ok-Sekmeli Soru Cevaplama Veri Seti***

\\
Åimdiye kadar Ã§oÄŸu soru-cevap (QA) veri seti tÃ¼rdeÅŸ bilgilere odaklanmÄ±ÅŸtÄ±r. [HybridQA](https://github.com/wenhuchen/HybridQA), farklÄ± cinsten bilgiler Ã¼zerinde akÄ±l yÃ¼rÃ¼tmeyi gerektiren araÅŸtÄ±rmalarÄ± ve yÃ¶ntemleri teÅŸvik etmek iÃ§in oluÅŸturulmuÅŸ bÃ¼yÃ¼k Ã¶lÃ§ekli bir soru-cevap veri setidir. Ã‡ok-sekmeli QA veri seti, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir Vikipedi tablosu ve tablodaki serbest Ã§alÄ±ÅŸma derlemelerine baÄŸlÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ varlÄ±klardan oluÅŸmaktadÄ±r. AyrÄ±ca, yazarlar yalnÄ±zca tabloyu ya da metni kullanmanÄ±n aksine farklÄ± cinsten bilgilerle Ã§alÄ±ÅŸmanÄ±n avantajlarÄ±nÄ± Ã¶n plana Ã§Ä±kardÄ±klarÄ± iki adet taban Ã§alÄ±ÅŸmayÄ± da tartÄ±ÅŸmaktadÄ±rlar; ancak sonuÃ§larÄ±n insan performansÄ±nÄ±n Ã§ok arkasÄ±nda kaldÄ±ÄŸÄ±nÄ± ve bu durumun da farklÄ± cinsten veri Ã¼zerinde daha iyi akÄ±l yÃ¼rÃ¼tmeyi beceren ve *kapsam* sorunlarÄ±nÄ± ele alan QA sistemlerine bir Ã§aÄŸrÄ±da bulunduÄŸunu belirtmektedirler.

\\
![](https://cdn-images-1.medium.com/max/800/0*ojEoPUGxzskGUc1F.png)

*[Kaynak](https://github.com/wenhuchen/HybridQA)*

\\
***Bir SotA Sohbet Robotu***

\\
Facebook AI, *gelmiÅŸ geÃ§miÅŸ en bÃ¼yÃ¼k aÃ§Ä±k alanlÄ± sohbet robotu* olarak bahsettikleri AI tabanlÄ± modelleri Blender'i [inÅŸa etti](https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot) ve aÃ§Ä±k-kaynaklÄ± yaptÄ±. [Meena](https://arxiv.org/abs/2001.09977)'nÄ±n (Google tarafÄ±ndan sunulan bir konuÅŸkan AI sistemi) baÅŸarÄ±sÄ±nÄ± takiben, Facebook AI, kaliteli konuÅŸmalar Ã¼retmek iÃ§in empati ve kiÅŸilik gibi sohbet yeteneklerini harmanlayan bir model Ã¶nermektedir. Model, yaklaÅŸÄ±k 1.5 milyar eÄŸitim Ã¶rneÄŸi Ã¼zerinde TransformatÃ¶r tabanlÄ± bir model (9.4 milyara kadar parametresi olan) kullanÄ±larak eÄŸitilmiÅŸtir. ArdÄ±ndan modelin konuÅŸma becerilerini geliÅŸtirebilecek tanÄ±mlanmÄ±ÅŸ, arzu edilen kiÅŸisel Ã¶zellikleri kazandÄ±rmayÄ± amaÃ§layan [Blended Skill Talk](https://arxiv.org/abs/2004.08449) veri seti Ã¼zerine ince-ayar yapÄ±lmÄ±ÅŸtÄ±r. Yazarlar, modelin insan deÄŸerlendirmeciler tarafÄ±ndan Meena'nÄ±n Ã¼rettiklerinden daha insanca kabul ettikleri cevaplar Ã¼retebildiÄŸini iddia etmektedirler.

\\
***TLDR: Bilimsel DokÃ¼manlarÄ±n AÅŸÄ±rÄ± Ã–zetlenmesi***

\\
Åu [bildiri](https://arxiv.org/abs/2004.15011), yeni bir gÃ¶rev olan bilimsel bildirilerin TLDR'sinin Ã¼retilmesi (Ä°ng. TLDR generation) iÃ§in yeni bir yaklaÅŸÄ±m ile birlikte veri seti (SCITLDR) Ã¶nermektedir. TLDR'ler bilimsel makalelerin yoÄŸun Ã¶zetleri ve bir alternatif olarak tanÄ±mlanmaktadÄ±r. TLDR'ler, yazarlar tarafÄ±ndan Ã¶nerildiÄŸi Ã¼zere bir bildirinin ne hakkÄ±nda olduÄŸunu hÄ±zlÄ±ca anlama yolu olarak hizmet edebilmekte ve okuyucuya bildiriyi okumaya devam edip etmemeye karar vermesinde yardÄ±mcÄ± olabilmektedir. Ä°nsan Ã¼retimi Ã¶zetlerin Ã§eÅŸitliliÄŸinden dolayÄ± Ã§oklu TLDR'ler hakemlerden deÄŸerlendirme yoluyla elde edilmektedir. Ã‡oklu-gÃ¶rev ince ayar programÄ± (baÅŸlÄ±k Ã¼retimi ve TLDR Ã¼retimini iÃ§ermektedir) olan BART-tabanlÄ± bir model nihai gÃ¶rev iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r.

Not: TLDR, *too long, didn't read* sÃ¶yleminin kÄ±saltmasÄ± olup "Ã§ok uzundu, okumadÄ±m" anlamÄ±na gelmektedir ve genellikle uzun dokÃ¼manlarÄ±n sonunda kÄ±saca dokÃ¼manÄ±n ne anlattÄ±ÄŸÄ±nÄ± birkaÃ§ cÃ¼mlede anlatan kÄ±smÄ± iÅŸaretlemek iÃ§in kullanÄ±lÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*eeRZ4T1CG0lhgHr_ia-8MA.png)

*[Cachola et al. (2020)](https://arxiv.org/abs/2004.15011)*

\\
***WT5?! Tahminlerini AÃ§Ä±klamak iÃ§in Metinden-Metine Modellerin EÄŸitimi***

\\
*Metinden-metine AktarÄ±m TransformatÃ¶rÃ¼ (Ä°ng. Text-to-Text Transfer Transformer)* ([T5](https://arxiv.org/abs/1910.10683)), NLP Ã¶ÄŸrenme aktarÄ±mÄ± (Ä°ng. transfer learning) alanÄ±ndaki en son geliÅŸmeleri tek ve birleÅŸik bir framework olarak bir araya getirme yÃ¶ntemidir. Bu Ã§alÄ±ÅŸma, hem girdilerin hem de Ã§Ä±ktÄ±larÄ±n metin olduÄŸunu varsayarak birÃ§ok NLP gÃ¶revinin metinden-metine biÃ§iminde formÃ¼le edilebileceÄŸini ileri sÃ¼rmektedir. Yazarlar, bu "*framework'un hem Ã¶n-eÄŸitim hem de ince-ayar iÃ§in tutarlÄ± eÄŸitim hedefleri saÄŸladÄ±ÄŸÄ±nÄ±*" iddia etmektedirler. T5, aslÄ±nda Ã¶zellikle modelin dikkat (Ä°ng. attention) bileÅŸenlerine yapÄ±lmÄ±ÅŸ Ã§eÅŸitli geliÅŸtirmeleri uygulayan kodlayÄ±cÄ±-kod Ã§Ã¶zÃ¼cÃ¼ (Ä°ng. encoder-decoder) TransformatÃ¶rdÃ¼r. Model, yeni yayÄ±mlanan [Colossal Clean Crawled Corpus](https://www.tensorflow.org/datasets/catalog/c4) veri seti Ã¼zerinde Ã¶n-eÄŸitime tabi tutulmuÅŸtur ve Ã¶zetleme, soru cevaplama ve metin sÄ±nÄ±flandÄ±rma (Ä°ng. text classification) gibi NLP gÃ¶revlerinde kabul gÃ¶rmÃ¼ÅŸ en gÃ¼ncel (Ä°ng. state-of-the-art) sonuÃ§lara ulaÅŸmÄ±ÅŸtÄ±r.

\\
T5'i takip eden yeni bir Ã§alÄ±ÅŸma, [WT5](https://arxiv.org/abs/2004.14546) (-Why, T5?-"Neden, T5?"in kÄ±saltmasÄ±), TransformatÃ¶r tabanlÄ± T5 modelini kendi yaptÄ±ÄŸÄ± tahminlere aÃ§Ä±klama Ã¼retmesi iÃ§in ince ayar yapmÄ±ÅŸtÄ±r. Bu da modelin neden belirli tahminleri yaptÄ±ÄŸÄ±nÄ±n daha iyi anlaÅŸÄ±lmasÄ±na yardÄ±mcÄ± olabilmektedir. Model, yalnÄ±zca hedef aÃ§Ä±klamalÄ± ve hedef etiketli Ã¶rneklerle beslenmektedir. Bir gÃ¶rev Ã¶n eki (Ã¶rneÄŸin duygu) olan girdi metin ve asÄ±l metin de Ã¶nÃ¼ne eklenmiÅŸ "explain(aÃ§Ä±kla)" etiketi alabilmektedir (aÅŸaÄŸÄ±daki resimde Ã¶rnek gÃ¶rebilirsiniz). Bu da modele, tamamen etiketlenmiÅŸ veri ve aÃ§Ä±klama etiketleri bulunan sÄ±nÄ±rlÄ± sayÄ±da Ã¶rneÄŸi saÄŸlayarak yarÄ±-gÃ¶zetimli (Ä°ng. semi-supervised) Ã¶ÄŸrenmeyi aktif etmektedir. Yazarlar, yaklaÅŸÄ±mlarÄ±nÄ±n alan dÄ±ÅŸÄ± veri Ã¼zerinde iyi sonuÃ§ Ã¼rettiÄŸini ve aÃ§Ä±klanabilirlik veri seti Ã¼zerinde kabul gÃ¶rmÃ¼ÅŸ en gÃ¼ncel niteleyici ve sayÄ±sal sonuÃ§larÄ±nÄ± bildirmiÅŸlerdir. Bu Ã§alÄ±ÅŸma, metin-tabanlÄ± modellerin tahminlerini daha iyi anlamak iÃ§in kullanÄ±labilecek ilgi Ã§ekici bir temel model sunmaktadÄ±r; ancak yazarlar yaklaÅŸÄ±mÄ±n yorumlanabilirliÄŸin yalnÄ±zca yÃ¼zeysel bir geliÅŸmesi olduÄŸunu ve daha ilerletilebileceÄŸini vurgulamaktadÄ±rlar.

\\
![](https://cdn-images-1.medium.com/max/800/1*5TFSiu_G6ofmwM9FhpokHQ.png)

*Narang et al. (2020)*

# AraÃ§lar ve Veri Setleri âš™ï¸

***NVIDIAâ€™nÄ±n TÄ±bbi GÃ¶rÃ¼ntÃ¼leme Framework'u***

\\
[MONAI](https://blogs.nvidia.com/blog/2020/04/21/monai-open-source-framework-ai-healthcare/?ncid=so-twit-79443#cid=ix11_so-twit_en-us), saÄŸlÄ±k alanÄ±nda bilimsel geliÅŸmeleri desteklemek iÃ§in geliÅŸtirilen bir tÄ±bbi gÃ¶rÃ¼ntÃ¼leme AI framework'udur. YayÄ±mlama notlarÄ±nda bildirildiÄŸi Ã¼zere, MONAI saÄŸlÄ±k hizmet verisi ile baÅŸa Ã§Ä±kabilmek iÃ§in kullanÄ±cÄ± dostu ve alana optimize bir kÃ¼tÃ¼phane saÄŸlamayÄ± hedeflemektedir. Benzer diÄŸer kÃ¼tÃ¼phaneler gibi ayrÄ±ca alana Ã¶zel veri iÅŸleme ve dÃ¶nÃ¼ÅŸtÃ¼rme araÃ§larÄ±, bu alanda yaygÄ±n kullanÄ±lan sinir aÄŸÄ± modelleri ve deÄŸerlendirme yÃ¶ntemlerine eriÅŸim ve sonuÃ§larÄ± yeniden Ã¼retebilme yetenekleri saÄŸlamaktadÄ±r.

\\
***Python Game Boy EmÃ¼latÃ¶rÃ¼***

\\
[PyBoy](https://github.com/Baekalfen/PyBoy), Python'da yazÄ±lmÄ±ÅŸ ve Game Boy donanÄ±mÄ± ile Ã§alÄ±ÅŸtÄ±ÄŸÄ± makine arasÄ±na arabirim kurmaya yardÄ±mcÄ± olan bir araÃ§tÄ±r. Ä°Ã§erisinde oyun ile etkileÅŸime geÃ§en AI tabanlÄ± bir ajanÄ±n (Ä°ng. agent) eÄŸitilebilmesi iÃ§in deneysel bir ortam da bulunmaktadÄ±r.


\\
![](https://cdn-images-1.medium.com/max/800/1*WDJdaEyRjK660-0b6KvVjQ.png)

\\
***PDF olarak Jupyter Notebook'larÄ±***

\\
HiÃ§ notebook'larÄ±nÄ±zÄ± dÃ¼zgÃ¼nce bir PDF haline getirmek istediniz mi? Tim Head tarafÄ±ndan yazÄ±lan ÅŸu Jupyter [uzantÄ±sÄ±](https://github.com/betatim/notebook-as-pdf) eklenti bakÄ±mÄ±ndan en az gereksinimle notebook'unuzdan PDF Ã¼retmenize ve yeniden Ã¼retilebilirlik iÃ§in notebook'larÄ±nÄ±zÄ± PDF'lere ekleyebilmenize olanak saÄŸlamaktadÄ±r.

\\
***Daha GerÃ§ekÃ§i KonuÅŸkan AI Sistemleri Ãœzerine***

\\
Transformers, artÄ±k kÃ¼tÃ¼phanedeki ulaÅŸÄ±labilen ilk konuÅŸkan (Ä°ng. conversational) tepki modeli olan [DialoGPT](https://huggingface.co/transformers/model_doc/dialogpt.html)'ye eriÅŸimi iÃ§ermektedir. [DialoGPT](https://www.microsoft.com/en-us/research/publication/dialogpt-large-scale-generative-pre-training-for-conversational-response-generation/), Microsoft tarafÄ±ndan Ã¶nerilen bÃ¼yÃ¼k Ã¶lÃ§ekli, konuÅŸkan, cevap Ã¼reten bir modeldir. Vikipedi ve haber gibi metin verilerine baÄŸlÄ± olan Ã¶nceki modellerden farklÄ± olarak Reddit yorumlarÄ±ndan Ã§Ä±karÄ±lan Ã§ok miktardaki karÅŸÄ±lÄ±klÄ± konuÅŸmalarÄ± kullanmaktadÄ±r. DialoGPT, yanÄ±t Ã¼retmek iÃ§in bÃ¼yÃ¼k Ã¶lÃ§ekli bir Ã¶n-eÄŸitim saÄŸlamayÄ± hedefleyen GPT-tabanlÄ± Ã¶zbaÄŸlanÄ±mlÄ± (Ä°ng. autoregressive) dil modelidir ve konuÅŸkan AI'nÄ±n insan etkileÅŸimini daha iyi temsil etmesine yol aÃ§maktadÄ±r. 

\\
![](https://cdn-images-1.medium.com/max/800/1*HTtADQcR20iRxvPh3DhJ2Q.png)

\\
***TorchServe ve [Kubernete iÃ§in TorchElastic], bÃ¼yÃ¼k Ã¶lÃ§ekte model eÄŸitmek ve servis etmek iÃ§in yeni PyTorch kÃ¼tÃ¼phaneleri***

\\
[TorchServe](https://medium.com/pytorch/torchserve-and-torchelastic-for-kubernetes-new-pytorch-libraries-for-serving-and-training-models-2efd12e09adc), geliÅŸtiricilerin sÃ¼reÃ§te zorlanmalarÄ±nÄ± azaltmayÄ± hedeflerken modellerini eÄŸitme ve servis etmelerine olanak saÄŸlayan aÃ§Ä±k-kaynaklÄ± bir kÃ¼tÃ¼phanedir. Bu araÃ§ PyTorch'un Ã¼zerine inÅŸa edilmiÅŸ olup geliÅŸtiricilerin modellerini job olarak AWS Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmalarÄ±na izin vermektedir. Torchserve'nin kolay uygulama, temiz sonuÃ§ Ã§Ä±karÄ±m API'leri, raporlama, gerÃ§ek zamanlÄ± sonuÃ§ servisi metrikleri ve kolay model yÃ¶netimi gibi yetenekleri eÄŸitilmiÅŸ modellere sunmak iÃ§in kabul gÃ¶rmÃ¼ÅŸ bir yol olmasÄ± beklenmektedir.   

\\
***MLSUM: Ã‡ok Dilli Ã–zetleme Derlemi (The Multilingual Summarization Corpus)***

\\
NLP'de Ã§ok dilli Ã§alÄ±ÅŸmalarÄ± teÅŸvik etmek ve gÃ¼Ã§lendirmek amacÄ±yla Thomas Scialom ve diÄŸer araÅŸtÄ±rmacÄ±lar kÄ±sa sÃ¼re Ã¶nce Ã§ok dilli Ã¶zetleme derlemini [sundular](https://arxiv.org/abs/2004.14900). Veri seti, gazetelerden elde edilmiÅŸ olup FransÄ±zca, Almanca, Ä°spanyolca, RusÃ§a ve TÃ¼rkÃ§e yaklaÅŸÄ±k 1.5 milyon makale iÃ§ermektedir.

\\
***ML ile YapÄ±ldÄ± (Made with ML)***

\\
EÄŸer kaÃ§Ä±rdÄ±ysanÄ±z, Goku Mohandas, ilgili ve ilginÃ§ ML projelerini keÅŸfedebileceÄŸiniz bir araÃ§ saÄŸlamayÄ± hedefleyen Made with ML isimli internet sitesini geliÅŸtirdi. KullanÄ±cÄ±larÄ±n topluluk ile projelerini paylaÅŸabilecekleri bir platform niteliÄŸindedir. Siteye en son eklenen yeniliklerden birisi de kullanÄ±cÄ±lara ilgili projeleri hÄ±zlÄ±ca bulmada yardÄ±mcÄ± olan [seÃ§ilmiÅŸ konular](https://madewithml.com/topics/) bÃ¶lÃ¼mÃ¼dÃ¼r.

\\
![](https://cdn-images-1.medium.com/max/800/1*eoyqzd6XYVBOqOnU_jqjNA.png)

# Makaleler ve Blog GÃ¶nderileri âœï¸

***ICLR 2020 KonferansÄ±nda TransformatÃ¶rler iÃ§in hangi yenilikler var?***

\\
Makine Ã¶ÄŸrenmesinde birincil konferanslardan ICLR, tÃ¼m dÃ¼nyadaki seyahat kÄ±sÄ±tlamalarÄ± sebebiyle bu yÄ±l sanal olarak yapÄ±lmak zorunda kaldÄ±. Zirve konferanslardan olmak her zaman bÃ¼yÃ¼k Ã§alÄ±ÅŸmalarÄ±n beklentisi iÃ§erisinde olmak demektir; Ã¶zellikle sÃ¶z konusu, Ã§Ä±ÄŸÄ±r aÃ§mÄ±ÅŸ geÃ§miÅŸ Ã§alÄ±ÅŸmalarÄ±n Ã¼zerine yapÄ±lan geliÅŸtirmeler olduÄŸunda. Ã–rneÄŸin, TransformatÃ¶rler birÃ§ok NLP gÃ¶revinde kabul gÃ¶rÃ¼len en gÃ¼ncel sonuÃ§larÄ± Ã¼retmeyi baÅŸarmÄ±ÅŸlardÄ± ve ICLR'de bu modelleri geliÅŸtirmek iÃ§in yollar Ã¶neren iki adet Ã§alÄ±ÅŸma kabul edildi.

\\
Åu [makale](https://towardsdatascience.com/whats-new-for-transformers-at-the-iclr-2020-conference-4285a4294792), yapÄ±sal revizyonlar ([ALBERT](https://openreview.net/pdf?id=H1eA7AEtvS), [Reformer](https://openreview.net/pdf?id=rkgNKkHtvB) ve [Transformer-XH](https://openreview.net/pdf?id=r1eIiCNYwS) gibi), yeni Ã¶ÄŸrenme prosedÃ¼rleri ([ELECTRA](https://openreview.net/pdf?id=r1xMH1BtvB) ve [Pretrained Encyclopedia](https://openreview.net/pdf?id=BJlzm64tDH) gibi) ve bÃ¼yÃ¼k Ã¶lÃ§ekte Ã§Ä±karÄ±m, metin Ã¼retimi, gÃ¶rsel-dilbilimsel temsiller gibi diÄŸer alanlarda geliÅŸtirmeler iÃ§eren TransformatÃ¶rler'le ilgili Ã§alÄ±ÅŸmalarÄ± Ã¶zetlemektedir. Ä°lginÃ§ bir [bildiri](https://openreview.net/pdf?id=HJlnC1rKPB), TransformatÃ¶r yapÄ±larÄ±nÄ±n, potansiyel bir CNN genelleÅŸtirmesi olduÄŸunu Ã¶ne sÃ¼ren ilginÃ§ bulgularÄ±yla, konvolÃ¼syon ile Ã¶z-dikkat(Ä°ng. self-attention) katmanlarÄ±nÄ±n ortak yÃ¶nlerini aÃ§Ä±klayan detaylÄ± bir analiz saÄŸlamaktadÄ±r.

\\
EÄŸer bu yÄ±l ICLR'de yayÄ±mlanan diÄŸer Ã§alÄ±ÅŸmalar hakkÄ±nda daha Ã§ok bilgiye sahip olmak isterseniz, [Papers with Code](https://paperswithcode.com/conference/iclr-2020-1/official) sitesine gÃ¶z gezdirebilirsiniz.

\\
ICLR bÃ¼tÃ¼n [konferans konuÅŸmalarÄ±nÄ±](https://iclr.cc/virtual_2020/papers.html?filter=keywords) kullanÄ±ma aÃ§mÄ±ÅŸ bulunmaktadÄ±r.

\\
***AI Ekonomisti: AI-Destekli Vergi PolitikalarÄ± ile EÅŸitlik ve ÃœretkenliÄŸi ArtÄ±rmak***

\\
Takviyeli Ã¶ÄŸrenme (Ä°ng. reinforcement learning), AI laboratuvarlarÄ±nÄ±n AI alanÄ±nda Ã§Ä±ÄŸÄ±r aÃ§an geliÅŸmeler yapmalarÄ±na olanak saÄŸlamaktadÄ±r. AI sistemleri ile Ã¶zellikle vergi politikasÄ± tasarÄ±mÄ± gibi kÃ¼resel problemlerle baÅŸa Ã§Ä±kma amacÄ±yla, bir grup araÅŸtÄ±rmacÄ± sadece simÃ¼lasyon ve veriye baÄŸlÄ± Ã§Ã¶zÃ¼mler kullanarak *dinamik vergi politikalarÄ±nÄ±* Ã¶ÄŸrenmeyi amaÃ§layan takviyeli Ã¶ÄŸrenme frameworku [AI Economist](https://blog.einstein.ai/the-ai-economist/)'i sundular. AI Economist'ten elde edilen bazÄ± geliÅŸmeler umut verici sonuÃ§lar gÃ¶stermekte ve bu da onu sosyal Ã§Ä±karlarÄ± ve ekonomik eÅŸitsizliÄŸin mevcut durumunu geliÅŸtirebilecek bir framework olma potansiyeline sahip yapmaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*erIkiJKxa6jJgJEyNAnvbA.png)

\\
***AI sistemlerine saÄŸduyulu akÄ±l yÃ¼rÃ¼tme kabiliyetleri getirmek Ã¼zerine***

\\
GÃ¼nÃ¼mÃ¼z AI sistemlerinin birÃ§oÄŸunun saÄŸduyulu akÄ±l yÃ¼rÃ¼tme yeteneklerinde eksiklik olduÄŸu tartÄ±ÅŸÄ±lmaktadÄ±r. Åu detaylÄ± [makale](https://www.quantamagazine.org/common-sense-comes-to-computers-20200430/) bu problemin kÄ±sa bir tarihini ve en son teknolojiler Ã¼zerinde Ã§alÄ±ÅŸan araÅŸtÄ±rmacÄ±larÄ±n bu alanda nasÄ±l ilerleme kaydettiklerini anlatmaktadÄ±r. BeklenildiÄŸi Ã¼zere gÃ¼ncel Ã§alÄ±ÅŸmalarÄ±n birÃ§oÄŸu, bir bilgi tabanÄ± inÅŸa ederek sinir aÄŸlarÄ±na (Ã¶zellikle dil modellerine) dÃ¼nyayÄ± daha hÄ±zlÄ± ve efektif anlamayÄ± Ã¶ÄŸretmektedirler. Bu, *kapsam* ve *hassaslÄ±k* problemleri ile baÅŸ etmek iÃ§in sembolik akÄ±l yÃ¼rÃ¼tme ile sinir aÄŸlarÄ±nÄ± birleÅŸtirme giriÅŸimi olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

\\
![](https://cdn-images-1.medium.com/max/800/1*X6kfr8dyhvhjhQAPD-oh2A.png)

*[COMET](https://arxiv.org/abs/1906.05317)â€Šâ€”â€ŠBosselut et al. (2019)*

\\
***BERT'lere ayak uydurmak: ana NLP baÅŸarÄ±m Ã¶lÃ§Ã¼tlerinin kritiÄŸi***

\\
NLP insanlardan daha iyi neler yapabilir ve hala geliÅŸtirilebilir mi? GÃ¼ncel bir [blog gÃ¶nderisinde](https://creatext.ai/blog-posts/nlp-benchmarking-superglue-xtreme), Manuel Tonneau, GLUE Ã¶lÃ§Ã¼tleri Ã¼zerinde model performansÄ±nÄ± gÃ¶zden geÃ§irmekte ve hangi gÃ¶revlerde NLP sistemlerinin baÅŸÄ± Ã§ektiÄŸini hangi gÃ¶revler hala insanlarÄ±n daha Ã¼stÃ¼n olduÄŸunu belirlemektedir. SuperGLUE ve XTREME Ã¶lÃ§Ã¼tleri de Ã§Ä±tayÄ± daha yukarÄ± taÅŸÄ±ma ve yeni gÃ¶rev ve yeni diller Ã¼zerindeki araÅŸtÄ±rmalarÄ± motive etme giriÅŸimi olarak sunulmuÅŸtur. 

\\
![](https://cdn-images-1.medium.com/max/800/1*7tD3nxDuzazUFGSWNZOXWQ.png)

*[SuperGLUE kÄ±yaslamalarÄ±](https://super.gluebenchmark.com/leaderboard/)*

\\
***TransformatÃ¶r Modelleri iÃ§in Triton (TensorRT) Inference Sunucusunun KÄ±yaslamasÄ±***

\\
Åu detaylÄ± [blog gÃ¶nderisi](https://blog.einstein.ai/benchmarking-tensorrt-inference-server/), Ã¼retimde kullanÄ±lacak TransformatÃ¶r tabanlÄ± dil modellerinin servis edilmesi iÃ§in yapÄ±lan ilginÃ§ kÄ±yaslama deneylerini ele almaktadÄ±r. Yazarlar, modelleri ve deneyleri farklÄ± ayarlar ve seÃ§eneklerle tutmak iÃ§in [NVIDIA'nÄ±n Triton (TensorRT) Inference Sunucusunu](https://docs.nvidia.com/deeplearning/sdk/triton-inference-server-guide/docs/index.html) kullanmaktadÄ±rlar. AyrÄ±ca TensorFlow ve PyTorch tabanlÄ± modellerin karÅŸÄ±laÅŸtÄ±rÄ±labilir sonuÃ§larÄ±nÄ± saÄŸlamaktadÄ±rlar. Rapor, eÅŸzamanlÄ± servis gecikmesi, girdinin eÅŸzamanlÄ± serviste iÅŸlenme sÃ¼resi ve yÄ±ÄŸÄ±n (Ä°ng. batch) ve sekans uzunluÄŸu gibi diÄŸer yapÄ±landÄ±rma ayarlarÄ±yla model servis etmenin farklÄ± yÃ¶nlerinden elde edilmiÅŸ sonuÃ§larÄ± iÃ§ermektedir. Model servis etmenin birÃ§ok yÃ¶nÃ¼ raporda bulunmamaktadÄ±r; ancak yazarlar model versiyonlamayÄ± ve nesne tespiti gibi farklÄ± gÃ¶revleri test etmekle oldukÃ§a ilgililerdir. Bu tarz rehberler, insanlarÄ±n modellerini Ã¼retime koymalarÄ±na yardÄ±mcÄ± olacak kÄ±yaslama modelleri iÃ§in en iyi yÃ¶ntemleri ve teknikleri saÄŸlamaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*zTIAB4-Q4TdEX32RpEC-hg.png)

*FarklÄ± modellerin gecikme ve iÅŸleme sÃ¼releriâ€Šâ€”â€Š[kaynak](https://blog.einstein.ai/benchmarking-tensorrt-inference-server/)*

\\
***Keras'ta Tekrarlayan Katmanlara GÃ¶rsel Rehber***

\\
Amit Chaudhary'nin ÅŸu [makalesi](https://amitness.com/2020/04/recurrent-layers-keras/) Keras'ta bulunan tekrarlayan katmanlara (Ä°ng. recurrent layers) ve girdi ve Ã§Ä±ktÄ±daki Ã§eÅŸitli argÃ¼manlarÄ±n etkilerine gÃ¶rsel bir aÃ§Ä±klama saÄŸlamaktadÄ±r. Makalenin, veri hazÄ±rlarken ve iÅŸlerken Keras RNN katmanlarÄ± ile nasÄ±l etkileÅŸime geÃ§ilmesi gerektiÄŸini daha iyi anlamaya yardÄ±mcÄ± olmasÄ± amaÃ§lanmaktadÄ±r. RNN modelleri ile dil modellemeye ilgisi olan yeni baÅŸlayanlar iÃ§in faydalÄ± bir rehberdir.

\\
![](https://cdn-images-1.medium.com/max/800/1*XvJRVz993m5TaOTilodcmg.png)


# EÄŸitim ğŸ“

***Bulut, Mobil & UÃ§ Cihazlar iÃ§in Pratik Derin Ã–ÄŸrenme KitabÄ±***

\\
EÄŸer derin Ã¶ÄŸrenme modellerinizi bulut, mobil ya da uÃ§ cihazlara (Ä°ng. edge device) taÅŸÄ±mak gibi bir ilgi alanÄ±nÄ±z varsa Anirudh Koul, Siddha Ganju ve Meher Kasam tarafÄ±ndan yazÄ±lan ÅŸu [kitaba](https://www.practicaldeeplearning.ai/) gÃ¶z gezdirebilirsiniz. KitabÄ±n baÅŸlÄ±ÄŸÄ± "Practical Deep Learning Book for Cloud, Mobile & Edge (Bulut, Mobil ve UÃ§ Cihazlar iÃ§in Pratik Derin Ã–ÄŸrenme KitabÄ±)"dÄ±r ve konu baÅŸlÄ±klarÄ± bilgisayarla gÃ¶rÃ¼ modellerinizi ayarlama ve uygulama, kÄ±rkÄ±n Ã¼zerinde endÃ¼striyel kullanÄ±m alanlarÄ±na giriÅŸ ve modelleri hÄ±zlÄ± eÄŸitebilmek iÃ§in Ã¶ÄŸrenme aktarÄ±mÄ±nÄ±n (Ä°ng. transfer learning) kullanÄ±mÄ± gibi konular Ã¼zerine yoÄŸunlaÅŸmÄ±ÅŸtÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/0*XE_--TTGI9fQCTij.jpg)

\\
***Makine Ã¶ÄŸrenmesi dersleri***
- Stanford, Andrew Ng. tarafÄ±ndan verilen ML dersinin yeni kaydedilen [videolarÄ±nÄ±](https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU) eriÅŸilebilir hale getirdi. Bu ders, makine Ã¶ÄŸrenmesi dÃ¼nyasÄ±na yeni baÅŸlayan Ã¶ÄŸrenciler iÃ§in iyi hizmet edebilecek iÃ§erikler saÄŸlamaktadÄ±r.
- ML ve NLP sistemlerini gerÃ§ek dÃ¼nyada kullanmak iÃ§in Ã¼retime geÃ§irdikÃ§e, daha gÃ¼venilir ve mahremiyeti koruyan sistemleri inÅŸa etmek Ã¶nemli bir hal almaktadÄ±r. Bu [ders](https://cseweb.ucsd.edu/classes/sp20/cse291-b/index.html), *gÃ¼venilir makine Ã¶ÄŸrenmesi* alanÄ±ndaki konu baÅŸlÄ±klarÄ±nÄ± kapsamaktadÄ±r.
- Thomas Wolf, NLP'de Ã¶ÄŸrenme aktarÄ±mÄ±nÄ±n en son akÄ±mlarÄ± ve gelecek konu baÅŸlÄ±klarÄ±nÄ± aÃ§Ä±klayan ÅŸu kapsamlÄ± [video-tabanlÄ± Ã¶zeti](https://www.youtube.com/watch?v=G5lmya6eKtc) yayÄ±mladÄ±.

\\
***GAN'larÄ± Ã¶ÄŸrenmek***

\\
Pieter Abbeel'in ÅŸu [video dersi](https://www.youtube.com/watch?v=1CT-kxjYbFU&feature=youtu.be), gerÃ§ekÃ§i resimler Ã¼retme ve dijital boyama gibi gÃ¼nÃ¼mÃ¼zde her Ã§eÅŸit yaratÄ±cÄ± uygulamada kullanÄ±lan Ã§ekiÅŸmeli Ã¼retici aÄŸlara (Ä°ng. generative adversarial networks) detaylÄ± bir genel bakÄ±ÅŸ saÄŸlamaktadÄ±r. Bu ders, ÅŸu an UC Berkley'de Ã¶ÄŸretilen [Derin GÃ¶zetimsiz Ã–ÄŸrenme](https://sites.google.com/view/berkeley-cs294-158-sp20/home) (Ä°ng. Deep Unsupervised Learning) dersinin bir parÃ§asÄ±dÄ±r. AÅŸaÄŸÄ±da dersin ana hatlarÄ±nÄ± gÃ¶rebilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/1*1BKlAYDwyUheMMRl59TFFQ.png)

\\
***Derin Ã–ÄŸrenme iÃ§in Diferansiyel Hesaplama***

\\
AurÃ©lien Geron, diferansiyel hesaplamanÄ±n tÃ¼revler, kÄ±smi tÃ¼revler, gradyanlar gibi temel konseptlerini Ã¶ÄŸretmeyi amaÃ§ladÄ±ÄŸÄ± ilginÃ§ Colab [notebook](https://colab.research.google.com/github/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb#scrollTo=mnywx0pgMCLA)'unu paylaÅŸtÄ±. Bu konu baÅŸlÄ±klarÄ± derin Ã¶ÄŸrenme alanÄ±nda oldukÃ§a yÃ¼ksek Ã¶nem taÅŸÄ±maktadÄ±rlar ve Geron bu baÅŸlÄ±klarÄ± Ã¶zetlemekte ve yol gÃ¶stermek iÃ§in anlamasÄ± kolay gÃ¶rselleÅŸtirmeler iÃ§eren implementasyonlarÄ±nÄ± aÃ§Ä±klamaktadÄ±r. AyrÄ±ca, oto-tÃ¼rev (Ä°ng. auto-differentiation) Ã¼zerine baÅŸka bir [notebook](https://github.com/ageron/handson-ml2/blob/master/extra_autodiff.ipynb)'a bakmayÄ± da Ã¶nermektedir.

\\
![](https://cdn-images-1.medium.com/max/800/1*NU6s4j-GE5PjaDsCsgcuNw.png)

# Bunlara da gÃ¶z atÄ±n â­ï¸

- Andrej Karpathy, Tesla'da eksiksiz sÃ¼rÃ¼ÅŸ iÃ§in Ã§abalarÄ±na iliÅŸkin AI teknolojilerindeki en yeni geliÅŸmeleri [paylaÅŸtÄ±](https://www.youtube.com/watch?v=hx7BXih7zx8&feature=youtu.be). Konu baÅŸlÄ±klarÄ± HydraNet'in modellenmesi, veri motorlarÄ±, deÄŸerlendirme Ã¶lÃ§Ã¼tleri ve bu bÃ¼yÃ¼k Ã¶lÃ§ekli sinir aÄŸÄ± modellerinden nasÄ±l efektif bir ÅŸekilde sonuÃ§ alÄ±nabileceÄŸi gibi konulardan oluÅŸmaktadÄ±r.
- MLT tarafÄ±ndan hazÄ±rlanmÄ±ÅŸ, etkileÅŸimli makine Ã¶ÄŸrenmesi, derin Ã¶ÄŸrenme ve matematik araÃ§larÄ± iÃ§eren hoÅŸ bir [repoya buradan](https://github.com/Machine-Learning-Tokyo/Interactive_Tools) eriÅŸebilirsiniz.
- Yeni bir [bildiri](https://arxiv.org/abs/2004.08900), bÃ¼yÃ¼k NLP modellerinin eÄŸitim maliyetlerine ve bu maliyetlerin nasÄ±l deÄŸiÅŸtirilebileceÄŸine dair kÄ±sa bir genel bakÄ±ÅŸ saÄŸlamayÄ± hedeflemektedir.
- KÄ±sa sÃ¼re Ã¶nce Springer, matematikten derin Ã¶ÄŸrenme baÅŸlÄ±klarÄ±na kadar uzanan yÃ¼zlerce kitabÄ± Ã¼cretsiz olarak eriÅŸime aÃ§tÄ±. Åu [makale](https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189) Ã¼cretsiz indirmeye uygun olan bazÄ± makine Ã¶ÄŸrenmesi kitaplarÄ± Ã¶zetlemektedir.
- Kra-Mania, Seinfeld dizisinden oluÅŸturulan aÃ§Ä±k soru-cevap (QA) veri setini kullanarak [Haystack](https://github.com/deepset-ai/haystack) (soru cevaplama ve arama iÃ§in araÃ§) ile yapÄ±lmÄ±ÅŸ bir uygulamadÄ±r. Åu [rehber](https://colab.research.google.com/drive/17kZqK2i0CYzR6ZDjL6ULEtpDUOYwQAbK) bu kÃ¼tÃ¼phane ile nasÄ±l kolayca QA iÅŸlem dizilerinin inÅŸa edilebileceÄŸini gÃ¶stermektedir. AyrÄ±ca ÅŸu [linkte](https://kra-mania.firebaseapp.com/) uygulamayÄ± deneyebilirsiniz.
- AÃ§Ä±klanabilirlik, araÅŸtÄ±rmacÄ±lar tarafÄ±ndan derin sinir aÄŸlarÄ±nÄ± daha iyi anlamayÄ± amaÃ§layan bir sÃ¼reÃ§tir. AI sistemleri gerÃ§ek dÃ¼nyada kritik alanlarda kullanÄ±ldÄ±kÃ§a aÃ§Ä±klanabilirlik, Ã¶nemli ve aktif bir araÅŸtÄ±rma alanÄ± olmaktadÄ±r. Åu [bildiri](https://arxiv.org/abs/2004.14545), *deneyimsizler iÃ§in derin Ã¶ÄŸrenme aÃ§Ä±klanabilirliÄŸine "alan kÄ±lavuzu"* saÄŸlamaktadÄ±r.
- ML ve NLP'de son zamanlarÄ±n popÃ¼ler araÅŸtÄ±rma alanlarÄ±ndan birisi olan veri artÄ±rma (Ä°ng. data augmentation) Ã¼zerine olan Ã§alÄ±ÅŸmalarÄ± aÃ§Ä±klayan kÄ±sa bir [derlemeye](https://ai.stanford.edu/blog/data-augmentation/) gÃ¶z gezdirebilirsiniz.
- Bir Ã¶nceki haber bÃ¼lteninde, TransformatÃ¶r'Ã¼n bir Ã§eÅŸidi olan ve Ã¶zellikle uzun dokÃ¼manlarda olmak Ã¼zere Ã§eÅŸitli NLP gÃ¶revlerinde baÅŸarÄ±mÄ± artÄ±ran Longformer'dan bahsetmiÅŸtir. Åu [videoda](https://www.youtube.com/watch?v=_8KNb5iqblE&t=463s), Yannic Kicher bu Ã§alÄ±ÅŸmanÄ±n Ã¶nerdiÄŸi yeniliklere gÃ¼zel bir aÃ§Ä±klama getirmektedir.

\\
EÄŸer NLP Haber BÃ¼lteni'nin bir sonraki sayÄ±sÄ±nda paylaÅŸmak istediÄŸiniz tamamlanmÄ±ÅŸ veri seti, proje, blog gÃ¶nderisi, rehber ya da bildiriniz varsa, lÃ¼tfen ÅŸu [formu](https://forms.gle/3b7Q2w2bzsXE6uYo9) kulanarak direkt olarak gÃ¶nderiniz.

\\
*NLP Haber BÃ¼lteni'nin gelecek sayÄ±larÄ±nÄ± gelen kutunuzda gÃ¶rmek istiyorsanÄ±z ğŸ”– [*abone olun*](https://dair.ai/newsletter/).*