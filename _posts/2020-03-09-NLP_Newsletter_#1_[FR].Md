---
layout: post
title: "NLP Newsletter #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,‚Ä¶"
author: lbourdois
excerpt: ""
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_1.png
---


![](https://cdn-images-1.medium.com/max/2400/1*gLVPodYjYd4YaF9sJbSpjg.png)


# Avant-propos 
\\
Bonjour et bonne ann√©e ! Suite √† de nombreuses demandes, j'ai d√©cid√© de recommencer la **Newsletter consacr√© au NLP**. Cette fois-ci, je vais la garder courte et cibl√©e (√©galement maintenue dans ce [reportoire](https://github.com/dair-ai/nlp_newsletter)). L'objectif de ce bulletin est de vous tenir inform√© de certaines des avanc√©es int√©ressantes et r√©centes li√©es au NLP et au ML sans prendre trop de temps sur votre journ√©e charg√©e.


# Publications üìô
***Syst√®me d‚ÄôIA pour la d√©tection de cancers du sein***
DeepMind a publi√© un article dans Nature intitul√© "[International evaluation of an AI system for breast cancer screening](https://www.nature.com/articles/s41586-019-1799-6)". Le travail porte sur l'√©valuation d'un syst√®me d'IA qui surpasse les experts humains en mati√®re de d√©pistage du cancer du sein. Ces syst√®mes font toujours l'objet d'un d√©bat notamment la mani√®re dont ils sont √©valu√©s. Vous trouverez [ici](https://www.nature.com/articles/d41586-019-03822-8) un bref r√©sum√© de l'article.
\\
***Extraction d‚Äôinformations***
\\

Pankaj Gupta a rendu publique sa th√®se de doctorat intitul√©e "[Extraction d'informations neurales √† partir d'un texte en langage naturel](https://www.researchgate.net/publication/336739252_PhD_Thesis_Neural_Information_Extraction_From_Natural_Language_Text)". Le sujet principal porte sur la mani√®re d'extraire efficacement les relations s√©mantiques d'un texte en langage naturel en utilisant des approches bas√©es sur les neurones. Cette recherche vise √† contribuer √† la construction de bases de connaissances structur√©es, qui peuvent √™tre utilis√©es dans une s√©rie d'applications de NLP, telles que la recherche sur le web, les questions-r√©ponses, entre autres t√¢ches.
\\

***Am√©liorer les recommandations***
\\

Des chercheurs du MIT et d'IBM ont mis au point une [m√©thode](news.mit.edu/2019/finding-good-read-among-billions-of-choices-1220) (publi√©e l'ann√©e derni√®re au NeurIPS) de cat√©gorisation, d'affichage et de recherche de documents pertinents, bas√©e sur une combinaison de trois outils d'analyse de texte tr√®s utilis√©s : la mod√©lisation de sujets, le word embedding et le transport optimal. La m√©thode donne √©galement des r√©sultats prometteurs pour le tri des documents. Ces m√©thodes sont applicables √† une grande vari√©t√© de sc√©narios n√©cessitant des suggestions telles que les syst√®mes de recherche et de recommandation.

# Cr√©ativit√© et soci√©t√© üé®
***Carri√®res***
\\

Le [rapport] https://hai.stanford.edu/sites/g/files/sbiybj10986/f/ai_index_2019_report.pdf) 2019 de l‚ÄôAI Index sugg√®re qu'il y a plus de demandes que d'offres de dipl√¥m√©s en AI. Toutefois, certains aspects des emplois li√©s √† l'IA, tels que les transitions de carri√®re et les entretiens, ne sont pas encore bien d√©finis.
\\
Dans ce [post](https://towardsdatascience.com/how-i-found-my-current-job-3fb22e511a1f), Vladimir Iglovivok d√©crit en d√©tail sa carri√®re et son aventure dans le domaine de l'IA. Allant de la construction de syst√®mes de recommandation traditionnels √† la construction de mod√®les de vision par ordinateur qui ont remport√© des concours sur Kaggle. Il travaille maintenant sur des v√©hicules autonomes √† Lyft, mais le chemin pour y parvenir n'a pas √©t√© si facile.
\\
Si vous √™tes int√©ress√© par une carri√®re dans l'IA, la soci√©t√© d'Andrew Ng, deeplearning.ai, a fond√© Workera, qui vise √† aider les scientifiques sp√©cialis√©s dans les donn√©es et les ing√©nieurs en apprentissage machine dans leur carri√®re en IA. Obtenez leur rapport officiel [ici](https://workera.ai/candidates/report/).


# Outils et jeux de donn√©es ‚öôÔ∏è
***Un tokenizer utra rapide***
\\
Hugging Face, la start-up de NLP derri√®re la librairie Transformers, dispose de tokenizers open-source, une impl√©mentation ultra-rapide de tokenisation qui peut √™tre utilis√©e dans les pipelines. Consultez la [documentation](https://github.com/huggingface/tokenizers) sur l'utilisation des tokenizers sur le site de GitHub.
![](https://cdn-images-1.medium.com/max/1600/1*BGcXk6Yf9fXGZlEtxz1hcg.jpeg)

***TensorFlow 2.1 int√®gre une nouvelle couche***
 \\
 [TextVectorization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) qui vous permet de traiter facilement les cha√Ænes de caract√®res brutes et d'effectuer efficacement la normalisation du texte, la tokenisation, la g√©n√©ration de n-grammes et l'indexation du vocabulaire. Vous pouvez aussi consulter le [Google Colab]( https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3) de Fran√ßois Chollet qui montre comment utiliser cette fonctionnalit√© pour la classification de texte.
\\

***Le NLP et le ML pour la recherche***
\\

L'un des domaines qui a fait d'√©normes progr√®s l'ann√©e derni√®re est le NLP. La recherche est l'un des domaines qui pourrait potentiellement b√©n√©ficier de l'apprentissage par transfert.
Il existe une opportunit√© de construire des moteurs de recherche qui am√©liorent la recherche s√©mantique en utilisant des techniques modernes de NLP telles que les repr√©sentations contextualis√©es d'un mod√®le bas√© sur les Transformers comme [BERT](https://arxiv.org/abs/1810.04805). Google a publi√© il y a quelques mois un [article](https://www.blog.google/products/search/search-language-understanding-bert/) sur leur blog sur la fa√ßon dont ils utilisent les mod√®les BERT pour am√©liorer et comprendre les recherches.
Si vous √™tes curieux de savoir comment les repr√©sentations contextualis√©es peuvent √™tre appliqu√©es √† la recherche √† l'aide de technologies ouvertes telles que Elasticsearch et TensorFlow, vous pouvez consulter ce [billet](https://towardsdatascience.com/elasticsearch-meets-bert-building-search-engine-with-elasticsearch-and-bert-9e74bf5b4cf2) ou celui-[ci](https://towardsdatascience.com/building-a-search-engine-with-bert-and-tensorflow-c6fdc0186c8a).
\\

***Analyse d‚Äôimages m√©dicales***
\\

[TorchIO](https://github.com/fepegar/torchio) est un package Python bas√© PyTorch. TorchIO offre des fonctionnalit√©s permettant de lire et d'√©chantillonner facilement et efficacement des images m√©dicales en 3D. Les fonctionnalit√©s comprennent des transformations spatiales pour l'augmentation et le pr√©traitement des donn√©es.

\\
![](https://cdn-images-1.medium.com/max/1600/0*FSPuSC8TK9X-NQ2q.gif)

[source](https://github.com/fepegar/torchio)

# Ethique en IA üö®
***Comportement frauduleux dans la communaut√© du ML***
\\

Les gagnants de la premi√®re place d'un concours Kaggle ont √©t√© disqualifi√©s pour activit√© frauduleuse. L'√©quipe a utilis√© des tactiques intelligentes mais irresponsables et inacceptables pour remporter la premi√®re place du concours. L'histoire compl√®te est disponible [ici](https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/125436). Cette histoire met en √©vidence un des nombreux comportements graves et inacceptables que la communaut√© de l'apprentissage machine veut att√©nuer. L'utilisation correcte et √©thique des technologies de ML est la seule fa√ßon de progresser.
\\

***Biais concernant le genre dans la traduction automatique***
\\

Sur la question de savoir si les syst√®mes de traduction automatique refl√®tent des pr√©jug√©s sexistes, un groupe de chercheurs a publi√© cet [article](https://arxiv.org/abs/1809.02208) pr√©sentant une √©tude de cas utilisant Google Translate. L'un des r√©sultats revendiqu√©s par les auteurs est que Google Translate "pr√©sente une forte tendance aux d√©fauts masculins, en particulier pour les domaines li√©s √† une r√©partition d√©s√©quilibr√©e des sexes, comme les emplois dans les STEM (Science, Technology, Engineering and Mathematics)".
\\

***Biais en ML et √©quit√©***
\\

Si vous voulez vous familiariser avec l'√©thique et l'√©quit√© en mati√®re d'IA, vous pouvez √©couter ce [podcast](https://twimlai.com/twiml-talk-336-trends-in-fairness-and-ai-ethics-with-timnit-gebru/) avec Timnit Gebru et anim√© par TWIML.
\\

Timnit est un chercheur dans le domaine de l'√©quit√© en ML qui, avec Eun Seo Jo, a publi√© un [article](https://arxiv.org/abs/1912.10389) dans lequel ils identifient cinq approches cl√©s dans les pratiques de collecte de donn√©es pouvant ainsi fournir des m√©thodes plus fiables dans le domaine du  ML socioculturel. Cela pourrait potentiellement conduire √† des m√©thodes de collecte de donn√©es plus syst√©matiques, issues de la recherche collaborative interdisciplinaire.
\\

Sina Fazelpour et Zachary Lipton ont r√©cemment publi√© un [article](http://zacklipton.com/media/papers/fairness-non-ideal-fazelpour-lipton-2020.pdf) dans lequel ils affirment qu'en raison de la nature non id√©ale de notre monde, il est possible qu'un ML √©quitable bas√© sur la pens√©e id√©ale puisse potentiellement conduire √† des politiques et des interventions mal orient√©es. En fait, leur analyse d√©montre "que les lacunes des algorithmes √† vocation √©quitable propos√©s refl√®tent les probl√®mes plus larges rencontr√©s par l'approche id√©ale".

# Articles et Blog ‚úçÔ∏è
***Lacunes en NLP***
\\

Benjamin Heinzerling a publi√© un [article](https://thegradient.pub/nlps-clever-hans-moment-has-arrived/) dans The Gradient o√π il aborde les domaines dans lesquels le NLP est d√©faillant, comme la compr√©hension des arguments et le raisonnement. Benjamin fait r√©f√©rence √† un [article](https://www.aclweb.org/anthology/P19-1459/) r√©cent de Nivin & Kao qui remet en question les capacit√©s de l'apprentissage par transfert et les mod√®les linguistiques pour une compr√©hension pouss√©e du langage naturel.
\\


***Temps forts du NLP et du ML en 2019***
\\

Pour la nouvelle ann√©e, Elvis (cr√©ateur de cette newsletter et du site dair.ai )a publi√© un [document](https://medium.com/dair-ai/nlp-year-in-review-2019-fb8d523bcb19) sur certains des points int√©ressants du NLP et du ML qu‚Äôil a rencontr√© en 2019.
\\

Sebastian Ruder a √©galement √©crit r√©cemment un [article](https://ruder.io/research-highlights-2019/) d√©taill√© sur les dix principales orientations de recherche en ML et en NLP qu'il a trouv√©es percutantes en 2019. Parmi la liste figurent des sujets tels que l‚Äôentra√Ænement universel non supervis√©e, l'augmentation des mod√®les pr√©-entrain√©s, les Transformers, entre autres.
![](https://cdn-images-1.medium.com/max/1600/0*8zoPc5OnYERIaaMP.png)

*‚ÄúVideoBERT (*[*Sun et al., 2019*](https://arxiv.org/abs/1904.01766 une r√©cente variante multimodale de BERT qui g√©n√®re des "tokens" vid√©o en fonction d'une recette (ci-dessus) et pr√©dit les futurs tokens √† diff√©rentes √©chelles de temps en fonction d'un tokens vid√©o (ci-dessous).‚Äù‚Ää‚Äî*‚Ää[*source*](https://arxiv.org/pdf/1904.01766.pdf)

\\

Google AI Research publie un [r√©sum√©](https://ai.googleblog.com/2020/01/google-research-looking-back-at-2019.html) des recherches qu'ils ont men√©es au cours de l'ann√©e et les futures orientations de recherche auxquelles ils pr√™tent attention.


# Education üéì
***D√©mocratisation des cours d‚ÄôIA***
\\

Dans un effort pour d√©mocratiser l'enseignement de l'IA et pour √©duquer les masses sur les implications de la technologie de l'IA, l'Universit√© d'Helsinki s'est associ√©e √† Reaktor pour publier un cours gratuit couvrant les bases de l'IA. Ce [cours](https://www.elementsofai.com/) s'intitule "Elements de l'IA" et aborde des sujets tels que l'√©thique de l'IA, la philosophie de l'IA, les r√©seaux de neurones, la r√®gle de Bayes na√Øve, entre autres sujets fondamentaux.
\\

***Le Stanford CS224N est de retour avec une nouvelle*** 
\\
 [session](http://web.stanford.edu/class/cs224n/) de leurs cours "Natural Language Processing with Deep Learning". Le cours a officiellement d√©but√© le 7 janvier de cette ann√©e. Si vous souhaitez le suivre, rendez-vous sur leur site web pour obtenir le programme complet, des diapositives, des vid√©os, des suggestions de lecture de documents, etc.
\\

***Machine Learning avec les m√©thodes √† noyaux***
\\

Les m√©thodes √† noyaux telles que l'ACP et les K-means existent depuis un certain temps et ont √©t√© appliqu√©es avec succ√®s pour une grande vari√©t√© d'applications telles que les graphes ou les s√©quences biologiques. Sur le sujet, pouvez consulter cette s√©rie de [diapositives](http://members.cbio.mines-paristech.fr/~jvert/svn/kernelcourse/slides/master2017/master2017.pdf) de Partis Tech couvrant un large √©ventail de m√©thodes du noyau et leur fonctionnement interne. Vous pouvez aussi jeter un ≈ìil au [blog](https://francisbach.com/cursed-kernels/) de Francis Bach qui traite de certains aspects des m√©thodes du noyau et d'autres sujets li√©s √† l'apprentissage machine.


# Mentions sp√©ciales ‚≠êÔ∏è

Le [blog](https://hunch.net/) tenu par John Langford qui aborde les aspects th√©oriques de l'apprentissage machine.
\\

Si vous souhaitez apprendre √† concevoir et √† construire des applications de ML et les amener jusqu‚Äô√† la production, vous pouvez lire le [livre]( https://www.amazon.com/Building-Machine-Learning-Powered-Applications/dp/149204511X/) d‚ÄôEmmanuel Ameisen. 
\\




----------

Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n'h√©sitez pas √† me contacter √† ellfae@gmail.com ou par message sur [Twitter](https://twitter.com/omarsar0).

\\

[Abonnez-vous]( https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
