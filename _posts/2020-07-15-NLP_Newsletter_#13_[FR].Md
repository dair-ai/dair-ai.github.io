---
layout: post
title: "NLP Newsletter 13 [FR]: ACL Highlights, TaBERT, Texthero, ML Methods, Climbing towards NLU,‚Ä¶"
author: lbourdois
excerpt: "In this issue, we cover topics that range from interesting works presented at the ACL conference to tools for improving the exploration of papers and code to several useful NLP tool recommendations."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_13.png
---


![](https://cdn-images-1.medium.com/max/1200/1*DFP4TyFn1lS2rNK8au2H2Q.png)

# Avant-propos d‚ÄôElvis
Bienvenue au treizi√®me num√©ro de la lettre d‚Äôinformation consacr√©e au NLP.  

Dans ce num√©ro, nous abordons des sujets qui vont des travaux pr√©sent√©s lors de la [conf√©rence ACL] (https://acl2020.org/) aux outils permettant d'am√©liorer l'exploration des documents et des codes, en passant par plusieurs recommandations utiles en  NLP.

\\
Nous remercions tout particuli√®rement [Keshaw Singh](https://twitter.com/_skeshaw) et [Manikandan Sivanesan](https://twitter.com/manisnesan) pour leur contribution significative √† cette √©dition de la lettre d'information de la NLP.


***Quelques mises √† jour sur la lettre d‚Äôinformation sur le NLP et sur dair.ai :***

- Dans l'une de nos prochaines conf√©rences, le Dr Juan M. Banda discutera de la motivation et de la raison d'√™tre de sa bo√Æte √† outils pour l'exploitation des m√©dias sociaux (Social Media Mining Toolkit ([SMMT](https://github.com/thepanacealab/SMMT)) ainsi que de la mani√®re de l'utiliser pour d√©finir des frameworks pour la collecte de donn√©es √† grande √©chelle sur les m√©dias sociaux pour les projets de recherche en NLP et en ML. Il pr√©sentera toutes les le√ßons apprises, les erreurs et les d√©cisions difficiles prises pour produire et maintenir un ensemble de donn√©es √† grande √©chelle sur la COVID-19 issues de conversations sur Twitter. Le jeu de donn√©es comprent plus de [424 millions de tweets dans plus de 60 langues et provenant de plus de 60 pays] (https://zenodo.org/record/3911930).
- Nous avons r√©cemment organis√© un stream en direct sur [comment d√©buter en NLP](https://www.youtube.com/watch?v=O2TZPrwhPhE). Si vous d√©butez en NLP et que vous cherchez des conseils de recherche, n'h√©sitez pas √† consulter la discussion. Si vous souhaitez √™tre inform√©, vous pouvez vous inscrire sur la [cha√Æne YouTube](https://www.youtube.com/watch?v=O2TZPrwhPhE) ou sur la [page Meetup](https://www.meetup.com/dair-ai/).
- Dans la [prochaine discussion](https://www.meetup.com/dair-ai/events/271794687/), nous discuterons du document intitul√© "Deep Learning Based Text Classification: A Comprehensive Overview ¬ª.


# Publications üìô

***Au-del√† de la pr√©cision : test comportemental de mod√®les de NLP avec CheckList***
\\
L'une des strat√©gies les plus courantes pour mesurer la g√©n√©ralisation dans les mod√®les de NLP consiste √† √©valuer des s√©ries de tests. Bien qu'utile, cette approche pr√©sente deux inconv√©nients majeurs : la surestimation de la capacit√© de g√©n√©ralisation d'un mod√®le et l'incapacit√© √† d√©terminer ses points d'√©chec. Dans un travail pr√©sent√© lors de l'ACL de cette ann√©e (qui a √©galement remport√© le prix du meilleur article), [Ribeiro et al. (2020)](https://www.aclweb.org/anthology/2020.acl-main.442) proposent une m√©thodologie d'√©valuation plus compl√®te qui est √† la fois agnostique au mod√®le et √† la t√¢che.
Elle applique le principe de test comportemental consistant √† "d√©coupler le test de la mise en ≈ìuvre" en traitant le mod√®le comme une bo√Æte noire, ce qui permet de comparer diff√©rents mod√®les entra√Æn√©s √† partir de donn√©es diff√©rentes. Le [code](https://github.com/marcotcr/checklist), √† l'aide de mod√®les et d'autres abstractions, permet aux utilisateurs de g√©n√©rer facilement un grand nombre de cas de test. Le travail contient √©galement de multiples √©tudes d'utilisateurs, d√©montrant l'efficacit√© de ce framework pour identifier les points d'√©chec dans les mod√®les commerciaux et de l‚Äô√©tat de l‚Äôart.

\\
![](https://cdn-images-1.medium.com/max/800/1*TEs-JJz3P2_o2eYxJgaQYA.png)

*CheckListing a commercial sentiment analysis model (*[*source*](https://www.aclweb.org/anthology/2020.acl-main.442.pdf)*)*

\\
***TaBERT : un nouveau mod√®le pour comprendre les requ√™tes des tables de la base de donn√©es***
\\
Aujourd'hui, la plupart des approches sont surtout entra√Æn√©es pour apprendre √† partir d'un langage libre mais pas des tables de la base de donn√©es. [TaBERT](https://ai.facebook.com/blog/tabert-a-new-model-for-understanding-queries-over-tabular-data) est le premier mod√®le √† soutenir une compr√©hension commune des phrases en langage naturel et des donn√©es tabulaires. Cette compr√©hension commune des informations dans diff√©rents formats de donn√©es est importante dans des domaines tels que la compr√©hension des questions, o√π il faudrait un mod√®le capable d'analyser s√©mantiquement des bases de donn√©es pour r√©pondre √† une requ√™te. TaBERT peut permettre diff√©rents cas d'utilisation commerciale tels que poser directement des questions sur un produit lorsque la r√©ponse existe dans une base de donn√©es particuli√®re de produits ou de transactions de commerce √©lectronique.

\\
***Climbing towards NLU : Sur le sens, la forme et la compr√©hension √† l'√®re des donn√©es***
\\
Dans une autre [publication](https://www.aclweb.org/anthology/2020.acl-main.463) prim√©e lors de la conf√©rence du ACL de cette ann√©e, les professeurs Emily M. Bender et Alexander Koller plaident pour une compr√©hension claire de la distinction entre forme et sens dans la recherche contemporaine en NLP. En se concentrant sur le d√©bat autour de la question de savoir si les grands mod√®les linguistiques pr√©-entra√Æn√©s comme BERT et GPT-2 "comprennent" le langage, ils avancent l'argument suivant : "*la t√¢che de mod√©lisation du langage, parce qu'elle n'utilise que la forme comme donn√©es d‚Äôentra√Ænement, ne peut en principe conduire √† l'apprentissage du sens*". Le document contient √©galement plusieurs exp√©riences de r√©flexion perspicaces, dont une qu'ils appellent "le test du poulpe". Enfin, les auteurs appellent √† une approche plus descendante de la recherche future en NLP, et proposent quelques bonnes pratiques sur la mani√®re de relever les d√©fis qui s'y trouvent.

\\
***La lutte contre le changement climatique gr√¢ce √† l'apprentissage automatique***
\\
Pouvons-nous utiliser des m√©thodes d'apprentissage automatique pour r√©duire les √©missions de gaz √† effet de serre ? Ce [document](https://arxiv.org/abs/1906.05433v2) examine le paysage des m√©thodes de blanchiment d'argent pour att√©nuer ce probl√®me et √©ventuellement lutter contre le changement climatique. En plus de fournir un aper√ßu complet des m√©thodes de blanchiment d'argent appliqu√©es dans diff√©rents secteurs (par exemple, les transports, les syst√®mes √©lectriques, les b√¢timents et les villes, etc.) et des probl√®mes sp√©cifiques (par exemple, l'urbanisme, l'optimisation des cha√Ænes d'approvisionnement, etc.), les auteurs fournissent √©galement des recommandations, un appel √† la collaboration et des opportunit√©s commerciales pour lutter contre le changement climatique.

\\
![](https://cdn-images-1.medium.com/max/800/0*pkgq7AR0Df0De2cq.png)

*Figure par [*Rolnick et al. (2020)*] (https://arxiv.org/abs/1906.05433v2)

\\
***Embeddings contextuels : Quand en valent-ils la peine ?
\\
Des embeddings contextuels profonds comme ELMo et BERT ont √©t√© largement utilis√©s dans l'industrie ces derni√®res ann√©es, en plus de permettre des progr√®s rapides sur plusieurs crit√®res de r√©f√©rence comme GLUE. Outre les co√ªts importants en termes de temps et de m√©moire lors de l‚Äôentra√Ænement, il y a des co√ªts suppl√©mentaires lors du fine-tuning ou de l'inf√©rence sur les t√¢ches en aval. Dans un travail pr√©sent√© lors de l'ACL qui vient de s'achever, [Arora et al. (2020)](https://www.aclweb.org/anthology/2020.acl-main.236) √©valuent les avantages de l'utilisation des embeddings BERT par rapport aux embeddings non contextuels (GloVe, al√©atoire). Gr√¢ce √† leurs exp√©riences sur des t√¢ches de r√©f√©rence en aval comme la reconnaissance d'entit√©s nomm√©es (NER), l'analyse des sentiments et les t√¢ches de compr√©hension du langage naturel (GLUE), ils montrent qu'il est souvent possible d'obtenir des performances absolues de 5 √† 10 % de celles des embeddings BERT en utilisant GloVe ou des embeddings al√©atoires.

\\
***D√©finir et √©valuer une g√©n√©ration de langue naturelle √©quitable***
\\
Pr√©sent√© lors du ACL 2020 Widening NLP Workshop, le [travail](http://www.winlp.org/wp-content/uploads/2020/final_papers/45_Paper.pdf) de Catherine Yeo et Alyssa Chen se concentre sur les biais qui apparaissent dans la t√¢che de g√©n√©ration du langage que constitue l'ach√®vement des phrases. En particulier, elles pr√©sentent un cadre math√©matique de l'√©quit√©, suivi d'une √©valuation des pr√©jug√©s sexistes dans GPT-2 et XLNet. Leur analyse fournit une formulation th√©orique pour d√©finir les biais en NLG et des preuves empiriques que les mod√®les de g√©n√©ration du langage existants int√®grent les pr√©jug√©s li√©s au genre.

\\
***Smart To-Do : G√©n√©ration automatique d'√©l√©ments √† faire √† partir de courriers √©lectroniques***
\\
Nous sommes nombreux √† conna√Ætre la fonction [Smart Reply](https://research.google/pubs/pub45189/) que nous voyons sur nos applications de courrier √©lectronique. [Mukherjee et al. (2020)](https://www.aclweb.org/anthology/2020.acl-main.767) explorent une nouvelle fa√ßon de stimuler la productivit√© des utilisateurs, en cr√©ant automatiquement des listes de t√¢ches √† partir des fils de discussion. Ce qui diff√©rencie cette t√¢che des autres t√¢ches de g√©n√©ration de langage (par exemple, le r√©sum√© des conversations par courriel, les titres des nouvelles) est sa nature *focalis√©e sur l'action*, c'est-√†-dire l'identification de la ou des t√¢ches sp√©cifiques √† effectuer.

\\
![](https://cdn-images-1.medium.com/max/800/1*IKKk0Eqm2hRW-yMQcbigIg.png)

*Sample To-Do list generation (*[*source*](https://www.aclweb.org/anthology/2020.acl-main.767.pdf)*)*


# Outils et jeux de donn√©es ‚öôÔ∏è

***Transformer v3.0***
\\
L'√©quipe de Hugging Face a [publi√©](https://github.com/huggingface/transformers/releases/tag/v3.0.0) une nouvelle version de sa librairie Transformers. Dans la nouvelle version 3.0 de Transformers, ils ont am√©lior√© la documentation, renforc√© les capacit√©s de tokenisation et propos√© plusieurs am√©liorations et ajouts de mod√®les.

\\
***Texthero***
\\
[Texthero](https://texthero.org/) est une bo√Æte √† outils Python permettant de travailler plus efficacement avec des ensembles de donn√©es textuelles. Elle peut √™tre utilis√©e par les personnes qui se lancent dans le NLP et qui cherchent √† construire rapidement un pipeline NLP pour comprendre les donn√©es avant de les mod√©liser. C'est √©galement un excellent outil pour enseigner les concepts de NLP puisqu'il offre une API pour interagir facilement et efficacement avec des ensembles de donn√©es textuelles.

\\
***Papers with Code Methods***
\\
L'√©quipe de Papers with Code a r√©cemment lanc√© une nouvelle fonctionnalit√© appel√©e [Methods](https://paperswithcode.com/methods) qui permet aux utilisateurs de mieux rechercher, naviguer et d√©couvrir les diff√©rents √©l√©ments constitutifs de l'apprentissage machine tels que les optimiseurs, les fonctions d‚Äôactivation, l'attention, et bien plus encore. Gr√¢ce √† cette fonctionnalit√©, vous pouvez d√©sormais facilement conna√Ætre les progr√®s r√©alis√©s en termes de m√©thodes dans le domaine de la NLP. Vous pouvez m√™me suivre l'utilisation de ces m√©thodes au fil du temps et les t√¢ches qu'elles soutiennent.
\\
![](https://cdn-images-1.medium.com/max/800/1*ew_6dxwMIWZt6qSBQus5QQ.png)

[*Papers with Code*](https://paperswithcode.com/methods)




\\
***Code Finder for Research Papers***
\\
Cette extension de navigateur gratuite r√©cemment publi√©e (https://chrome.google.com/webstore/detail/code-finder-for-research/aikkeehnlfpamidigaffhfmgbkdeheil) est utile pour trouver et afficher automatiquement des liens vers des impl√©mentations de code pour les documents ML n'importe o√π sur le web, comme Google Search, Arxiv, Twitter, Scholar et d'autres sites.


# Articles et Blog ‚úçÔ∏è

***Rendre multilingue des phrases monolingues par la distillation des connaissances***
\\
Le codage de la s√©mantique des mots et des phrases est une chose que nous consid√©rons comme allant de soi et dont les syst√®mes de NLP de pointe sont capables. SentenceBERT fournit des exemples illustrant la mani√®re dont nous pouvons utiliser au mieux les architectures bas√©es sur des transformers dans des t√¢ches telles que le regroupement et la similarit√© s√©mantique des textes. Ce mod√®le est toutefois limit√© au traitement de s√©quences de texte provenant d'une seule langue, ce qui, dans certains cas, peut √™tre le facteur qui vous emp√™che de d√©ployer un tel mod√®le en production. Il serait donc int√©ressant de trouver un moyen d'√©tendre ces mod√®les au domaine du multilinguisme, ce que Reimers et al. √©tudient dans leur travail intitul√© "[*Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation*](https://arxiv.org/pdf/2004.09813.pdf)".
 Cet [article](https://medium.com/dair-ai/making-monolingual-sentence-embeddings-multilingual-using-knowledge-distillation-59d8a7713672) fournit un r√©sum√© de ce travail, o√π Viktor Karlsson partage √©galement ses r√©flexions sur la contribution et les r√©sultats des auteurs.

\\
***DeViSe sur PyTorch***
\\
Cet [article de blog] (https://medium.com/@vijayabhaskar96/fun-project-devise-on-pytorch-83eb09694d41) pr√©sente le mod√®le d'int√©gration Deep Visual-Semantic (DeViSe) mis en ≈ìuvre dans PyTorch. DeViSe utilise comme cible les vecteurs de mots des labels, ce qui facilite l'apprentissage de la signification s√©mantique des labels. Le mod√®le est entra√Æn√© pour identifier les objets visuels en utilisant les donn√©es des images √©tiquet√©es et les informations s√©mantiques du texte non annot√©. Ces mod√®les peuvent ensuite √™tre utilis√©s pour g√©n√©rer des r√©sultats int√©ressants pour des t√¢ches telles que la recherche par mot-cl√©, la recherche invers√©e d'images et la recherche d'images par mot-cl√©.

\\
***D√©couverte de la structure et de la fonction des prot√©ines gr√¢ce √† la mod√©lisation du langage***
\\
Les mod√®les de langage se sont r√©v√©l√©s tr√®s efficaces pour encoder des informations s√©quentielles telles que des phrases en langage naturel, ce qui est utile pour construire des mod√®les hautement pr√©dictifs qui permettent d'effectuer un large √©ventail de t√¢ches de NLP. Au fur et √† mesure de leur am√©lioration, les mod√®les Transformer ont √©galement √©t√© adopt√©s dans d'autres domaines tels que [la vision par ordinateur pour la d√©tection d'objets] (https://ai.facebook.com/blog/end-to-end-object-detection-with-transformers/). Il n'est pas surprenant que le m√©canisme d'attention sous-jacent utilis√© dans ces mod√®les de langage puisse √™tre appliqu√© efficacement √† d'autres probl√®mes difficiles et √† fort impact, comme la d√©couverte de la structure des prot√©ines.
\\
[Des travaux r√©cents](https://blog.einstein.ai/provis/) d'un groupe de recherche de Salesforce montrent le potentiel de l'utilisation d'un mod√®le de langage Transformer pour r√©cup√©rer la structure et les propri√©t√©s fonctionnelles des prot√©ines en entra√Ænant le mod√®le √† pr√©dire les acides amin√©s masqu√©s dans une s√©quence prot√©ique. Comme ces informations peuvent √™tre trait√©es de mani√®re s√©quentielle, une strat√©gie de pr√©entra√Ænement similaire √† celle du mod√®le BERT peut √™tre utilis√©e et appliqu√©e √† des s√©quences de prot√©ines non marqu√©es √† grande √©chelle. Il est d√©montr√© que le m√©canisme d'attention permet de saisir les relations de contact qui pourraient √™tre utiles pour la pr√©diction des interactions entre prot√©ines et alimenter la d√©couverte scientifique en biologie.

\\
![](https://cdn-images-1.medium.com/max/800/0*H20KG_4EnTW7iNSq.png)

*Figure source:* [*Salesforce Einstein*](https://blog.einstein.ai/provis/)

\\
***Nettoyage des donn√©es textuelles √† l'aide Dynamic Embedding Visualisation ***
\\
Il est primordial de disposer de donn√©es d‚Äôentra√Ænement de haute qualit√© pour les t√¢ches de traduction automatique, ce qui est plus difficile dans le cas des langues √† faibles ressources. Dans ce [blogpost](https://t.co/JmAJn6L6HG), Morgan McGuire d√©montre comment utiliser des techniques telles que l'int√©gration contextuelle multilingue, ainsi que la r√©duction de la dimensionnalit√© en utilisant UMAP pour identifier de mani√®re interactive les groupes bruyants et les supprimer afin d'am√©liorer les ensembles de donn√©es. L'animation suivante pr√©sente un groupe bruyant al√©atoire contenant des donn√©es en arabe et en pied de page de site web dans un ensemble de donn√©es irlandais-anglais.

# Education üéì
	
***Ethical & Responsible NLP***
\\
Rachel Tatman aborde des sujets importants dans son discours d'ouverture [What I won't build](https://slideslive.com/38929585/what-i-wont-build) √† [@WiNLPWorkshop] (https://twitter.com/WiNLPWorkshop). Les chercheurs et les praticiens doivent d√©terminer si les syst√®mes qu'ils mettent en place peuvent causer du tort, de la discrimination ou porter atteinte √† la vie priv√©e. Rachel nous invite √† poser une s√©rie de questions sur les utilisateurs, l'utilisation du syst√®me et son effet sur l'in√©galit√© syst√©mique. Elle pr√©conise √©galement de sensibiliser les autres aux risques et √† la mani√®re dont l'organisation d'un effort coordonn√© peut donner des r√©sultats.

\\
***Full Stack Deep Learning***
\\
Ce nouveau cours appel√© [Full Stack Deep Learning](https://course.fullstackdeeplearning.com/) vise √† fournir les connaissances n√©cessaires pour d√©ployer des mod√®les d'apprentissage approfondi en production. Ce cours en ligne gratuit aborde notamment la mise en place de projets d'apprentissage machine, la gestion des donn√©es, l‚Äôentra√Ænement et le d√©bogage, les tests et le d√©ploiement.
\\
![](https://cdn-images-1.medium.com/max/800/0*ps_3B2O9_nuwIZLW.png)

\\
***Reinforcement Learning Tutorial***
\\
Dans ce tutoriel d'apprentissage par renforcement (https://github.com/eemlcommunity/PracticalSessions2020/blob/master/rl/EEML2020_RL_Tutorial.ipynb) (disponible sous forme de Google Colab), Feryal d√©montre d'importants concepts de RL qui comprennent des algorithmes tels que l'it√©ration des politiques, le Q-Learning et le Q ajust√© aux neurones. En outre, une courte introduction √† l'apprentissage du renforcement profond est √©galement couverte, qui comprend des explications et le code de l'algorithme du r√©seau Q profond (DQN).

\\
![](https://cdn-images-1.medium.com/max/800/0*bMU-UL-wPPGmZMKo.png)


# Rester inform√© üéØ

Si vous cherchez d'autres aper√ßus et faits marquants de l'ACL de cette ann√©e, les liens suivants peuvent vous int√©resser :
- [Highlights of ACL 2020](https://medium.com/@vered1986/highlights-of-acl-2020-4ef9f27a4f0c) (by Vered Shwartz)
- [The missing pieces in virtual-ACL](https://medium.com/@yoav.goldberg/the-missing-pieces-in-virtual-acl-a05327cf9a18) (by Yoav Goldberg)
- [Takeaways from ACL 2020 Mentoring Session on Career Planning & becoming a research leader](https://medium.com/@maggie0/top-takeaways-from-an-acl-2020-mentoring-session-on-career-planning-becoming-a-research-leader-5c79ce75b98c) (by Zhijing Jin)

Quelques suggestions de challenges en cours si vous cherchez des id√©es pour d√©marrer et mettre en pratique vos connaissances en NLP et en ML :
- [Dravidian-CodeMix](https://dravidian-codemix.github.io/2020/index.html) - analyser des sentiments pour les langues dravidiennes dans le texte cod√© que l'on trouve dans les m√©dias sociaux
- [NLC2CMD](http://nlc2cmd.us-east.mybluemix.net/) - traduire les descriptions en anglaise des dans leur syntaxe Bash correspondante
- [IEEE BigData 2020 Cup] (https://knowledgepit.ml/predicting-escalations-in-customer-support/) - un d√©fi d'exploration de donn√©es pour pr√©dire l'augmentation de l'assistance technique aux clients en utilisant des techniques de langage naturel



# Mentions sp√©ciales ‚≠êÔ∏è

- Amit Chaudhary a publi√© un [article](https://amitness.com/2020/06/fasttext-embeddings/) qui passe en revue les d√©fis pos√©s par l'algorithme Word2Vec et la fa√ßon dont FastText les r√©sout en utilisant des informations de sous-mots.
- Dans cet article, George Ho [r√©sume](https://eigenfoo.xyz/transformers-in-nlp/) les tendances r√©centes en NLP. Il fournit un bref r√©sum√© des m√©thodes r√©centes, y compris d'autres aspects de ces mod√®les tels que la mise √† l'√©chelle et les diff√©rences de repr√©sentation.
- Kostas Stathoulopoulos a cr√©√© cet [outil de recherche](http://acl-explorer.eu-west-2.elasticbeanstalk.com/) pour explorer et d√©couvrir des articles r√©cents ou pass√©s de l‚ÄôACL . Vous pouvez rechercher des publications par auteur, le domaine d'√©tude, l'ann√©e, le titre de l'article, etc.
- [cutlet](https://www.dampfkraft.com/nlp/cutlet-python-romaji-converter.html) permet de convertir le japonais en romaji. Contrairement aux outils existants, il utilise le m√™me dictionnaire qu'un tokenizer japonais commun et a la possibilit√© d'utiliser l'orthographe originale pour les mots de pr√™t √©trangers.

----------

Vous pouvez retrouver la pr√©c√©dente newsletter [ici](https://dair.ai/NLP_Newsletter_-12_-FR/) \\

Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, vous pouvez utiliser ce [formulaire](https://forms.gle/3b7Q2w2bzsXE6uYo9).
\\

[Abonnez-vous](https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
