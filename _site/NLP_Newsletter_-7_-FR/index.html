<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶ &#8211; dair.ai</title>
<meta name="description" content="

">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">
<meta name="twitter:description" content="

">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/nlp_newsletter_7.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">
<meta property="og:description" content="

">
<meta property="og:url" content="http://localhost:4000/NLP_Newsletter_-7_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="http://localhost:4000/images/nlp_newsletter_7.png">







<link rel="canonical" href="http://localhost:4000/NLP_Newsletter_-7_-FR/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="http://localhost:4000/posts/" >Blog ‚úçÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/about/" >About ‚ÑπÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/newsletter/" >NLP Newsletter üóûÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/projects/" >Projects üí°</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub üìÅ</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ‚ú®</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium üì∞</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview üìò</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) üî•</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="http://localhost:4000/images/lbourdois.png" class="bio-photo" alt="Lo√Øck BOURDOIS bio photo">


  <h3 itemprop="name">Lo√Øck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="http://localhost:4000/NLP_Newsletter_-7_-FR/" rel="bookmark" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*9gNslKwKiRaffDt2RSOgoQ.png" alt="" /></p>

<h1 id="avant-propos-delvis">Avant-propos d‚ÄôElvis</h1>
<p><br />
Bienvenue au 7e num√©ro de la lettre d‚Äôinformation consacr√©e au NLP. J‚Äôesp√®re que vous passez une merveilleuse journ√©e et que vous et vos proches √™tes en s√©curit√© en ces temps difficiles. Nous avons d√©cid√© de publier ce bulletin pour apporter un peu de joie √† nos lecteurs, alors n‚Äôh√©sitez pas √† le lire quand vous aurez du temps libre. Pour l‚Äôinstant, concentrons-nous sur les choses qui sont de la plus haute priorit√© : nos familles et nos amis. ‚ù§Ô∏è üíõ üíö</p>

<p><br />
<strong><em>Quelques mises √† jour sur la lettre d‚Äôinformation sur le NLP et sur dair.ai.</em></strong></p>

<p><br />
Les traductions fran√ßaises et chinoises de tous les num√©ros pr√©c√©dents de la newsletter sont d√©sormais <a href="https://github.com/dair-ai/nlp_newsletter">disponibles</a>. D√©couvrez comment vous pouvez contribuer √† la traduction des num√©ros pr√©c√©dents et √† venir en cliquant sur ce <a href="https://github.com/dair-ai/dair-ai.github.io/issues/11">lien</a>.</p>

<p><br />
Nous avons r√©cemment cr√©√© deux nouveaux d√©p√¥ts GitHub qui contiennent des <a href="https://github.com/dair-ai/nlp_paper_summaries">r√©sum√©s de publications sur le NLP</a> et des <a href="https://github.com/dair-ai/pytorch_notebooks">notebooks PyTorch</a> pour vous aider √† d√©marrer avec les r√©seaux de neurones.</p>

<h1 id="publications-">Publications üìô</h1>

<p><strong><em>Mesure de la g√©n√©ralisation de la composition</em></strong></p>

<p><br />
Dans le contexte de l‚Äôapprentissage machine, la g√©n√©ralisation de la composition est la capacit√© d‚Äôapprendre √† repr√©senter le sens et des s√©quences (combinaisons in√©dites) √† partir de ce qui est appris dans le jeu d‚Äôentra√Ænement. √Ä ce jour, la mani√®re de mesurer correctement la composition dans les r√©seaux neuronaux n‚Äôest pas claire. Une √©quipe de Google AI <a href="https://ai.googleblog.com/2020/03/measuring-compositional-generalization.html">propose</a> l‚Äôun des plus grands benchmarks pour la g√©n√©ralisation de la composition en utilisant des t√¢ches telles que le question/ answering et l‚Äôanalyse s√©mantique. L‚Äôimage ci-dessous montre un exemple du mod√®le propos√© utilisant des atomes (produire, diriger, etc.) pour produire de nouveaux compos√©s, c‚Äôest-√†-dire des combinaisons d‚Äôatomes. L‚Äôid√©e de ce travail est de produire des √©chantillons entra√Ænement/test qui contiennent des exemples qui partagent des atomes similaires (blocs de construction pour g√©n√©rer des exemples) de distribution mais une distribution de compos√©s diff√©rente (la composition des atomes). Les auteurs affirment que c‚Äôest une fa√ßon plus fiable de tester la g√©n√©ralisation de la composition.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*lXmUWOY8HJL7YVn1.gif" alt="" /></p>

<p><em>Credit: Google AI Blog</em></p>

<p><br />
<strong><em>Fine-Tuning de mod√®les linguistiques pr√©-entra√Æn√©s : Initialisation des poids, ordonnancement des donn√©es et arr√™t anticip√©</em></strong></p>

<p><br />
Des chercheurs ont men√© une <a href="https://arxiv.org/abs/2002.06305">s√©rie d‚Äôessais de fine-tuning</a> pour mieux comprendre l‚Äôeffet de l‚Äôinitialisation du poids et de l‚Äôarr√™t pr√©coce dans la performance des mod√®les. Au cours de diverses exp√©riences qui ont n√©cessit√© des centaines de tunage de BERT, il a √©t√© constat√© que des graines al√©atoires distinctes donnent des r√©sultats tr√®s diff√©rents. En particulier, l‚Äô√©tude indique qu‚Äôune certaine initialisation des poids donne de bons r√©sultats pour un ensemble de t√¢ches. Toutes les donn√©es exp√©rimentales et les essais ont √©t√© rendus publics pour les autres chercheurs qui souhaitent mieux comprendre les diff√©rentes dynamiques lors de la mise au point.</p>

<p><br />
<strong><em>Une introduction aux circuits</em></strong></p>

<p><br />
Les chercheurs d‚ÄôOpenAI ont publi√© un <a href="https://distill.pub/2020/circuits/zoom-in/">article</a> sur l‚Äôinterpr√©tabilit√© des r√©seaux de neurones et proposent une nouvelle approche pour les interpr√©ter. Inspir√©s par la biologie cellulaire, les auteurs approfondissent la compr√©hension des mod√®les de vision et de ce qu‚Äôils apprennent en inspectant le poids des r√©seaux neuronaux. Essentiellement, l‚Äô√©tude pr√©sente quelques affirmations ainsi que des preuves recueillies qui, selon eux, pourraient ouvrir la voie √† une meilleure interpr√©tation des r√©seaux neuronaux.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*i0c-qpiire6dD4IqJVKlYg.png" alt="" /></p>

<p><br />
<strong><em>NLP Research Highlights‚Ää‚Äî‚ÄäIssue #1</em></strong></p>

<p><br />
Dans une nouvelle s√©rie de dair.ai intitul√©e <a href="https://medium.com/dair-ai/nlp-newsletter-bertology-primer-fastpages-t5-data-science-education-pytorch-notebooks-slow-8ae5d499e040">NLP Research Highlights</a>, nous fournissons des descriptions d√©taill√©es des recherches actuelles int√©ressantes et importantes sur le NLP. Dans le premier num√©ro trimestriel, les sujets vont de l‚Äôam√©lioration des mod√®les de langage √† l‚Äôam√©lioration des agents conversationnels en passant par les syst√®mes de reconnaissance vocale de pointe. Ces r√©sum√©s seront √©galement mis √† jour <a href="https://github.com/dair-ai/nlp_paper_summaries">ici</a>.</p>

<p><br />
<strong><em>Apprendre √† simuler la physique complexe avec les r√©seaux de graphes</em></strong></p>

<p><br />
Ces derniers mois, nous avons beaucoup parl√© des r√©seaux de neurones de graphes (GNN) en raison de leur efficacit√© non seulement en NLP mais aussi dans d‚Äôautres domaines tels que la g√©nomique et les mat√©riaux. Dans un r√©cent <a href="https://arxiv.org/abs/2002.09405">article</a>, des chercheurs proposent un cadre g√©n√©ral bas√© sur les r√©seaux de graphes qui est capable d‚Äôapprendre des simulations dans diff√©rents domaines tels que les fluides et les mat√©riaux d√©formables. Les auteurs affirment qu‚Äôils obtiennent des performances de pointe dans diff√©rents domaines et que leur approche g√©n√©rale est potentiellement le simulateur de physique le mieux appris √† ce jour. Les exp√©riences comprennent la simulation de mat√©riaux tels que le ¬´ goop over water ¬ª (je ne sais pas comment cela se traduit en fran√ßais) et d‚Äôautres interactions avec des obstacles rigides. Ils ont √©galement test√© un mod√®le pr√©-entra√Æn√© sur des t√¢ches hors distribution et ont trouv√© des r√©sultats prometteurs qui montrent la g√©n√©ralisation du framework √† des domaines plus vastes.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*48EolUDJoHpYRCTZxgn_qg.png" alt="" /></p>

<p><a href="https://arxiv.org/pdf/2002.09405.pdf"><em>(Sanchez-Gonzalez et al., 2020)</em></a></p>

<p><br />
<strong><em>Mod√®les BERT sp√©cifiques √† chaque langue</em></strong></p>

<p><br />
Le BERT en arabe (AraBERT) est maintenant disponible dans la librairie Transformer. Vous pouvez acc√©der au mod√®le <a href="https://huggingface.co/aubmindlab/bert-base-arabert">ici</a> et au document <a href="https://arxiv.org/abs/2003.00104">ici</a>. R√©cemment, une version japonaise de BERT a √©galement √©t√© <a href="https://github.com/akirakubo/bert-japanese-aozora">publi√©e</a>. Il existe √©galement une version polonaise de BERT appel√©e <a href="https://github.com/kldarek/polbert">Polbert</a>.</p>

<h1 id="cr√©ativit√©-√©thique-et-soci√©t√©-">Cr√©ativit√©, √©thique et soci√©t√© üåé</h1>

<p><strong><em>Pr√©visions des structures prot√©iques associ√©es au COVID-19</em></strong></p>

<p><br />
DeepMind d√©voile <a href="https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19">des structures pr√©dites par calcul</a> pour les prot√©ines li√©es au COVID-19. Les pr√©dictions sont directement obtenues √† partir des syst√®mes AlphaFold mais n‚Äôont pas √©t√© v√©rifi√©es exp√©rimentalement. L‚Äôid√©e de cette publication est d‚Äôencourager les contributions qui visent √† mieux comprendre le virus et son fonctionnement.</p>

<p><br />
<strong><em>Utilisation du GPT2 pour une exp√©rience sur des cas judiciaires</em></strong></p>

<p><br />
Janelle Shane partage les <a href="https://aiweirdness.com/post/612669075940900864/court-cases-that-sound-like-the-weirdest-fights">r√©sultats</a> d‚Äôune exp√©rience amusante o√π un mod√®le GPT-2 est fine-tun√© pour g√©n√©rer des cas contre des objets inanim√©s. Le mod√®le a √©t√© aliment√© par une liste de cas o√π le gouvernement saisissait des marchandises de contrebande ou dangereuses. Cela a g√©n√©r√© des cas comme ceux pr√©sent√©s dans l‚Äôimage ci-dessous.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*E5mHmkm1h4VQJ2Ni.png" alt="" /></p>

<p><a href="https://aiweirdness.com/post/612669075940900864/court-cases-that-sound-like-the-weirdest-fights"><em>Source</em></a></p>

<p><br />
<strong><em>Vers une conception centr√©e sur l‚Äôhomme des frameworks de ML</em></strong></p>

<p><br />
Google AI <a href="https://ai.googleblog.com/2020/03/toward-human-centered-design-for-ml.html">a publi√©</a> les r√©sultats d‚Äôune enqu√™te √† grande √©chelle men√©e aupr√®s de 645 personnes ayant utilis√© TensorFlow.js. L‚Äôobjectif √©tait de conna√Ætre les caract√©ristiques les plus importantes ainsi que l‚Äôexp√©rience g√©n√©rale des d√©veloppeurs de logiciels non ML testant des frameworks de ML actuels.
Les r√©sultats montrent notamment que le ‚Äúmanque de compr√©hension conceptuelle du ML‚Äù entrave l‚Äôutilisation des frameworks de ML pour cet ensemble d‚Äôutilisateurs. Les participants √† l‚Äô√©tude ont √©galement signal√© le besoin de meilleures instructions sur la fa√ßon d‚Äôappliquer les mod√®les de ML √† diff√©rents probl√®mes et d‚Äôun soutien plus explicite pour les modifications.</p>

<p><br />
<strong><em>Tracking du visage et de la main avec MediaPipe et TensorFlow.js</em></strong></p>

<p><br />
Cet <a href="https://blog.tensorflow.org/2020/03/face-and-hand-tracking-in-browser-with-mediapipe-and-tensorflowjs.html?linkId=83996111">article sur TensorFlow</a> explique comment activer le suivi des visages et des mains en temps r√©el √† l‚Äôaide de TensorFlow.js et de MediaPipe.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*XsRsB-tSOZo9yWOc.gif" alt="" /></p>

<p><em>Credit: TensorFlow Blog</em></p>

<h1 id="outils-et-jeux-de-donn√©es-Ô∏è">Outils et jeux de donn√©es ‚öôÔ∏è</h1>

<p><strong><em>NLP Paper Summaries</em></strong></p>

<p><br />
Nous avons r√©cemment cr√©√© un <a href="https://github.com/dair-ai/nlp_paper_summaries">d√©p√¥t</a> contenant des r√©sum√©s des publications de NLP les int√©ressantes et les plus importantes de ces derni√®res ann√©es. L‚Äôobjectif est d‚Äôam√©liorer l‚Äôaccessibilit√© de ces recherches et sujets.</p>

<p><br />
<strong><em>Une librairie de vision par ordinateur pour PyTorch</em></strong>
<br />
<a href="https://github.com/kornia/kornia">Kornia</a> est une librairie open-source construite sur PyTorch qui permet aux chercheurs d‚Äôutiliser un ensemble d‚Äôop√©rateurs pour r√©aliser une vision informatique diff√©renci√©e en utilisant PyTorch. Parmi les fonctionnalit√©s, on trouve les transformations d‚Äôimages, l‚Äôestimation de la profondeur et le traitement d‚Äôimages de bas niveau, pour n‚Äôen citer que quelques-unes. Elle est fortement inspir√©e d‚ÄôOpenCV, mais la diff√©rence est qu‚Äôelle est destin√©e √† la recherche plut√¥t qu‚Äô√† la cr√©ation d‚Äôapplications pr√™tes √† la production.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*gN_-llcA4_3lIHYE.gif" alt="" /></p>

<p><br />
<strong><em>Pr√©sentation de DIET : une architecture qui surpasse le fine-tuning de BERT et qui est 6X plus rapide √† entra√Æner</em></strong></p>

<p><br />
DIET (Dual Intent and Entity Transformer) est une architecture multit√¢che de compr√©hension du langage naturel (NLU) <a href="https://blog.rasa.com/introducing-dual-intent-and-entity-transformer-diet-state-of-the-art-performance-on-a-lightweight-architecture/">propos√©e</a> par Rasa. Le framework se concentre sur l‚Äôentra√Ænement multit√¢che afin d‚Äôam√©liorer les r√©sultats en mati√®re de classification des intentions et de reconnaissance des entit√©s. Un autre avantage de DIET est que l‚Äôon peut utiliser n‚Äôimporte quel √©l√©ment pr√© entrain√© tels que BERT et GloVe. L‚Äôobjectif principale de cette librairie est de fournir un mod√®le qui am√©liore les performances actuelles de ces t√¢ches et qui est plus rapide √† entra√Æner (acc√©l√©ration de 6X). Le mod√®le est disponible dans la <a href="https://rasa.com/docs/rasa/1.8.0/nlu/components/#dietclassifier">librairie python Rasa Open Source</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*R_8FOU-CVZabv7hJ.jpg" alt="" /></p>

<p><a href="https://blog.rasa.com/introducing-dual-intent-and-entity-transformer-diet-state-of-the-art-performance-on-a-lightweight-architecture/?utm_source=twitter"><em>DIET framework</em></a></p>

<p><br />
<strong><em>Perdu parmi toutes les langues disponibles pour BERT ?</em></strong>
<a href="https://bertlang.unibocconi.it/">BERT Lang Street</a> est un site web qui offre la possibilit√© de rechercher plus de 30 mod√®les bas√©s sur le BERT, en 18 langues et 28 t√¢ches, soit un total de 177 entr√©es. Par exemple, si vous souhaitez conna√Ætre les r√©sultats de la classification des sentiments √† l‚Äôaide des mod√®les de BERT, il vous suffit de rechercher ‚Äúsentiment‚Äù dans la barre de recherche (exemple illustr√© dans la capture d‚Äô√©cran ci-dessous).</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*UuVno2eOAzYb_wlSSfukPA.png" alt="" /></p>

<p><br />
<strong><em>Med7</em></strong></p>

<p><br />
Andrey Kormilitzin publie <a href="https://github.com/kormilitzin/med7">Med7</a> qui est un mod√®le pour du NLP √† usage clinique (en particulier les t√¢ches de reconnaissance d‚Äôentit√©s nomm√©es (NER)) sur les dossiers m√©dicaux √©lectroniques. Le mod√®le peut identifier jusqu‚Äô√† sept cat√©gories et est disponible pour √™tre utilis√© avec la biblioth√®que spaCy.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*yOMqhvTwYnxB4LYXv2Mgjg.png" alt="" /></p>

<p><br />
<strong><em>Une biblioth√®que open source pour le ML quantique</em></strong></p>

<p><br />
<a href="https://ai.googleblog.com/2020/03/announcing-tensorflow-quantum-open.html">TensorFlow Quantum</a> est une biblioth√®que open-source qui fournit une bo√Æte √† outils pour le prototypage rapide de la recherche en ML quantique qui permet l‚Äôapplication de mod√®les de ML pour aborder des probl√®mes allant de la m√©decine aux mat√©riaux.</p>

<p><br />
<strong><em>Des r√©seaux infiniment larges, rapides et faciles, avec Neural Tangents</em></strong></p>

<p><br />
Neural Tangents est une librairie open-source qui permet aux chercheurs de d‚Äôentra√Æner des mod√®les de largeur finie ou infinie en utilisant JAX. Lisez l‚Äôarticle du blog de la version <a href="https://ai.googleblog.com/2020/03/fast-and-easy-infinitely-wide-networks.html">ici</a> et acc√©dez √† la librairie <a href="https://github.com/google/neural-tangents">ici</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*CojgKJwB_n_7-j0DJZ0y7g.png" alt="" /></p>

<h1 id="articles-et-blog-Ô∏è">Articles et Blog ‚úçÔ∏è</h1>

<p><strong><em>De PyTorch √† JAX</em></strong></p>

<p><br />
Sabrina J. Mielke a publi√© un <a href="https://sjmielke.com/jax-purify.htm">article</a> qui explique comment construire et entra√Æner des r√©seaux de neurones en utilisant JAX. L‚Äôarticle se concentre sur la comparaison du fonctionnement interne de PyTorch et de JAX lors de la construction de r√©seaux neuronaux, ce qui permet de mieux comprendre certains des avantages et des diff√©rences de JAX.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*Nrw4UnmnIZ__elHu.png" alt="" /></p>

<p><a href="https://sjmielke.com/jax-purify.htm"><em>Source</em></a></p>

<p><br />
<strong><em>Pourquoi utilisons-nous encore des jeux de donn√©es test cr√©√©s il y a plus de 18 ans ?</em></strong></p>

<p><br />
Dans cet <a href="https://ehudreiter.com/2020/03/02/why-use-18-year-old-bleu/">article de blog</a>, Ehud Reiter explique pourquoi nous utilisons encore de vieilles techniques d‚Äô√©valuation comme BLUE pour √©valuer les mod√®les de NLP pour des t√¢ches comme la traduction automatique</p>

<p><br />
<strong><em>Introduction √† BART</em></strong></p>

<p><br />
<a href="https://arxiv.org/abs/1910.13461">BART</a> est un mod√®le propos√© par Facebook qui implique un autoencodeur de d√©bruitage pour le pr√©-entra√Ænement de mod√®les seq2seq, ce qui am√©liorent les performances sur les t√¢ches de g√©n√©ration de texte telles que le r√©sum√© abstrait. Sam Shleifer fournit un <a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html">r√©sum√©</a> de BART et explique comment il l‚Äôa int√©gr√© dans la librairie Transformers de Hugging Face.</p>

<p><br />
<strong><em>Am√©liorations des Transformers</em></strong></p>

<p><br />
Madison May a r√©cemment r√©dig√© une <a href="https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context/">enqu√™te</a> d√©crivant les moyens d‚Äôam√©liorer les approches bas√©es sur les Transformers. L‚Äôarticle aborde ainsi les Sparse Transformers, les Adaptive Span Transformers, le Transformer-XL, les compressive Transformers, le Reformer, et les routing transformers.</p>

<p><br />
<strong><em>Contr√¥ler le style et le contenu dans la r√©daction automatique de textes</em></strong></p>

<p><br />
Malgr√© l‚Äôimpressionnante fluidit√© dont a fait preuve l‚Äô√©criture automatique des textes l‚Äôann√©e derni√®re, il est toujours difficile de contr√¥ler des attributs comme la structure ou le contenu du texte. Dans un <a href="https://creatext.ai/blog-posts/controllable-text-generation">r√©cent article de blog</a>, Manuel Tonneau √©voque les progr√®s r√©cents et les perspectives dans le domaine de la g√©n√©ration de texte contr√¥lable, du mod√®le GPT-2 de Hugging Face, fine-tun√© sur arXiv, au T5 de Google, en passant par CTRL de Salesforce et PPLM de Uber AI.</p>

<h1 id="education-">Education üéì</h1>

<p><strong><em>L‚Äôavenir du NLP en Python</em></strong></p>

<p><br />
Dans l‚Äôun de nos num√©ros pr√©c√©dents, nous avons pr√©sent√© <a href="https://thinc.ai/">THiNC</a>, qui est une librairie de DL fonctionnelle ax√©e sur la compatibilit√© avec d‚Äôautres librairies existantes. Ces <a href="https://speakerdeck.com/inesmontani/the-future-of-nlp-in-python-keynote-pycon-colombia-2020?slide=9">diapositives</a> pr√©sentent un peu plus cette livrairie qui a √©t√© utilis√©e par Ines Montani pour la conf√©rence PyCon Colombia.</p>

<p><br />
<strong><em>Les notebooks de Transformers</em></strong></p>

<p><br />
HuggingFace a publi√© un ensemble de <a href="https://github.com/huggingface/transformers/tree/master/notebooks">notebooks</a> qui aident √† d√©marrer avec leur librairie Transformers. Certains notebooks comprennent l‚Äôutilisation de la tokenisation, la mise en place de pipelines et l‚Äôentra√Ænement d‚Äôun mod√®le sur des donn√©es personnalis√©es.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*0AYHYUsHbaqV2vqN2zCzLQ.png" alt="" /></p>

<p><br />
<strong><em>TensorFlow 2.0 en 7 heures</em></strong></p>

<p><br />
Jetez un oeil √† ce <a href="https://www.freecodecamp.org/news/massive-tensorflow-2-0-free-course/">cours gratuity d‚Äôenviron 7h</a> consacr√© √† TensorFlow 2.0 abordant des sujets qui vont des r√©seaux neuronaux de base au NLP avec les RNN, en passant par une introduction √† l‚Äôapprentissage par renforcement.</p>

<p><br />
<strong><em>DeepMind: le podcast</em></strong></p>

<p><br />
DeepMind a publi√© tous les √©pisodes (sous la forme d‚Äôune <a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZBiUr6_Qf8YTS2Oqy3OGZEj">playlist YouTube</a>) de son podcast qui pr√©sente des scientifiques, des chercheurs et des ing√©nieurs discutant de sujets allant de l‚ÄôIAG aux neurosciences en passant par la robotique.</p>

<p><br />
<strong><em>Cours de Machine Learning et de Deep Learning</em></strong></p>

<p><br />
Berkeley rend public le <a href="https://sites.google.com/view/berkeley-cs294-158-sp20/home">programme complet</a> de son cours sur ‚Äúl‚Äôapprentissage profond non supervis√©‚Äù, principalement ax√© sur les aspects th√©oriques de l‚Äôapprentissage autosupervis√© ainsi que sur les mod√®les g√©n√©rateurs. Parmi les sujets abord√©s, citons les mod√®les de variables latentes, les mod√®les autor√©gressifs et les mod√®les de flux pour n‚Äôen citer que quelques-uns. Des vid√©os et des diapositives sont disponibles sur Youtube.</p>

<p><br />
Nous avons √©galement trouv√© cette importante <a href="https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/">liste</a> de cours en ligne sur l‚Äôapprentissage machine, le NLP et l‚Äôapprentissage approfondi.</p>

<p><br />
Et voici un autre cours intitul√© <a href="https://compstat-lmu.github.io/lecture_i2ml/index.html">‚ÄúIntroduction to Machine Learning‚Äù</a> qui comprend des sujets tels que la r√©gression supervis√©e, l‚Äô√©valuation des performances, les for√™ts al√©atoires, le r√©glage des param√®tres, des conseils pratiques, et bien plus encore.</p>

<h1 id="mentions-sp√©ciales-Ô∏è">Mentions sp√©ciales ‚≠êÔ∏è</h1>

<p>Connon Shorten a publi√© une <a href="https://www.youtube.com/watch?v=QWu7j1nb_jI&amp;feature=emb_logo">vid√©o</a> expliquant le mod√®le ELECTRA qui propose une technique appel√©e ‚Äúremplacement de la d√©tection de jeton‚Äù pour pr√©traiter les Transformers plus efficacement. Si vous √™tes int√©ress√©, nous avons √©galement r√©dig√© un bref r√©sum√© du mod√®le <a href="https://medium.com/dair-ai/nlp-research-highlights-cd522b21b01a">ici</a> (en anglais).</p>

<p><br />
Rachael Tatman travaille sur une nouvelle s√©rie intitul√©e <a href="https://www.youtube.com/watch?v=-G36q8_cYsc&amp;feature=emb_logo">NLP for Developers</a> o√π l‚Äôid√©e est de parler plus en profondeur des diff√©rentes m√©thodes de NLP du moment et d‚Äôexpliquer les probl√®mes communs que vous pourriez rencontrer.</p>

<p><br />
DeepMind diffuse <a href="https://youtu.be/WXuK6gekU1Y">AlphaGo - The Movie</a> sur YouTube pour c√©l√©brer le 4√®me anniversaire de la victoire d‚ÄôAlphaGo sur Lee Sedol au jeu de Go.</p>

<p><br />
OpenMined <a href="https://blog.openmined.org/introducing-openmined-research/">√©voque</a> les r√¥les d‚Äôing√©nieur de recherche et de chercheur scientifique, ce qui est une bonne occasion de s‚Äôimpliquer dans la pr√©servation de la vie priv√©e en mati√®re d‚ÄôIA.</p>

<hr />

<p>Vous pouvez retrouver la pr√©c√©dente newsletter <a href="https://dair.ai/NLP_Newsletter_-6_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n‚Äôh√©sitez pas √† contacter Elvis √† ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains num√©ros dans votre bo√Æte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/NLP_Newsletter_-7_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/NLP_Newsletter_-7_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/NLP_Newsletter_-7_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</strong> was published on <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
