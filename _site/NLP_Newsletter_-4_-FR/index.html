<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦ &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_4.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">
<meta property="og:description" content="">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter_-4_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_4.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter_-4_-FR/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog âœï¸</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About â„¹ï¸</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter ğŸ—ï¸</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects ğŸ’¡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub ğŸ“</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute âœ¨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium ğŸ“°</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview ğŸ“˜</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) ğŸ”¥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/lbourdois.png" class="bio-photo" alt="LoÃ¯ck BOURDOIS bio photo">


  <h3 itemprop="name">LoÃ¯ck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter_-4_-FR/" rel="bookmark" title="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*3vNKhz6K-oGQ8aLi3mo84Q.png" alt="" /></p>

<h1 id="publications-">Publications ğŸ“™</h1>
<p><strong><em>Turing-NLG: Un modÃ¨le linguistique de 17 milliards de paramÃ¨tres par Microsoft</em></strong></p>

<p><br />
Turing Natural Language Generation (T-NLG) est un modÃ¨le de 17 milliards de paramÃ¨tres <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/">proposÃ©</a> par les chercheurs en IA de Microsoft. Il est Ã  ce jour, le plus grand modÃ¨le de langage connu (illustrÃ© dans la figure ci-dessous) et est basÃ© sur un Transformer Ã  78 couches qui surpasse les rÃ©sultats prÃ©cÃ©dents (dÃ©tenus par Megatron-LM de NVIDIA) sur la perplexitÃ© de WikiText-103. Il a Ã©tÃ© testÃ© sur des tÃ¢ches telles que la rÃ©ponse Ã  des questions et le rÃ©sumÃ© abstrait. Le modÃ¨le est rendu possible par une librairie dâ€™optimisation de lâ€™entraÃ®nement appelÃ©e DeepSpeed avec ZeRO, qui est Ã©galement prÃ©sentÃ©e plus loin dans cette newsletter.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*CAZm7uj8EaupnvnJ.png" alt="" /></p>

<p><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/"><em>source</em></a></p>

<p><br />
<strong><em>Neural based Dependency Parsing</em></strong></p>

<p><br />
Miryam de Lhoneux a publiÃ© sa thÃ¨se de doctorat intitulÃ©e â€œ<a href="http://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1357373&amp;dswid=7905">Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages</a>â€. Ce travail porte sur lâ€™utilisation dâ€™approches neurales pour lâ€™<a href="http://nlpprogress.com/english/dependency_parsing.html">analyse des dÃ©pendances</a> dans les langues typologiquement diverses (câ€™est-Ã -dire les langues qui construisent et expriment le sens de maniÃ¨re structurellement diffÃ©rente). Ce travail rapporte que les RNN et les couches rÃ©cursives pourraient Ãªtre utiles pour lâ€™incorporation dans les parsers car elles aident Ã  informer les modÃ¨les avec des connaissances linguistiques importantes nÃ©cessaires pour lâ€™analyse. Dâ€™autres idÃ©es comprennent lâ€™utilisation de lâ€™analyse syntaxique polyglotte et des stratÃ©gies de partage de paramÃ¨tres pour lâ€™analyse syntaxique dans des langues apparentÃ©es et non apparentÃ©es.</p>

<p><br />
<strong><em>Extraction dâ€™informations de bout en bout dans le cloud avec BERT</em></strong></p>

<p><br />
Une Ã©quipe de chercheurs a publiÃ© un <a href="https://arxiv.org/abs/2002.01861">article</a> dÃ©crivant comment des modÃ¨les de Transformers comme BERT peuvent aider Ã  lâ€™extraction dâ€™informations de bout en bout dans des documents commerciaux spÃ©cifiques Ã  un domaine, tels que les dÃ©pÃ´ts rÃ©glementaires et les contrats de location de propriÃ©tÃ©. Non seulement ce type de travail peut aider Ã  optimiser les opÃ©rations commerciales, mais il montre Ã©galement lâ€™applicabilitÃ© et lâ€™efficacitÃ© des modÃ¨les basÃ©s sur BERT sur des rÃ©gimes avec trÃ¨s peu de donnÃ©es annotÃ©es. Une application, et ses dÃ©tails de mise en Å“uvre, qui fonctionne sur le cloud est Ã©galement proposÃ©e (voir figure ci-dessous).</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*KqViSLhP0otleDY-XFy3Bg.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2002.01861"><em>source</em></a></p>

<p><br />
<strong><em>Question Answering Benchmark</em></strong></p>

<p><br />
<a href="https://arxiv.org/abs/2001.11770v1">Wolfson et al. (2020)</a> ont publiÃ© un benchmark pour la comprÃ©hension des questions ainsi quâ€™une mÃ©thode pour dÃ©composer une question qui est nÃ©cessaire pour calculer une rÃ©ponse appropriÃ©e. Ils sâ€™appuient sur le crowdsourcing pour annoter les Ã©tapes nÃ©cessaires Ã  la dÃ©composition des questions. Pour montrer la faisabilitÃ© et lâ€™applicabilitÃ© de lâ€™approche, ils amÃ©liorent la rÃ©ponse aux questions du domaine ouvert en utilisant lâ€™ensemble de donnÃ©es HotPotQA.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*AztG-Inqt6LGQ87lSufRcw.png" alt="" /></p>

<p>â€Š<a href="https://arxiv.org/pdf/2001.11770v1.pdf"><em>source</em></a></p>

<p><br />
<strong><em>DonnÃ©es radioactives : le traÃ§age par lâ€™entraÃ®nement</em></strong></p>

<p><br />
Les chercheurs de Facebook AI ont rÃ©cemment publiÃ© un <a href="https://ai.facebook.com/blog/using-radioactive-data-to-detect-if-a-data-set-was-used-for-training/">travail</a> qui vise Ã  marquer les images (appelÃ©es donnÃ©es radioactives) afin de vÃ©rifier si un jeu de donnÃ©es particulier a Ã©tÃ© utilisÃ© pour lâ€™entraÃ®nement dâ€™un modÃ¨le de ML. Ils ont dÃ©couvert quâ€™il est possible dâ€™utiliser un marqueur intelligent qui dÃ©place les caractÃ©ristiques dans une direction, que le modÃ¨le utilise pour aider Ã  dÃ©tecter lâ€™utilisation de donnÃ©es radioactives mÃªme si seulement 1 % des donnÃ©es dâ€™entraÃ®nement sont radioactives. Câ€™est un dÃ©fi car tout changement dans les donnÃ©es peut potentiellement dÃ©grader la prÃ©cision du modÃ¨le. Selon les auteurs, ce travail peut Â« aider les chercheurs et les ingÃ©nieurs Ã  savoir quel jeu de donnÃ©es a Ã©tÃ© utilisÃ© pour entraÃ®ner un modÃ¨le, afin de mieux comprendre comment les diffÃ©rents ensembles de donnÃ©es affectent les performances des diffÃ©rents rÃ©seaux neuronaux Â». Cette approche semble importante pour les applications critiques de ML. Consultez le document complet <a href="https://arxiv.org/pdf/2002.00937.pdf">ici</a>.</p>

<p><br />
<strong><em>REALM: Retrieval-Augmented Language Model Pre-Training</em></strong></p>

<p><br />
<a href="https://kentonl.com/pub/gltpc.2020.pdf">REALM</a> est une approche dâ€™extraction Ã  grande Ã©chelle qui utilise un corpus de connaissances textuelles pour prÃ©-entraÃ®ner un modÃ¨le de langue de maniÃ¨re non supervisÃ©e. Les tÃ¢ches abordÃ©es et Ã©valuÃ©es Ã  lâ€™aide de REALM comprennent des questions ouvertes rÃ©pondant Ã  des critÃ¨res de rÃ©fÃ©rence. Outre lâ€™amÃ©lioration de la prÃ©cision du modÃ¨le, les autres avantages comprennent les composantes de modularitÃ© et dâ€™interprÃ©tabilitÃ©.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*MJO-yzCwsB5ydKGz7hKHVA.png" alt="" /></p>

<p><a href="https://kentonl.com/pub/gltpc.2020.pdf"><em>source</em></a></p>

<h1 id="crÃ©ativitÃ©-et-sociÃ©tÃ©-">CrÃ©ativitÃ© et sociÃ©tÃ© ğŸ¨</h1>

<p><strong><em>Permettre la prÃ©sentation Ã  distance de documents et dâ€™affiches lors de confÃ©rences scientifiques</em></strong></p>

<p><br />
La semaine derniÃ¨re, une <a href="https://www.change.org/p/organizers-of-data-science-and-machine-learning-conferences-neurips-icml-aistats-iclr-uai-allow-remote-paper-poster-presentations-at-conferences">pÃ©tition</a> a Ã©tÃ© lancÃ©e pour permettre la prÃ©sentation Ã  distance de documents et dâ€™affiches lors de confÃ©rences scientifiques comme celles liÃ©es au ML. Il semble que Yoshua Bengio, plaide pour que les gens aillent signer la pÃ©tition. Il lâ€™a clairement indiquÃ© dans son nouveau <a href="https://yoshuabengio.org/2020/02/10/fusce-risus/">blog</a>.</p>

<p><br />
<strong><em>DÃ©fi de lâ€™abstraction et du raisonnement</em></strong></p>

<p><br />
FranÃ§ois Chollet a rÃ©cemment mis en ligne un <a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview">concours Kaggle</a> oÃ¹ il a publiÃ© le Corpus dâ€™abstraction et de raisonnement (ARC). Il vise Ã  encourager les utilisateurs Ã  crÃ©er des systÃ¨mes dâ€™IA capables de rÃ©soudre des tÃ¢ches de raisonnement auxquelles ils nâ€™ont jamais Ã©tÃ© exposÃ©s. Lâ€™espoir est de commencer Ã  construire des systÃ¨mes dâ€™IA plus robustes, capables de rÃ©soudre mieux et rapidement de nouveaux problÃ¨mes par eux-mÃªmes, ce qui pourrait aider Ã  rÃ©soudre les applications du monde rÃ©el les plus difficiles, comme lâ€™amÃ©lioration des voitures autonomes.</p>

<p><br />
<strong><em>Publications de ML et NLP en 2019</em></strong></p>

<p><br />
Marek Rei publie son <a href="https://www.marekrei.com/blog/ml-and-nlp-publications-in-2019/">analyse annuelle</a> sur les statistiques en lien avec lâ€™apprentissage machine et le NLP pour lâ€™annÃ©e 2019. Les confÃ©rences incluses dans lâ€™analyse sont ACL, EMNLP, NAACL, EACL, COLING, TACL, CL, CoNLL, NeurIPS, ICML, ICLR, et AAAI.</p>

<p><br />
<strong><em>La croissance dâ€™automates cellulaires neuronaux</em></strong></p>

<p><br />
La morphogenÃ¨se est un processus dâ€™auto-organisation par lequel certaines crÃ©atures comme les salamandres peuvent se rÃ©gÃ©nÃ©rer ou rÃ©parer des dommages corporels. Ce processus est robuste aux perturbations et de nature adaptative. InspirÃ©s par ce phÃ©nomÃ¨ne biologique et par le besoin de mieux comprendre le processus, les chercheurs ont publiÃ© un <a href="https://distill.pub/2020/growing-ca/">article</a> intitulÃ© â€œGrowing Neural Cellular Automataâ€, qui adopte un modÃ¨le diffÃ©renciable pour la morphogenÃ¨se visant Ã  reproduire les comportements et les propriÃ©tÃ©s des systÃ¨mes dâ€™autorÃ©paration. Lâ€™espoir est de pouvoir construire des machines autorÃ©paratrices qui possÃ¨dent la mÃªme robustesse et plasticitÃ© que la vie biologique. En outre, cela permettrait de mieux comprendre le processus de rÃ©gÃ©nÃ©ration lui-mÃªme. Les applications qui peuvent en bÃ©nÃ©ficier comprennent la mÃ©decine rÃ©gÃ©nÃ©ratrice et la modÃ©lisation des systÃ¨mes sociaux et biologiques.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*2p62h1RaHD6d11LX8olnTA.png" alt="" /></p>

<p><a href="https://distill.pub/2020/growing-ca/"><em>source</em></a></p>

<p><br />
<strong><em>Visualiser lâ€™attention des Transformers</em></strong></p>

<p><br />
Hendrik Strobelt a partagÃ© ce <a href="https://github.com/SIDN-IAP/attnvis">repertoire</a> qui montre comment construire rapidement une visualisation interactive simple de lâ€™attention dâ€™un Transformer Ã  travers une application web en utilisant la bibliothÃ¨que HuggingFace et d3.js.</p>

<p><br />
<strong><em>SketchTransfer : Une nouvelle tÃ¢che stimulante pour explorer lâ€™invariance des dÃ©tails et les abstractions apprises par les rÃ©seaux</em></strong></p>

<p><br />
<a href="https://arxiv.org/pdf/1912.11570.pdf">SketchTransfer</a> propose une nouvelle tÃ¢che pour tester la capacitÃ© des rÃ©seaux neuronaux Ã  supporter lâ€™invariance en prÃ©sence/absence de dÃ©tails. On a longtemps dÃ©battu du fait que les rÃ©seaux ne peuvent pas se gÃ©nÃ©raliser Ã  des variations qui nâ€™ont pas encore Ã©tÃ© observÃ©es pendant lâ€™entraÃ®nement, comme par exemple traiter les dÃ©tails visuels manquants lorsquâ€™ils regardent des dessins animÃ©s. Le document examine et publie un ensemble de donnÃ©es pour aider les chercheurs Ã  Ã©tudier attentivement le problÃ¨me de Â« lâ€™invariance des dÃ©tails Â» en fournissant des croquis non Ã©tiquetÃ©s et des exemples Ã©tiquetÃ©s dâ€™images rÃ©elles.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*jdYuMoHiu2yya5rHzZyjwQ.png" alt="" /></p>

<p><a href="https://arxiv.org/pdf/1912.11570.pdf"><em>source</em></a></p>

<h1 id="outils-et-jeux-de-donnÃ©es-ï¸">Outils et jeux de donnÃ©es âš™ï¸</h1>

<p><strong><em>DeepSpeed + ZeRO</em></strong></p>

<p><br />
Microsoft a dÃ©voilÃ©e une librairie dâ€™optimisation pour lâ€™entrainement appelÃ©e DeepSpeed. Elle est compatible avec PyTorch et peut permettre lâ€™entrainement dâ€™un modÃ¨le de 100 milliards de paramÃ¨tres. La librairie se concentre sur quatre aspects importants de lâ€™entrainement dâ€™un modÃ¨le : lâ€™Ã©chelle, la vitesse, le coÃ»t et la convivialitÃ©. DeepSpeed a Ã©tÃ© <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/">lancÃ©</a> en mÃªme temps que ZeRO. ZeRO est une technologie dâ€™optimisation de la mÃ©moire qui permet de faire du deep learning distribuÃ© Ã  grande Ã©chelle sur GPU tout en amÃ©liorant le dÃ©bit de trois Ã  cinq fois plus que le meilleur systÃ¨me actuel.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*MXDI1f3cSBrY5w2g.gif" alt="" /></p>

<p><a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/"><em>source</em></a></p>

<p><br />
<strong><em>Une librairie pour mener des recherches rapides et efficaces sur le DL en 3D</em></strong></p>

<p><br />
<a href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/">PyTorch3D</a> est une boÃ®te Ã  outils open-source pour la recherche sur le DL en 3D. La librairie consiste en des implÃ©mentations rapides et optimisÃ©es dâ€™opÃ©rateurs 3D et de fonctions de perte frÃ©quemment utilisÃ©s. Elle est Ã©galement dotÃ©e dâ€™un moteur de rendu modulaire et diffÃ©renciable qui permet de mener des recherches sur des entrÃ©es 3D complexes et de faire des prÃ©visions 3D de haute qualitÃ©.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*VbspKMmPBUsgpdnIkd5jYA.png" alt="" /></p>

<p><a href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/"><em>source</em></a></p>

<p><br />
<strong><em>Gestion de la configuration de projets de ML</em></strong></p>

<p><br />
Hydra est un outil pour gÃ©rer plus efficacement les projets de ML complexes. Il est destinÃ© Ã  aider les chercheurs de PyTorch en offrant une rÃ©utilisation fonctionnelle des configurations. Son principal avantage est quâ€™il permet au programmeur de gÃ©rer la configuration comme du code de composition, ce qui signifie que le fichier de configuration peut Ãªtre facilement Ã©crasÃ©. Hydra peut Ã©galement aider Ã  gÃ©rer automatiquement le rÃ©pertoire de travail des rÃ©sultats de votre projet de ML, ce qui est utile lorsque vous avez besoin de sauvegarder et dâ€™accÃ©der aux rÃ©sultats de plusieurs expÃ©riences pour des travaux multiples. Pour en savoir plus, cliquez <a href="https://medium.com/pytorch/hydra-a-fresh-look-at-configuration-for-machine-learning-projects-50583186b710">ici</a>.</p>

<p><br />
<strong><em>Une boÃ®te Ã  outils pour lâ€™infÃ©rence causale avec les rÃ©seaux bayÃ©siens</em></strong></p>

<p><br />
<a href="https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html">CausalNex</a> est une boÃ®te Ã  outils pour â€œlâ€™infÃ©rence causale avec les rÃ©seaux bayÃ©siensâ€. Lâ€™outil vise Ã  combiner lâ€™apprentissage machine et le raisonnement causal pour dÃ©couvrir des relations structurelles dans les donnÃ©es. Les auteurs ont Ã©galement prÃ©parÃ© un guide dâ€™introduction sur le pourquoi et le comment de lâ€™infÃ©rence causale avec les rÃ©seaux bayÃ©siens en utilisant la librairie Python proposÃ©e.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*EYwKhdnscR7ZLuNkTqCS2Q.png" alt="" /></p>

<p><a href="https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html"><em>source</em></a></p>

<p><br />
<strong><em>Google Colab Pro est maintenant disponible</em></strong></p>

<p><br />
Google Colab propose dÃ©sormais une Ã©dition Pro, qui offre des avantages tels quâ€™un accÃ¨s exclusif Ã  des GPU et TPU plus rapides, des durÃ©es dâ€™exÃ©cution plus longues et plus de mÃ©moire.</p>

<p><br />
<strong><em>TyDi QA: Un benchmark pour le Question/Anwsering multilingues</em></strong></p>

<p><br />
Google AI publie <a href="https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html">TyDi QA</a>, un ensemble de donnÃ©es multilingues qui peut encourager les chercheurs Ã  rÃ©pondre Ã  des questions dans des langues plus typologiquement diverses. Câ€™est Ã  dire qui construisent et expriment le sens de diffÃ©rentes maniÃ¨res. Lâ€™idÃ©e est de motiver les chercheurs Ã  construire des modÃ¨les plus robustes sur des langues typologiquement Ã©loignÃ©es, telles que lâ€™arabe, le bengali, le corÃ©en, le russe, le tÃ©lougou et le thaÃ¯, afin de gÃ©nÃ©raliser Ã  encore plus de langues.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*1dZv5you3jigdrQ2uAKzUw.png" alt="" /></p>

<p><a href="https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html"><em>source</em></a></p>

<p><br />
<strong><em>Question Answering pour Node.js</em></strong></p>

<p><br />
Hugging Face publie une <a href="https://github.com/huggingface/node-question-answering">librairie</a> de questions/rÃ©ponses basÃ©e sur DistilBERT. Ce modÃ¨le peut fonctionner en production en utilisant Node.js avec seulement 3 lignes de code. Le modÃ¨le tire parti de la mise en Å“uvre rapide de Tokenizers, et de TensorFlow.js (une bibliothÃ¨que populaire pour lâ€™utilisation de modÃ¨les dâ€™apprentissage machine avec Javascript).</p>

<h1 id="ethique-en-ia-">Ethique en IA ğŸš¨</h1>

<p><strong><em>Identifier les biais subjectifs dans les textes</em></strong></p>

<p><br />
Ce <a href="https://podcasts.apple.com/us/podcast/will-ai-help-identify-bias-or-perpetuate-it-with-diyi-yang/id1435564422?i=1000464141922">podcast</a> prÃ©sente Diyi Yang, chercheur en sciences sociales computationnelles, qui explique comment les systÃ¨mes dâ€™IA peuvent aider Ã  identifier les biais subjectifs dans les informations textuelles. Il sâ€™agit dâ€™un domaine de recherche important impliquant les systÃ¨mes dâ€™IA et de NLP. En particulier lorsque nous discutons de la consommation de mÃ©dias textuels tels que les news qui peuvent Ãªtre facilement encadrÃ©s pour biaiser les consommateurs alors quâ€™en rÃ©alitÃ© ils devraient viser Ã  Ãªtre plus objectifs. Du point de vue de lâ€™application, il devient essentiel dâ€™identifier automatiquement le biais subjectif prÃ©sent dans les mÃ©dias textuels afin dâ€™aider les consommateurs Ã  devenir plus conscients du contenu quâ€™ils consomment. Lâ€™Ã©pisode traite Ã©galement de la maniÃ¨re dont lâ€™IA peut Ã©galement perpÃ©tuer le biais.</p>

<p><br />
<strong><em>Intelligence artificielle, valeurs et alignement</em></strong></p>

<p><br />
Lâ€™essor des systÃ¨mes dâ€™IA et la maniÃ¨re dont ils sâ€™alignent sur les valeurs humaines est un domaine de recherche actif qui implique lâ€™Ã©thique dans les systÃ¨mes dâ€™IA. DeepMind a rÃ©cemment publiÃ© un <a href="https://deepmind.com/research/publications/Artificial-Intelligence-Values-and-Alignment">papier</a> qui examine plus en profondeur les questions philosophiques entourant lâ€™alignement de lâ€™IA. Le rapport se concentre sur deux parties :  technique (câ€™est-Ã -dire comment coder les valeurs qui rendent les rÃ©sultats des agents dâ€™IA fiables) et normative (quels principes seraient justes Ã  coder dans lâ€™IA). Le document prÃ©conise une approche fondÃ©e sur des principes visant Ã  prÃ©server Ã  prÃ©server un traitement Ã©quitable malgrÃ© la diffÃ©rence de croyances et dâ€™opinions.</p>

<p><br />
<strong><em>Sur lâ€™audit des systÃ¨mes dâ€™IA</em></strong></p>

<p><br />
VentureBeat rapporte que Google Researchers, en collaboration avec dâ€™autres groupes, a crÃ©Ã© un framework appelÃ© SMACTR qui permet aux ingÃ©nieurs de vÃ©rifier les systÃ¨mes dâ€™IA. La raison de ce travail est de combler le fossÃ© de responsabilitÃ© qui existe avec les systÃ¨mes dâ€™IA actuels qui sont mis dans la nature pour Ãªtre utilisÃ©s par les consommateurs. Pour plus dâ€™informations, lire les deux documents suivants :  <a href="https://venturebeat.com/2020/01/30/google-researchers-release-audit-framework-to-close-ai-accountability-gap/">ici</a> et <a href="https://dl.acm.org/doi/abs/10.1145/3351095.3372873">ici</a>.</p>

<h1 id="articles-et-blog-ï¸">Articles et Blog âœï¸</h1>

<p><strong><em>La distillation de modÃ¨le en NLP</em></strong></p>

<p><br />
Dans un <a href="https://soundcloud.com/nlp-highlights/104-model-distillation-with-victor-sanh-and-thomas-wolf">podcast</a> de NLP Highlights, Thomas Wolf et Victor Sanh parlent de la distillation de modÃ¨les et de la faÃ§on dont elle peut Ãªtre utilisÃ©e comme une approche rÃ©alisable pour comprimer de grands modÃ¨les comme BERT. Ce concept est discutÃ© plus en dÃ©tail dans la mÃ©thode quâ€™ils proposent, appelÃ©e <a href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, dans laquelle ils construisent des modÃ¨les plus petits (basÃ©s sur la mÃªme architecture quâ€™un modÃ¨le plus grand) pour essayer dâ€™imiter le comportement du modÃ¨le plus grand. En substance, le petit modÃ¨le (lâ€™Ã©tudiant) essaie de sâ€™adapter Ã  la distribution de probabilitÃ© de lâ€™enseignant.</p>

<p><br />
<em>**BERT, ELMo, &amp; GPT-2: Dans quelle mesure les reprÃ©sentations contextuelles des mots sont-elles contextualisÃ©es ? **</em></p>

<p><br />
On a beaucoup parlÃ© du succÃ¨s des mÃ©thodes contextualisÃ©es comme BERT pour aborder une grande variÃ©tÃ© de tÃ¢ches complexes de NLP. Dans cet <a href="https://kawine.github.io/blog/nlp/2020/02/03/contextual.html">article</a>, Kawin Ethayarajh tente de rÃ©pondre Ã  la question qui consiste Ã  savoir comment sont contextualisÃ©s les mots dans les modÃ¨les comme BERT, ELMo et le GPT-2. Les sujets abordÃ©s comprennent les mesures de la contextualitÃ©, la spÃ©cificitÃ© du contexte et les comparaisons entre les embeddings statiques et les reprÃ©sentations contextualisÃ©es.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*70aIv1Fkkz4rnHgQ.png" alt="" /></p>

<p><a href="https://kawine.github.io/blog/nlp/2020/02/03/contextual.html"><em>source</em></a></p>

<p><br />
<strong><em>Sparsity in Neural Networks</em></strong></p>

<p><br />
FranÃ§ois Lagunas, a Ã©crit cet <a href="https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70">article Medium</a> pour discuter de son optimisme quant Ã  lâ€™adoption de tenseurs clairsemÃ©s dans les modÃ¨les de rÃ©seaux de neurones. Lâ€™espoir est dâ€™utiliser une forme de raretÃ© pour rÃ©duire la taille des modÃ¨les actuels qui, Ã  un moment donnÃ©, deviennent peu pratiques en raison de leur taille et de leur vitesse. Ce concept pourrait Ãªtre intÃ©ressant Ã  explorer en ML en raison de la taille mÃªme des modÃ¨les actuels comme les Transformers. Cependant, les dÃ©tails de mise en Å“uvre ne sont pas aussi clairs du point de vue des outils de dÃ©veloppement disponibles, et câ€™est quelque chose sur lequel la communautÃ© travaille dÃ©jÃ .</p>

<p><br />
<strong><em>EntraÃ®ner votre propre modÃ¨le linguistique</em></strong></p>

<p><br />
Si vous souhaitez apprendre Ã  entrainer un modÃ¨le de zÃ©ro, consultez ce <a href="https://huggingface.co/blog/how-to-train">tutoriel</a> dâ€™Hugging Face. Ils utilisent Ã©videmment leurs propres bibliothÃ¨ques Transformers et Tokenizers pour entraÃ®ner le modÃ¨le.</p>

<p><br />
<strong><em>Tokenizers: Comment les machines lisent</em></strong></p>

<p><br />
Cathal Horan a publiÃ© un <a href="https://blog.floydhub.com/tokenization-nlp/">article</a> sur la maniÃ¨re dont les modÃ¨les de NLP les plus rÃ©cents utilisent les tokenizers. Il explique Ã©galement pourquoi la tokenisation est un domaine de recherche actif, passionnant et important. Lâ€™article vous montre mÃªme comment entraÃ®ner vos propres tokenizers en utilisant des mÃ©thodes de tokenisation comme SentencePiece et WordPiece.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*Vkjw5n9Sz0Was43haVNJMg.png" alt="" /></p>

<p><a href="https://blog.floydhub.com/tokenization-nlp/%27"><em>source</em></a></p>

<h1 id="education-">Education ğŸ“</h1>

<p><strong><em>ML Ã  lâ€™universitÃ© dâ€™Amsterdam</em></strong></p>

<p><br />
Vous pouvez dÃ©sormais suivre en ligne le <a href="https://mlvu.github.io/">cours dâ€™apprentissage machine 2020 MLVU</a>, qui comprend des diapositives, des <a href="https://www.youtube.com/watch?v=excCZSTJEPs&amp;feature=youtu.be">vidÃ©os</a> et le programme. Il sâ€™agit dâ€™une introduction au ML, mais il comporte Ã©galement dâ€™autres sujets liÃ©s Ã  lâ€™apprentissage approfondi, tels que les VAE et les GAN.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*zFpU2rQL5Fby7X3boJyQNg.png" alt="" /></p>

<p><a href="https://mlvu.github.io/"><em>source</em></a></p>

<p><br />
<strong><em>Ressources mathÃ©matiques pour le ML</em></strong></p>

<p><br />
Suzana IliÄ‡ et le Machine Learning Tokyo (MLT) ont fait un travail remarquable en termes de dÃ©mocratisation de lâ€™Ã©ducation au ML. Par exemple, consultez ce <a href="https://github.com/Machine-Learning-Tokyo/Math_resources">rÃ©pertoire</a> qui prÃ©sente une collection de ressources en ligne gratuites pour apprendre les fondements des concepts mathÃ©matiques utilisÃ©s en ML.</p>

<p><br />
<strong><em>Introduction au Deep Learning</em></strong></p>

<p><br />
Suivez le cours â€œIntroduction to Deep Learningâ€ du MIT sur ce <a href="http://introtodeeplearning.com/">site</a>. De nouveaux cours seront publiÃ©s chaque semaine et toutes les diapositives, vidÃ©os et codes seront publiÃ©s.</p>

<p><br />
<strong><em>Deep Learning avec PyTorch</em></strong></p>

<p><br />
Alfredo Canziani a publiÃ© les diapositives et les notebooks pour son mini-cours sur lâ€™apprentissage profond avec PyTorch. Le dÃ©pÃ´t contient Ã©galement un <a href="https://atcold.github.io/pytorch-Deep-Learning/">site web complÃ©mentaire</a> qui comprend des descriptions textuelles des concepts enseignÃ©s dans le cours.</p>

<p><br />
<strong><em>Missing Semester of Your CS</em></strong></p>

<p><br />
Le â€œ<a href="https://missing.csail.mit.edu/">Missing Semester of Your CS</a>â€ est un cours en ligne pouvant Ãªtre utile aux spÃ©cialistes des donnÃ©es ayant une formation autre que celle du dÃ©veloppement. Il comprend des sujets tels que les outils shell, les scripts et le contrÃ´le de version. Le cours a Ã©tÃ© publiÃ© par des membres du corps enseignant du MIT.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*weUnTXxmHxYf-B2DDaslvw.png" alt="" /></p>

<p><a href="https://missing.csail.mit.edu/2020/shell-tools/"><em>source</em></a></p>

<p><br />
<strong><em>Deep Learning avancÃ©</em></strong></p>

<p><br />
La CMU a publiÃ© les diapositives et le programme du cours â€œ<a href="https://andrejristeski.github.io/10707-S20/syllabus.html">Advanced Deep Learning</a>â€ qui comprend des sujets tels que les modÃ¨les autorÃ©gressifs, les modÃ¨les gÃ©nÃ©rateurs et lâ€™apprentissage autosurveillÃ©/prÃ©dictif. Le cours sâ€™adresse aux Ã©tudiants de master ou de doctorat ayant une formation avancÃ©e en ML.</p>

<h1 id="mentions-spÃ©ciales-ï¸">Mentions spÃ©ciales â­ï¸</h1>

<p>Xu et ses collaborateurs (2020) ont proposÃ© une <a href="https://arxiv.org/abs/2002.02925">mÃ©thode</a> pour remplacer et compresser progressivement un modÃ¨le BERT en le divisant en ses composantes dâ€™origine. Le modÃ¨le proposÃ© surpasse les autres approches de distillation sur le rÃ©fÃ©rentiel GLUE.</p>

<p><br />
Le cours â€œ<a href="https://compstat-lmu.github.io/lecture_i2ml/index.html">Introduction Ã  lâ€™apprentissage machine</a>â€ couvre les bases du ML, la rÃ©gression supervisÃ©e, les forÃªts alÃ©atoires, le tuning des paramÃ¨tres et bien dâ€™autres sujets fondamentaux du ML.</p>

<p><br />
Le modÃ¨le grec de BERT (<a href="https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1">GreekBERT</a>) est maintenant disponible sur Transformers.</p>

<p><br />
Jeremy Howard publie un <a href="https://arxiv.org/abs/2002.04688">article</a> dÃ©crivant la librairie fastai. Il sâ€™agit dâ€™une lecture recommandÃ©e aux dÃ©veloppeurs de logiciels qui travaillent Ã  la crÃ©ation et Ã  lâ€™amÃ©lioration des librairies dâ€™apprentissage profond et de ML.</p>

<p><br />
Deeplearning.ai complÃ¨te la publication des quatre cours de TensorFlow : <a href="https://www.coursera.org/specializations/tensorflow-data-and-deployment">Data and Deployment Specialization</a>. Cette spÃ©cialisation vise principalement Ã  apprendre aux dÃ©veloppeurs comment dÃ©ployer efficacement des modÃ¨les dans diffÃ©rents scÃ©narios et utiliser les donnÃ©es de maniÃ¨re intÃ©ressante.</p>

<p><br />
Sebastian Raschka a rÃ©cemment publiÃ© un <a href="https://arxiv.org/abs/2002.04803">article</a> intitulÃ© â€œMachine Learning in Pythonâ€ : Principaux dÃ©veloppements et tendances technologiques en matiÃ¨re de science des donnÃ©es, dâ€™apprentissage automatique et dâ€™intelligence artificielleâ€. Ce document est un examen complet du paysage des outils dâ€™apprentissage machine. Il permet de comprendre les avantages de certaines librairies et les concepts utilisÃ©s dans lâ€™ingÃ©nierie ML. En outre, un mot sur lâ€™avenir des bibliothÃ¨ques dâ€™apprentissage machine basÃ©es sur Python est fourni.</p>

<hr />

<p>Vous pouvez retrouver la prÃ©cÃ©dente newsletter <a href="https://dair.ai/NLP_Newsletter_-3_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de donnÃ©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine Ã©dition de la newletter, nâ€™hÃ©sitez pas Ã  me contacter Ã  ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains numÃ©ros dans votre boÃ®te mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter_-4_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter_-4_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter_-4_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</strong> was published on <time datetime="2020-03-09T00:00:00-05:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ç®€æŠ¥ï¼ˆIssue#7ï¼‰: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP ç®€æŠ¥ï¼ˆIssue#7ï¼‰: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
