<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶ &#8211; dair.ai</title>
<meta name="description" content="Esta segunda newsletter aborda topics que v√£o de interpretabilidade de modelos para enovelamento de prote√≠nas (protein folding) at√© active transfer learning">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶">
<meta name="twitter:description" content="Esta segunda newsletter aborda topics que v√£o de interpretabilidade de modelos para enovelamento de prote√≠nas (protein folding) at√© active transfer learning">
<meta name="twitter:site" content="@dair_ai">
<meta name="twitter:creator" content="@flavioclesio">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_2.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶">
<meta property="og:description" content="Esta segunda newsletter aborda topics que v√£o de interpretabilidade de modelos para enovelamento de prote√≠nas (protein folding) at√© active transfer learning">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_2.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog ‚úçÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About ‚ÑπÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter üóûÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects üí°</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub üìÅ</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ‚ú®</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium üì∞</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview üìò</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) üî•</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/flavio.png" class="bio-photo" alt="Flavio Clesio bio photo">


  <h3 itemprop="name">Flavio Clesio</h3>
  <p>Machine Learning Engineer (NLP, CV, Marketplace RecSys)</p>

  <a href="http://twitter.com/flavioclesio" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  
  
  <a href="http://instagram.com/flavioclesio" class="author-social" target="_blank"><i class="fa fa-fw fa-instagram"></i> Instagram</a>
  
  <a href="http://github.com/fclesio" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" rel="bookmark" title="NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶">NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*mgWc3FhHPRfCxdPir6wSeg.png" alt="" /></p>

<p><br />
Bem vindo novamente √† NLP Newsletter! üëã Esta segunda newsletter aborda topicos que v√£o de interpretabilidade de modelos para enovelamento de prote√≠nas (protein folding) at√© active transfer learning. <em>Voc√™ pode encontrar a vers√£o Markdown desta edi√ß√£o no final.</em></p>

<h1 id="publica√ß√µes-">Publica√ß√µes üìô</h1>

<p><strong><em>Confiando na incerteza dos modelos</em></strong></p>

<p><br />
Um artigo recente do Google AI, publicado na NeurIPS, analisa se as probabilidades de um modelo refletem a sua capacidade de prever dados fora de distribui√ß√£o ou mudan√ßa no conjunto de dados (shifted data).</p>

<p><br />
Ensembles profundos (Deep ensembles) tiveram um melhor desempenho (<em>i.e.</em>, melhoraram a incerteza do modelo) no dataset com mudan√ßa no conjunto de dados (data shift), enquanto outros modelos n√£o tornaram-se mais incertos com o mesmo data shift, mas ao contrario transformaram-se confidentemente errados(Leia o paper <a href="https://arxiv.org/abs/1906.02530">aqui</a> e o sum√°rio <a href="https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html">aqui</a>.).</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*NrsUnHS1thKq3ChK.png" alt="" /></p>

<p><em>Corrup√ß√£o da imagem‚Ää‚Äî</em>‚Ää<a href="https://ai.googleblog.com/2020/01/can-you-trust-your-models-uncertainty.html"><em>fonte</em></a></p>

<p><br />
<strong><em>Generaliza√ß√£o Sistem√°tica</em></strong></p>

<p><br />
Um <a href="https://www.semanticscholar.org/paper/Systematic-Generalization%3A-What-Is-Required-and-Can-Bahdanau-Murty/6c7494a47cc5421a7b636c244e13586dc2dab007">trabalho interessante</a> publicado na ICLR apresenta uma compara√ß√£o entre modelos modulares e modelos gen√©ricos e as suas respectivas efetividades para <em>generaliza√ß√£o sistematica</em> em entendimento de linguagem (language understanding). Com base na avalia√ß√£o do <em>reasoning</em> realizada em uma tarefa em que se <a href="https://arxiv.org/abs/1909.01860">respondia uma pergunta visual</a>, os autores concluem que pode haver a necessidade de regularizadores e priorizadores expl√≠citos para se conseguir uma generaliza√ß√£o sistem√°tica.</p>

<p><br />
<strong><em>Um modelo eficiente baseado em Transformer chamado Reformer</em></strong></p>

<p><br />
√â bem conhecido que um modelo Transformer √© bastante limitado em rela√ß√£o √† janela de contexto que pode ser coberta, devido aos c√°lculos de algo custo computacional realizados na camada de <a href="https://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/">Attention</a>. Assim, s√≥ pode ser poss√≠vel aplicar o modelo Transformer a tamanhos de texto limitados ou gerar frases curtas e/ou pe√ßas musicais. O GoogleAI publicou recentemente uma variante eficiente de um modelo Transformer chamado <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">Reformer</a>. O foco principal deste m√©todo √© ser capaz de lidar com janelas de contexto muito mais altas e, ao mesmo tempo, reduzir os requisitos computacionais com a melhoria da efici√™ncia do uso de mem√≥ria. O Reformer usa o ‚Äúlocality-sensitive-hashing‚Äù (<a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing">LSH</a>) para agrupar vetores similares e criar segmentos a partir deles, o que permite o processamento paralelo. A camada de Attention √© ent√£o aplicada a estes segmentos menores e em partes vizinhas correspondentes - isto √©, o que reduz a carga computacional. A efici√™ncia de mem√≥ria √© obtida usando camadas revers√≠veis que permitem que as informa√ß√µes de entrada de cada camada sejam recalculadas sob demanda durante o treinamento via backpropagation. Esta √© uma t√©cnica simples que evita que o modelo tenha a necessidade de armazenar as ativa√ß√µes em mem√≥ria. Confira este <a href="https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb">notebook no Colab</a> para ver como um modelo Reformer pode ser aplicado a uma tarefa de gera√ß√£o de imagens.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*Q6FHJ5bqZRCrBAp9.png" alt="" /></p>

<p><em>‚ÄúLocality-sensitive-hashing: O Reformer assume uma sequ√™ncia de palavras de entrada, onde cada palavra √© na verdade um vetor representando palavras individuais (ou pixels, no caso das imagens) na primeira camada e contextos maiores nas camadas subsequentes. O LSH √© aplicado √† sequ√™ncia, depois que as palavras s√£o ordenadas pelo seu hash e particionadas. O Attention √© aplicado apenas dentro de um √∫nico peda√ßo e dos seus vizinhos imediatos‚Äù.‚Ää- <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">fonte</a></em></p>

<p><br />
 <strong><em>Adapta√ß√£o de Dominio de forma n√£o-supervisionada para Classifica√ß√£o de Textos</em></strong></p>

<p><br />
Este <a href="https://arxiv.org/abs/2001.04362">trabalho</a> prop√µe uma combina√ß√£o de medidas de dist√¢ncia incorporadas em uma fun√ß√£o de perda adicional, para treinar um modelo e melhorar a adapta√ß√£o n√£o-supervisionada do dom√≠nio. O modelo √© estendido a um DistanceNet Bandit que otimiza os resultados para ‚Äútransfer√™ncia para o dom√≠nio alvo de poucos recursos‚Äù. O principal problema abordado com este m√©todo √© como lidar com a disparidade entre os dados de diferentes dom√≠nios, especificamente no que diz respeito √† tarefas de NLP, como a an√°lise de sentimentos (sentiment analysis).</p>

<p><br />
<strong><em>Melhoria de Representa√ß√µes Contextualizadas</em></strong></p>

<p><br />
Este <a href="https://openreview.net/forum?id=r1xMH1BtvB">artigo</a> prop√µe uma tarefa de pr√©-treino mais eficiente em termos de amostragem chamada <em>detec√ß√£o de token</em>. Esta tarefa pode ser utilizada para treinar um modelo lingu√≠stico que √© mais eficiente do que m√©todos de pr√©-treino com modelagem de linguagem mascarada, como o BERT. O modelo √© chamado ELECTRA e suas representa√ß√µes contextualizadas superam as do BERT e XLNET com os mesmos dados e tamanho de modelo. O m√©todo funciona particularmente bem no regime de baixa computa√ß√£o. Este √© um esfor√ßo para construir modelos de linguagem menores e mais baratos.</p>

<p><br />
<strong><em>Interpretabilidade de Modelos</em></strong></p>

<p><br />
A publica√ß√£o mais recente da Distill intitulada ‚Äú<a href="https://distill.pub/2020/attribution-baselines/">Visualizing the Impact of Feature Attribution Baselines</a>‚Äù discute os <a href="https://medium.com/@kartikeyabhardwaj98/integrated-gradients-for-deep-neural-networks-c114e3968eae">gradientes integrados</a> que s√£o usados para interpretar redes neurais em v√°rios problemas, identificando quais recursos s√£o relevantes para prever um determinado ponto. O problema √© definir e preservar corretamente uma no√ß√£o de <em>falta</em> que √© o que se pretende com a entrada de base dos gradientes integrados. O desafio aqui, no contexto da interpretabilidade de modelos, √© que o m√©todo deve assegurar que o modelo n√£o destaque as caracter√≠sticas em falta como importantes, evitando ao mesmo tempo dar zero import√¢ncia √†s entradas de <em>baseline</em>, o que pode facilmente acontecer. O autor prop√µe avaliar quantitativamente os diferentes efeitos de algumas escolhas de <em>baseline</em> previamente utilizadas e propostas que melhor preservem a no√ß√£o de falta.</p>

<h1 id="criatividade-e-sociedade-">Criatividade e Sociedade üé®</h1>

<p><strong><em>Incompatibilidade de sentimentos</em></strong></p>

<p><br />
Este <a href="https://ieeexplore.ieee.org/abstract/document/8952437">estudo longitudinal</a> descobre que a emo√ß√£o extra√≠da atrav√©s do uso de algoritmos baseados em texto, muitas vezes n√£o √© a mesma que as emo√ß√µes auto-relatadas.</p>

<p><br />
<strong><em>Compreens√£o da dopamina e o enovelamento de prote√≠nas (protein folding)</em></strong></p>

<p><br />
A DeepMind lan√ßou recentemente <strong>dois</strong> artigos interessantes na revista Nature. O primeiro <a href="https://deepmind.com/blog/article/Dopamine-and-temporal-difference-learning-A-fruitful-relationship-between-neuroscience-and-AI">artigo</a> visa entender melhor como funciona a dopamina no c√©rebro usando a aprendizagem por refor√ßo. O segundo <a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery">paper</a> est√° mais relacionado com <a href="https://en.wikipedia.org/wiki/Protein_folding">enovelamento de prote√≠nas</a> e tenta compreend√™-lo melhor para ser capaz de potencialmente descobrir tratamentos para uma ampla gama de doen√ßas. Estes s√£o grandes exemplos de como sistemas de IA poderiam potencialmente ser aplicados em aplica√ß√µes do mundo real para ajudar a sociedade.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*0mfEtacqGLSrmaUlNjJa0g.png" alt="" /></p>

<p><em>‚ÄúFormas 3D complexas emergem de um conjunto de amino√°cidos.‚Äù‚Ää‚Äî</em>‚Ää<a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery"><em>fonte</em></a></p>

<p><br />
<strong><em>Entrevistas sobre o ML na sociedade</em></strong></p>

<p><br />
Em uma <a href="https://www.youtube.com/watch?v=I-EIVlHvHRM&amp;feature=youtu.be">entrevista</a> com a Wired, Refik Anadol discute o potencial dos algoritmos de aprendizagem de m√°quina para cria√ß√£o de arte. Este √© um excelente exemplo de como Machine Learning pode ser usado de forma a criativa.</p>

<p><br />
Um dos setores em que a IA pode ter um grande impacto √© na educa√ß√£o. Em um novo <a href="https://engineering.stanford.edu/magazine/article/emma-brunskill-amped-education-ai?sf115875862=1">epis√≥dio</a>, que faz parte de ‚Äú<em>The Future of Everything</em>‚Äù, Russ Altman e Emma Brunskill t√™m uma discuss√£o profunda sobre a aprendizagem assistida por computador.</p>

<h1 id="ferramentas-e-datasets-Ô∏è">Ferramentas e Datasets ‚öôÔ∏è</h1>

<p><strong><em>Modelos PyTorch em produ√ß√£o</em></strong></p>

<p><br />
O Cortex √© uma ferramenta para automatizar a infra-estrutura e implementar modelos PyTorch como APIs em produ√ß√£o com AWS. Saiba mais sobre como isso √© feito <a href="https://medium.com/pytorch/how-to-build-production-software-with-pytorch-9a8725382f2a">aqui</a>.</p>

<p><br />
<strong><em>Visualizando Sequ√™ncias de Gera√ß√£o de Texto</em></strong></p>

<p><br />
O time do Facebook AI lan√ßou o <a href="https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/">VizSeq</a>, que √© uma ferramenta que auxilia na avalia√ß√£o visual de seq√º√™ncias de gera√ß√£o de texto sob m√©tricas como BLUE e METEOR. O principal objetivo desta ferramenta √© fornecer uma an√°lise mais intuitiva dos conjuntos de dados de texto, alavancando visualiza√ß√µes e tornando-as mais escal√°veis e produtivas para todos os pesquisadores. Leia o artigo completo <a href="https://www.aclweb.org/anthology/D19-3043.pdf">aqui</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*Ff7BTxmEjUXHtYu9JkfClg.jpeg" alt="" /></p>

<p><a href="https://ai.facebook.com/blog/vizseq-a-visual-analysis-toolkit-for-accelerating-text-generation-research/"><em>Fonte</em></a></p>

<p><br />
<strong><em>Estado da arte em reconhecimento de fala online</em></strong></p>

<p><br />
O FacebookAI tornou open-source o <a href="https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/">wav2letter@anywhere</a> que √© um framework de infer√™ncia que √© baseado em um modelo ac√∫stico que usa o Transformer como base para reconhecimento de fala online de √∫ltima gera√ß√£o. Grandes melhorias est√£o em torno do tamanho do modelo e reduzindo a lat√™ncia entre o √°udio e a transcri√ß√£o, o que √© importante para seja obtida uma infer√™ncia mais r√°pida em tempo real.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*4_2Obuu8u8l2Vtp8UMHe7Q.gif" alt="" /></p>

<p><em>Processamento de fala‚Ää‚Äî</em>‚Ää<a href="https://ai.facebook.com/blog/online-speech-recognition-with-wav2letteranywhere/"><em>fonte</em></a></p>

<h1 id="√©tica-em-ia-">√âtica em IA üö®</h1>

<p><strong><em>Implica√ß√µes de IA</em></strong></p>

<p><br />
Em um esfor√ßo para evitar abusos e a√ß√µes anti√©ticas dos sistemas de IA sobre o p√∫blico, a Uni√£o Europ√©ia est√° considerando proibir a tecnologia de reconhecimento facial do p√∫blico por cinco anos. (<a href="https://www.reuters.com/article/us-eu-ai/eu-mulls-five-year-ban-on-facial-recognition-tech-in-public-areas-idUSKBN1ZF2QL">Hist√≥ria completa</a>)</p>

<p><br />
<strong><em>Os custos ambientais de NLP</em></strong></p>

<p><br />
Talvez negligenciado na maioria das vezes, este <a href="https://arxiv.org/abs/1906.02243">documento</a> discute as considera√ß√µes energ√©ticas e pol√≠ticas para abordagens modernas de deep learning em NLP. √â amplamente conhecido que os modelos atuais dependem de bilh√µes de par√¢metros e que, por sua vez, dependem de grandes recursos computacionais que demandam um consumo substancial de energia. Os autores esperam espalhar mais consci√™ncia sobre os custos ambientais envolvidos no treinamento desses modernos modelos de NLP.</p>

<p><br />
Zachary Lipton discute equidade(fairness), interpretabilidade e os perigos do solucionismo em Machine Learning nesta <a href="https://c4ejournal.net/2020/01/16/zack-lipton-fairness-interpretability-and-the-dangers-of-solutionism-ethics-of-ai-in-context2020-c4ej-2/">palestra</a> proferida na Universidade de Toronto. Os principais t√≥picos giraram em torno de considera√ß√µes cuidadosas e implica√ß√µes das abordagens de equidade em ML.</p>

<h1 id="artigos-e-posts-de-blogs-Ô∏è">Artigos e posts de blogs ‚úçÔ∏è</h1>

<p><strong><em>Open-Sourcing ML</em></strong></p>

<p><br />
Thomas Wolf, l√≠der cient√≠fico da Hugging Face, compartilha excelentes conselhos para aqueles que planejam fazer c√≥digo ML open-source ou pesquisa. Encontre o t√≥pico do Twitter <a href="https://twitter.com/Thom_Wolf/status/1216990543533821952?s=20">aqui</a>.</p>

<p><br />
<strong><em>Introdu√ß√£o para aprendizagem auto-supervisionada para computer vision</em></strong>*</p>

<p><br />
Jeremy Howard escreveu este grande <a href="https://www.fast.ai/2020/01/13/self_supervised/">blog post</a> introduzindo brevemente o conceito de aprendizagem auto-supervisionada no contexto de computer vision. Eu adoro estes pequenos resumos, pois ajudam a dar uma introdu√ß√£o confi√°vel no caso de voc√™ estar interessado em aplicar t√©cnicas deste dom√≠nio ao seu pr√≥prio problema.</p>

<p><br />
<strong><em>TinyBERT para problemas de busca</em></strong></p>

<p><br />
J√° vimos o sucesso de muitas variantes de modelos BERT (por exemplo, <a href="https://medium.com/huggingface/distilbert-8cf3380435b5">DistilBERT</a>) que utilizam alguma forma de <a href="https://nervanasystems.github.io/distiller/knowledge_distillation.html">destila√ß√£o do conhecimento</a> para diminuir substancialmente o tamanho do modelo e melhorar a velocidade. Algumas pessoas usaram uma variante do BERT chamada, <a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT">TinyBERT</a>, e aplicaram-na a uma <a href="https://towardsdatascience.com/tinybert-for-search-10x-faster-and-20x-smaller-than-bert-74cd1b6b5aec">solu√ß√£o de busca baseada em palavras-chave</a>. Este projeto foi inspirado por esta <a href="https://www.blog.google/products/search/search-language-understanding-bert/">solu√ß√£o de busca</a> para compreender as buscas propostas pelo Google. A maior parte da arquitetura que ela funciona √© em uma CPU padr√£o e pode ser usada para melhorar e entender os resultados das buscas.</p>

<p><br />
<strong><em>Active Transfer Learning</em></strong></p>

<p><br />
Rober Monarch escreveu este excelente <a href="https://medium.com/pytorch/https-medium-com-robert-munro-active-learning-with-pytorch-2f3ee8ebec">blog post</a> sobre <em>Active Transfer Learning</em> que faz parte de seu pr√≥ximo livro chamado <a href="https://www.manning.com/books/human-in-the-loop-machine-learning">Human-in-the-loop Machine Learning</a>. Ele est√° escrevendo √≥timos posts em seu blog sobre m√©todos para combinar intelig√™ncia humana e m√°quinas para resolu√ß√£o de problemas. Ele tamb√©m fornece implementa√ß√µes em PyTorch dos m√©todos discutidos.</p>

<p><br />
<strong><em>Revelando os segredos ocultos do BERT</em></strong></p>

<p><br />
Anna Roger escreveu este divertido e interessante <a href="https://text-machine-lab.github.io/blog/2020/bert-secrets/">blog post</a> que fala sobre o que realmente acontece com um BERT otimizado, e se os alegados pontos fortes s√£o usados para abordar tarefas posteriores, tais como an√°lise de sentimentos, vincula√ß√£o textual e infer√™ncia da linguagem natural, entre outras. Os resultados das an√°lises propostas sugerem que o BERT est√° excessivamente superparametrizado (overparameterized) e que os benef√≠cios identificados do componente de <em>self-attention</em> da estrutura podem n√£o ser necessariamente ben√©ficos como se imagina. Em particular no que diz respeito √† informa√ß√£o lingu√≠stica que est√° sendo codificada e utilizada para a parte de infer√™ncia.</p>

<h1 id="educa√ß√£o-">Educa√ß√£o üéì</h1>

<p><strong><em>Redes Neurais para NLP</em></strong></p>

<p><br />
Graham Neubig, professor de PNL na CMU, tem <a href="https://www.youtube.com/playlist?list=PL8PYTP1V4I8CJ7nMxMC8aXv8WqKYwj-aJ">lan√ßado alguns v√≠deos</a> para a aula ‚ÄúRedes Neurais para NLP‚Äù que est√° sendo ministrada neste semestre. Eu recomendo altamente esta playlist para aqueles interessados em aprender sobre os m√©todos modernos de NLP.</p>

<p><br />
<strong><em>Deep Learning Math (DeepMath)</em></strong></p>

<p><br />
Quer mergulhar profundamente na matem√°tica por tr√°s dos m√©todos de deep learning? Aqui est√° uma <a href="https://www.youtube.com/playlist?list=PLWQvhvMdDChzsThHFe4lYAff3pu2m0v2H">s√©rie de v√≠deo-palestras</a> com uma vasta gama de palestrantes.</p>

<p><br />
<strong><em>Cursos de Python e Tutoriais</em></strong></p>

<p><br />
Python tornou-se uma das linguagens de programa√ß√£o mais requisitadas n√£o s√≥ na ind√∫stria de TI, mas tamb√©m no espa√ßo da ci√™ncia dos dados. Em um esfor√ßo para qualificar alunos de todo o mundo com conhecimentos pr√°ticos de Python, o Google lan√ßou o ‚ÄúGoogle IT Automation with Python Professional Certificate‚Äù. Saiba mais sobre o lan√ßamento <a href="https://blog.google/outreach-initiatives/grow-with-google/new-certificate-help-people-grow-careers">aqui</a> e veja o curso <a href="https://www.coursera.org/professional-certificates/google-it-automation">aqui</a>. Embora o curso n√£o esteja diretamente relacionado ao ML ou √† IA, √© definitivamente um bom curso de fundamentos para deseja tornar-se proficiente com a linguagem Python. Bolsas de estudo tamb√©m est√£o dispon√≠veis.</p>

<p><br />
Aqui est√° outra <a href="https://www.youtube.com/watch?v=fMqL5vckiU0&amp;list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf">s√©rie de v√≠deos</a> promissora chamada ‚ÄúDeep Learning (for Audio) with Python‚Äù com foco no uso de Tensorflow e Python para constru√ß√£o de aplica√ß√µes relacionadas a √°udio/m√∫sica, e alavancando o uso de deep learning.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*N5d8-1La8khZ6-XwHL68sg.png" alt="" /></p>

<p><a href="https://www.youtube.com/watch?v=fMqL5vckiU0&amp;list=PL-wATfeyAMNrtbkCNsLcpoAyBBRJZVlnf"><em>fonte</em></a></p>

<p><br />
Andrew Trask lan√ßou um conjunto de <a href="https://c4ejournal.net/2020/01/16/zack-lipton-fairness-interpretability-and-the-dangers-of-solutionism-ethics-of-ai-in-context2020-c4ej-2/">notebooks com tutoriais passo-a-passo</a> para alcan√ßar deep learning de forma descentralizada com objetivo de preserva√ß√£o da privacidade. Todos os notebooks cont√™m implementa√ß√µes PyTorch e s√£o destinados a iniciantes.</p>

<p><br />
<strong><em>Estado da arte em Deep Learning</em></strong></p>

<p><br />
Confira esta <a href="https://www.youtube.com/watch?v=0VH1Lim8gL8">palestra em v√≠deo</a> de Lex Fridman sobre a recente pesquisa e desenvolvimento em Deep Learning. Ele fala sobre os principais avan√ßos em t√≥picos como perceptrons, redes neurais, backpropagation, CNN, deep learning, ImageNet, GANs, AlphaGo, e Transformers. Esta palestra faz parte da S√©rie de Deep Learning do MIT.</p>

<p><br />
<strong><em>Online learning e pesquisa</em></strong></p>

<p><br />
H√° muitas e grandes iniciativas online para colabora√ß√£o tanto em pesquisa quanto em aprendizagem. Os meus favoritos s√£o a sess√£o de leitura de matem√°tica <a href="https://twitter.com/__MLT__">MLT‚Äôs</a> e este novo esfor√ßo de colabora√ß√£o distribu√≠da em pesquisa AI iniciado por <a href="https://www.nightai.co/">nightai</a>. Recentemente, tem havido muitos grupos de estudo como este online e estes grupos de estudos s√£o √≥timas maneiras de mergulhar no mundo do ML.</p>

<p><br />
<strong><em>Perspectivas em aprendizagem por refor√ßo</em></strong></p>

<p><br />
Aprenda com a Dra. Katja Hofmann os principais conceitos e m√©todos de aprendizagem por refor√ßo nesta <a href="https://note.microsoft.com/MSR-Webinar-RL-Algorithm-to-Adoption-Registration-Live.html?wt.mc_id=twitter_MSR-WBNR_post_v3">s√©rie de webinars</a>.</p>

<h1 id="men√ß√µes-honrosas-Ô∏è">Men√ß√µes honrosas ‚≠êÔ∏è</h1>
<p>Confira <a href="https://gist.github.com/y0ast/d91d09565462125a1eb75acc65da1469">esta implementa√ß√£o limpa e auto-contida em PyTorch</a> da ResNet-18 aplicada ao CIFAR-10, que atinge ~94% de precis√£o.</p>

<p><br />
PyTorch 1.4 √© lan√ßado! Confira as notas de lan√ßamento <a href="https://github.com/pytorch/pytorch/releases/tag/v1.4.0">aqui</a>.</p>

<p><br />
Elona Shatri escreveu este excelente <a href="_COPY11@e.shatri1/what-is-optical-music-recognition-6515d8a53e01">resumo</a> sobre como ela pretende abordar o reconhecimento da m√∫sica √≥ptica usando deep learning.</p>

<p><br />
O t√≠tulo para este post no blog √© auto-explicativo: <a href="https://cims.nyu.edu/~andrewgw/caseforbdl/">‚ÄúThe Case for Bayesian Deep Learning‚Äù</a>‚Äù.</p>

<p><br />
Chris Said compartilha sua <a href="https://chris-said.io/2020/01/10/optimizing-sample-sizes-in-ab-testing-part-I/">experi√™ncia</a> na otimiza√ß√£o de tamanhos de amostras para testes A/B, uma parte importante em se tratando de Data Science de forma aplicada. Os t√≥picos incluem os custos e benef√≠cios de grandes tamanhos de amostras e melhores pr√°ticas para os profissionais.</p>

<p><br />
Neural Data Server (NDS) is a dedicated search engine for obtaining transfer learning data. Read about the method <a href="https://arxiv.org/abs/2001.02799">here</a> and the service <a href="http://aidemos.cs.toronto.edu/nds/">here</a>.</p>

<p>O Neural Data Server (NDS) √© um mecanismo de busca dedicado √† obten√ß√£o de dados via <em>transfer learning</em>. Leia sobre o m√©todo <a href="https://arxiv.org/abs/2001.02799">aqui</a> e o servi√ßo <a href="http://aidemos.cs.toronto.edu/nds/">aqui</a>.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,‚Ä¶</strong> was published on <time datetime="2020-01-19T00:00:00-06:00">January 19, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
