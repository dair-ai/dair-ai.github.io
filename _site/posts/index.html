<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>All Posts &#8211; dair.ai</title>
<meta name="description" content="A List of Posts">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="All Posts">
<meta name="twitter:description" content="A List of Posts">
<meta name="twitter:site" content="@dair_ai">
<meta name="twitter:creator" content="@dair_ai">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/avatar-background.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="All Posts">
<meta property="og:description" content="A List of Posts">
<meta property="og:url" content="http://localhost:4000/posts/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="http://localhost:4000/images/avatar-background.png">







<link rel="canonical" href="http://localhost:4000/posts/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post-index">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="http://localhost:4000/posts/" >Blog âœï¸</a></li>
				
				    
				    <li><a href="http://localhost:4000/about/" >About â„¹ï¸</a></li>
				
				    
				    <li><a href="http://localhost:4000/newsletter/" >NLP Newsletter ğŸ—ï¸</a></li>
				
				    
				    <li><a href="http://localhost:4000/projects/" >Projects ğŸ’¡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub ğŸ“</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute âœ¨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium ğŸ“°</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview ğŸ“˜</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) ğŸ”¥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="http://localhost:4000/images/dair-ai.png" class="bio-photo" alt="dair.ai bio photo">


  <h3 itemprop="name">dair.ai</h3>
  <p>Democratizing Artificial Intelligence Research, Education, and Technologies</p>

  <a href="http://twitter.com/dair_ai" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  
  
  
  
  <a href="http://github.com/dair-ai" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <div id="index">
    <h1>All Posts</h1>
    
    
      <!--<h3>2020</h3>-->
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ç®€æŠ¥ï¼ˆIssue#7ï¼‰: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP ç®€æŠ¥ï¼ˆIssue#7ï¼‰: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></h2>
          <!--<p>åœ¨æœ¬æœŸä¸­ï¼Œæˆ‘ä»¬æ¶µç›–çš„ä¸»é¢˜åŒ…æ‹¬äº†ä»å¦‚ä½•æ”¹è¿›æµ‹é‡æˆåˆ†æ³›åŒ–åˆ°è®¡ç®—æœºè§†è§‰PyTorchåº“åˆ°æœ€æ–°çš„ç‰©ç†æ¨¡æ‹Ÿå™¨ç­‰.</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></h2>
          <!--<p>In this issue, we cover topics that range from improving how to measure compositional generalization to a computer vision PyTorch library to a state-of-the-a...</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,â€¦</a></h2>
          <!--<p>

</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-6_-FR/" title="NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-5_-FR/" title="NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,â€¦">NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-4_-FR/" title="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-3_-FR/" title="NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦">NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-2_-FR/" title="NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,â€¦">NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-1_-FR/" title="NLP Newsletter [FR] #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦">NLP Newsletter [FR] #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5/" title="NLP ç®€æŠ¥ï¼ˆIssue#6ï¼‰">NLP ç®€æŠ¥ï¼ˆIssue#6ï¼‰</a></h2>
          <!--<p>æœ¬æœŸæ¶µç›–çš„ä¸»é¢˜èŒƒå›´ä»æ‰©å±•Transformeræ¨¡å‹åˆ°å»ºè®®å‡ç¼“MLå‘è¡¨é€Ÿåº¦åˆ°ä¸€ç³»åˆ—MLå’ŒNLPä¹¦ç±å’Œé¡¹ç›®å‘è¡Œã€‚</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_BERTology_Primer_fastpages_T5/" title="NLP Newsletter #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p>This issue covers topics that range from extending the Transformer model to slowing publication in ML to a series of ML and NLP books and project releases.</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_BERTology_Primer_fastpages_T5/" title="NLP Newsletter [PT-BR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter [PT-BR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p>Essa ediÃ§Ã£o cobre tÃ³picos como extensÃµes ao modelo Transformer, desaceleraÃ§Ã£o no processo de publicaÃ§Ã£o em Aprendizado de MÃ¡quina, divulgaÃ§Ã£o de livros e pro...</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5-Issue-5-The_Annotated_GPT-2-CodeBERT-JAX-GA/" title="NLPç®€æŠ¥ï¼ˆIssue#5ï¼‰ï¼šThe Annotated GPT-2ã€CodeBERTã€JAXã€GANILLAç­‰">NLPç®€æŠ¥ï¼ˆIssue#5ï¼‰ï¼šThe Annotated GPT-2ã€CodeBERTã€JAXã€GANILLAç­‰</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-29T00:00:00+01:00">February 29, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_The_Annotated_GPT-2,_Understanding/" title="NLP Newsletter: GPT-2 Anotado, Entendendo self-distillation, Haiku, GANILLA, Sparkwiki, Ã‰tica em NLP, Torchmeta,â€¦">NLP Newsletter: GPT-2 Anotado, Entendendo self-distillation, Haiku, GANILLA, Sparkwiki, Ã‰tica em NLP, Torchmeta,â€¦</a></h2>
          <!--<p>Esta ediÃ§Ã£o abrange tÃ³picos como a compreensÃ£o de self-distillation, traduÃ§Ã£o de imagem para ilustraÃ§Ã£o, consideraÃ§Ãµes Ã©ticas para modelos de NLP, etc.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-29T00:00:00+01:00">February 29, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter.AR._The_Annotated_GPT-2_And_More/" title="Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø®Ø§Ù…Ø³ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP) Ø§Ù„Ø¨Ø±ÙŠØ¯ÙŠØ©: GPT-2 Ø§Ù„Ù…Ø´Ø±ÙˆØ­ØŒ ÙÙ‡Ù… Ø§Ù„ØªÙ‚Ø·ÙŠØ±-Ø§Ù„Ø°Ø§ØªÙŠØŒ HaikuØŒ GANILLAØŒ SparkwikiØŒ Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ ÙÙŠ Ø¹Ù„Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ TorchmetaØŒ ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ ...">Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø®Ø§Ù…Ø³ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP) Ø§Ù„Ø¨Ø±ÙŠØ¯ÙŠØ©: GPT-2 Ø§Ù„Ù…Ø´Ø±ÙˆØ­ØŒ ÙÙ‡Ù… Ø§Ù„ØªÙ‚Ø·ÙŠØ±-Ø§Ù„Ø°Ø§ØªÙŠØŒ HaikuØŒ GANILLAØŒ SparkwikiØŒ Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ ÙÙŠ Ø¹Ù„Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ TorchmetaØŒ ÙˆØ§Ù„Ù…Ø²ÙŠØ¯ ...</a></h2>
          <!--<p>Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø¯Ø¯ ÙŠØºØ·ÙŠ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø«Ù„: ÙÙ‡Ù… Ø§Ù„ØªÙ‚Ø·ÙŠØ±-Ø§Ù„Ø°Ø§ØªÙŠ (Self-Distillation)ØŒ ØªØ±Ø¬Ù…Ø© ØµÙˆØ±Ø©-Ø¥Ù„Ù‰-Ø±Ø³Ù…Ø© (Image-to-illustration Translation)ØŒ Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠØ© ÙÙŠ Ø¹Ù„Ù… Ù…Ø¹Ø§Ù„Ø¬...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-28T00:00:00+01:00">February 28, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_The_Annotated_GPT-2,_Understanding/" title="NLP Newsletter #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,â€¦">NLP Newsletter #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,â€¦</a></h2>
          <!--<p>This issue covers topics such as understanding self-distillation, image-to-illustration translation, ethical considerations for NLP models,Â etc.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-23T00:00:00+01:00">February 23, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/Bolet%C3%ADn_informativo_NLP_GPT-2_Explicado,_Entendie/" title="BoletÃ­n informativo NLP #5: GPT-2 Explicado, Entendiendo â€˜Self-Distillationâ€™, Haiku, GANILLA, Sparkwiki, Ã‰tica en el NLP, Torchmeta,...">BoletÃ­n informativo NLP #5: GPT-2 Explicado, Entendiendo â€˜Self-Distillationâ€™, Haiku, GANILLA, Sparkwiki, Ã‰tica en el NLP, Torchmeta,...</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-23T00:00:00+01:00">February 23, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/Fundamentals-of-NLP-Chapter-1/" title="Fundamentals of NLP (Chapter 1): Tokenization, Lemmatization, Stemming, and Sentence Segmentation">Fundamentals of NLP (Chapter 1): Tokenization, Lemmatization, Stemming, and Sentence Segmentation</a></h2>
          <!--<p>In this first chapter of the Fundamentals of NLP series, we will learn about lemmatization, stemming, tokenization, and sentence segmentation.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-21T00:00:00+01:00">February 21, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Tokenizers,_TensorFlow_2_1,_TextVectorization/" title="NLPç®€æŠ¥ [CH]: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦">NLPç®€æŠ¥ [CH]: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-20T00:00:00+01:00">February 20, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_ISSUE_4_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLPç®€æŠ¥ [CH]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">NLPç®€æŠ¥ [CH]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-17T00:00:00+01:00">February 17, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLP Newsletter #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">NLP Newsletter #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</a></h2>
          <!--<p>This issue covers topics such as bigger language models, improving 3D deep learning research, multilingual question answering benchmark, auditing AI systems,...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-16T00:00:00+01:00">February 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLP Newsletter [PT-BR]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦">NLP Newsletter [PT-BR]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,â€¦</a></h2>
          <!--<p>Essa ediÃ§Ã£o cobre tÃ³picos como modelos de linguagem maiores, avanÃ§os na pesquisa de Deep Learning em 3D, benchmarks para question answering multi-idiomas, au...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-16T00:00:00+01:00">February 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" title="NLPç®€æŠ¥ [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦">NLPç®€æŠ¥ [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-15T00:00:00+01:00">February 15, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Flax,_Thinc,_Language-specific_BERT/" title="NLP Newsletter #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦">NLP Newsletter #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,â€¦</a></h2>
          <!--<p>The third issue covers topics such as improving conversational agents, releases of language-specific BERT models, free datasets, releases of deep learning li...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-01T00:00:00+01:00">February 01, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Reformer,_DeepMath,_ELECTRA,_TinyBERT/" title="NLPç®€æŠ¥ [CH]: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,â€¦">NLPç®€æŠ¥ [CH]: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Reformer,_DeepMath,_ELECTRA,_TinyB-copy/" title="NLP Newsletter #1: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,â€¦">NLP Newsletter #1: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,â€¦</a></h2>
          <!--<p>This second issue covers topics that range from model interpretability to protein folding to active transfer learning.</p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" title="NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,â€¦">NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,â€¦</a></h2>
          <!--<p>Esta segunda newsletter aborda topics que vÃ£o de interpretabilidade de modelos para enovelamento de proteÃ­nas (protein folding) atÃ© active transfer learning</p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Tokenizers,_TensorFlow_2_1,_TextVe/" title="NLP Newsletter #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦">NLP Newsletter #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,â€¦</a></h2>
          <!--<p>This edition covers a series of improved NLP pipelines, NLP shortfalls, an AI system for breast cancer screening,â€¦</p>-->
          <!--<p class="byline"> <time datetime="2020-01-12T00:00:00+01:00">January 12, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_Tokenizers,_TensorFlow_2_1,_TextVe/" title="NLP Newsletter [PT-BR]: Tokenizadores, TensorFlow 2.1, VetorizaÃ§Ã£o de Texto, TorchIO, DÃ©ficits de NLP,â€¦">NLP Newsletter [PT-BR]: Tokenizadores, TensorFlow 2.1, VetorizaÃ§Ã£o de Texto, TorchIO, DÃ©ficits de NLP,â€¦</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-01-12T00:00:00+01:00">January 12, 2020</time></p>-->
        

      </article>
    
    
        
        
        
          <!--<h3>2019</h3>-->
        
      
      <article>
        
          <h2><a href="http://localhost:4000/nlp-highlights-2018/" title="NLP 2018 Highlights (Free 70+ Pages PDF Report)">NLP 2018 Highlights (Free 70+ Pages PDF Report)</a></h2>
          <!--<p>NLP 2018 Highlights</p>-->
          <!--<p class="byline"> <time datetime="2019-01-10T00:00:00+01:00">January 10, 2019</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/emnlp-emotion-recognition/" title="EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)">EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)</a></h2>
          <!--<p>EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)</p>-->
          <!--<p class="byline"> <time datetime="2019-01-10T00:00:00+01:00">January 10, 2019</time></p>-->
        

      </article>
    
    
        
        
        
          <!--<h3>2018</h3>-->
        
      
      <article>
        
          <h2><a href="http://localhost:4000/bias-in-sentiment-analysis/" title="Examining Gender and Race Bias in Sentiment Analysis Systems">Examining Gender and Race Bias in Sentiment Analysis Systems</a></h2>
          <!--<p>Examining Gender and Race Bias in Sentiment Analysis Systems</p>-->
          <!--<p class="byline"> <time datetime="2018-12-22T00:00:00+01:00">December 22, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/nlp-overview/" title="Modern Deep Learning Techniques Applied to Natural Language Processing">Modern Deep Learning Techniques Applied to Natural Language Processing</a></h2>
          <!--<p>Modern Deep Learning Techniques Applied to Natural Language Processing</p>-->
          <!--<p class="byline"> <time datetime="2018-10-24T00:00:00+02:00">October 24, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/deep-learning-emotion-recognition-pytorch-tensorflow/" title="Deep Learning Based Emotion Recognition with PyTorch and TensorFlow">Deep Learning Based Emotion Recognition with PyTorch and TensorFlow</a></h2>
          <!--<p>Deep Learning Based Emotion Recognition with PyTorch and TensorFlow</p>-->
          <!--<p class="byline"> <time datetime="2018-10-19T00:00:00+02:00">October 19, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/deep-learning-for-nlp-pytorch-tensorflow/" title="Deep Learning for NLP: PyTorch vs Tensorflow â€“ PyCon Taiwan 2018">Deep Learning for NLP: PyTorch vs Tensorflow â€“ PyCon Taiwan 2018</a></h2>
          <!--<p>Deep Learning for NLP: PyTorch vs Tensorflow â€“ PyCon Taiwan 2018</p>-->
          <!--<p class="byline"> <time datetime="2018-08-11T00:00:00+02:00">August 11, 2018</time></p>-->
        

      </article>
    
  </div><!-- /#index -->
</div><!-- /#main -->

<div class="footer-wrap">
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
