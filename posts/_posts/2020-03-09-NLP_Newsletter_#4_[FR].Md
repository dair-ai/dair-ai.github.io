---
layout: post
title: "NLP Newsletter #4 [FR]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,‚Ä¶"
author: lbourdois
excerpt: ""
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_4.png
---

![](https://cdn-images-1.medium.com/max/1200/1*3vNKhz6K-oGQ8aLi3mo84Q.png)

# Publications üìô
***Turing-NLG: Un mod√®le linguistique de 17 milliards de param√®tres par Microsoft***

\\
Turing Natural Language Generation (T-NLG) est un mod√®le de 17 milliards de param√®tres [propos√©](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/) par les chercheurs en IA de Microsoft. Il est √† ce jour, le plus grand mod√®le de langage connu (illustr√© dans la figure ci-dessous) et est bas√© sur un Transformer √† 78 couches qui surpasse les r√©sultats pr√©c√©dents (d√©tenus par Megatron-LM de NVIDIA) sur la perplexit√© de WikiText-103. Il a √©t√© test√© sur des t√¢ches telles que la r√©ponse √† des questions et le r√©sum√© abstrait. Le mod√®le est rendu possible par une librairie d'optimisation de l‚Äôentra√Ænement appel√©e DeepSpeed avec ZeRO, qui est √©galement pr√©sent√©e plus loin dans cette newsletter.

\\
![](https://cdn-images-1.medium.com/max/800/0*CAZm7uj8EaupnvnJ.png)

[*source*](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/)

\\
***Neural based Dependency Parsing***

\\
Miryam de Lhoneux a publi√© sa th√®se de doctorat intitul√©e "[Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages](http://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1357373&dswid=7905)". Ce travail porte sur l'utilisation d'approches neurales pour l'[analyse des d√©pendances](http://nlpprogress.com/english/dependency_parsing.html) dans les langues typologiquement diverses (c'est-√†-dire les langues qui construisent et expriment le sens de mani√®re structurellement diff√©rente). Ce travail rapporte que les RNN et les couches r√©cursives pourraient √™tre utiles pour l'incorporation dans les parsers car elles aident √† informer les mod√®les avec des connaissances linguistiques importantes n√©cessaires pour l'analyse. D'autres id√©es comprennent l'utilisation de l'analyse syntaxique polyglotte et des strat√©gies de partage de param√®tres pour l'analyse syntaxique dans des langues apparent√©es et non apparent√©es.

\\
***Extraction d'informations de bout en bout dans le cloud avec BERT***

\\
Une √©quipe de chercheurs a publi√© un [article](https://arxiv.org/abs/2002.01861) d√©crivant comment des mod√®les de Transformers comme BERT peuvent aider √† l'extraction d'informations de bout en bout dans des documents commerciaux sp√©cifiques √† un domaine, tels que les d√©p√¥ts r√©glementaires et les contrats de location de propri√©t√©. Non seulement ce type de travail peut aider √† optimiser les op√©rations commerciales, mais il montre √©galement l'applicabilit√© et l'efficacit√© des mod√®les bas√©s sur BERT sur des r√©gimes avec tr√®s peu de donn√©es annot√©es. Une application, et ses d√©tails de mise en ≈ìuvre, qui fonctionne sur le cloud est √©galement propos√©e (voir figure ci-dessous).

\\
![](https://cdn-images-1.medium.com/max/800/1*KqViSLhP0otleDY-XFy3Bg.png)

[*source*](https://arxiv.org/abs/2002.01861)

\\
***Question Answering Benchmark***

\\
[Wolfson et al. (2020)](https://arxiv.org/abs/2001.11770v1) ont publi√© un benchmark pour la compr√©hension des questions ainsi qu‚Äôune m√©thode pour d√©composer une question qui est n√©cessaire pour calculer une r√©ponse appropri√©e. Ils s'appuient sur le crowdsourcing pour annoter les √©tapes n√©cessaires √† la d√©composition des questions. Pour montrer la faisabilit√© et l'applicabilit√© de l'approche, ils am√©liorent la r√©ponse aux questions du domaine ouvert en utilisant l'ensemble de donn√©es HotPotQA.

\\
![](https://cdn-images-1.medium.com/max/800/1*AztG-Inqt6LGQ87lSufRcw.png)

‚Ää[*source*](https://arxiv.org/pdf/2001.11770v1.pdf)

\\
***Donn√©es radioactives : le tra√ßage par l‚Äôentra√Ænement***

\\
Les chercheurs de Facebook AI ont r√©cemment publi√© un [travail](https://ai.facebook.com/blog/using-radioactive-data-to-detect-if-a-data-set-was-used-for-training/) qui vise √† marquer les images (appel√©es donn√©es radioactives) afin de v√©rifier si un jeu de donn√©es particulier a √©t√© utilis√© pour l'entra√Ænement d‚Äôun mod√®le de ML. Ils ont d√©couvert qu'il est possible d'utiliser un marqueur intelligent qui d√©place les caract√©ristiques dans une direction, que le mod√®le utilise pour aider √† d√©tecter l'utilisation de donn√©es radioactives m√™me si seulement 1 % des donn√©es d'entra√Ænement sont radioactives. C‚Äôest un d√©fi car tout changement dans les donn√©es peut potentiellement d√©grader la pr√©cision du mod√®le. Selon les auteurs, ce travail peut ¬´ aider les chercheurs et les ing√©nieurs √† savoir quel jeu de donn√©es a √©t√© utilis√© pour entra√Æner un mod√®le, afin de mieux comprendre comment les diff√©rents ensembles de donn√©es affectent les performances des diff√©rents r√©seaux neuronaux ¬ª. Cette approche semble importante pour les applications critiques de ML. Consultez le document complet [ici](https://arxiv.org/pdf/2002.00937.pdf).


\\
***REALM: Retrieval-Augmented Language Model Pre-Training***


\\
[REALM](https://kentonl.com/pub/gltpc.2020.pdf) est une approche d'extraction √† grande √©chelle qui utilise un corpus de connaissances textuelles pour pr√©-entra√Æner un mod√®le de langue de mani√®re non supervis√©e. Les t√¢ches abord√©es et √©valu√©es √† l'aide de REALM comprennent des questions ouvertes r√©pondant √† des crit√®res de r√©f√©rence. Outre l'am√©lioration de la pr√©cision du mod√®le, les autres avantages comprennent les composantes de modularit√© et d'interpr√©tabilit√©.

\\
![](https://cdn-images-1.medium.com/max/800/1*MJO-yzCwsB5ydKGz7hKHVA.png)

[*source*](https://kentonl.com/pub/gltpc.2020.pdf)

# Cr√©ativit√© et soci√©t√© üé®

***Permettre la pr√©sentation √† distance de documents et d'affiches lors de conf√©rences scientifiques***

\\
La semaine derni√®re, une [p√©tition](https://www.change.org/p/organizers-of-data-science-and-machine-learning-conferences-neurips-icml-aistats-iclr-uai-allow-remote-paper-poster-presentations-at-conferences) a √©t√© lanc√©e pour permettre la pr√©sentation √† distance de documents et d'affiches lors de conf√©rences scientifiques comme celles li√©es au ML. Il semble que Yoshua Bengio, plaide pour que les gens aillent signer la p√©tition. Il l'a clairement indiqu√© dans son nouveau [blog](https://yoshuabengio.org/2020/02/10/fusce-risus/).


\\
***D√©fi de l'abstraction et du raisonnement***

\\
Fran√ßois Chollet a r√©cemment mis en ligne un [concours Kaggle](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview) o√π il a publi√© le Corpus d'abstraction et de raisonnement (ARC). Il vise √† encourager les utilisateurs √† cr√©er des syst√®mes d'IA capables de r√©soudre des t√¢ches de raisonnement auxquelles ils n'ont jamais √©t√© expos√©s. L'espoir est de commencer √† construire des syst√®mes d'IA plus robustes, capables de r√©soudre mieux et rapidement de nouveaux probl√®mes par eux-m√™mes, ce qui pourrait aider √† r√©soudre les applications du monde r√©el les plus difficiles, comme l'am√©lioration des voitures autonomes.

\\
***Publications de ML et NLP en 2019***

\\
Marek Rei publie son [analyse annuelle]( https://www.marekrei.com/blog/ml-and-nlp-publications-in-2019/) sur les statistiques en lien avec l'apprentissage machine et le NLP pour l‚Äôann√©e 2019. Les conf√©rences incluses dans l'analyse sont ACL, EMNLP, NAACL, EACL, COLING, TACL, CL, CoNLL, NeurIPS, ICML, ICLR, et AAAI.

\\
***La croissance d‚Äôautomates cellulaires neuronaux***

\\
La morphogen√®se est un processus d'auto-organisation par lequel certaines cr√©atures comme les salamandres peuvent se r√©g√©n√©rer ou r√©parer des dommages corporels. Ce processus est robuste aux perturbations et de nature adaptative. Inspir√©s par ce ph√©nom√®ne biologique et par le besoin de mieux comprendre le processus, les chercheurs ont publi√© un [article](https://distill.pub/2020/growing-ca/) intitul√© "Growing Neural Cellular Automata", qui adopte un mod√®le diff√©renciable pour la morphogen√®se visant √† reproduire les comportements et les propri√©t√©s des syst√®mes d'autor√©paration. L'espoir est de pouvoir construire des machines autor√©paratrices qui poss√®dent la m√™me robustesse et plasticit√© que la vie biologique. En outre, cela permettrait de mieux comprendre le processus de r√©g√©n√©ration lui-m√™me. Les applications qui peuvent en b√©n√©ficier comprennent la m√©decine r√©g√©n√©ratrice et la mod√©lisation des syst√®mes sociaux et biologiques.

\\
![](https://cdn-images-1.medium.com/max/800/1*2p62h1RaHD6d11LX8olnTA.png)

[*source*](https://distill.pub/2020/growing-ca/)

\\
***Visualiser l'attention des Transformers***

\\
Hendrik Strobelt a partag√© ce [repertoire](https://github.com/SIDN-IAP/attnvis) qui montre comment construire rapidement une visualisation interactive simple de l'attention d‚Äôun Transformer √† travers une application web en utilisant la biblioth√®que HuggingFace et d3.js.

\\
***SketchTransfer : Une nouvelle t√¢che stimulante pour explorer l'invariance des d√©tails et les abstractions apprises par les r√©seaux***

\\
[SketchTransfer](https://arxiv.org/pdf/1912.11570.pdf) propose une nouvelle t√¢che pour tester la capacit√© des r√©seaux neuronaux √† supporter l'invariance en pr√©sence/absence de d√©tails. On a longtemps d√©battu du fait que les r√©seaux ne peuvent pas se g√©n√©raliser √† des variations qui n'ont pas encore √©t√© observ√©es pendant l‚Äôentra√Ænement, comme par exemple traiter les d√©tails visuels manquants lorsqu'ils regardent des dessins anim√©s. Le document examine et publie un ensemble de donn√©es pour aider les chercheurs √† √©tudier attentivement le probl√®me de ¬´ l'invariance des d√©tails ¬ª en fournissant des croquis non √©tiquet√©s et des exemples √©tiquet√©s d'images r√©elles.

\\
![](https://cdn-images-1.medium.com/max/800/1*jdYuMoHiu2yya5rHzZyjwQ.png)

[*source*](https://arxiv.org/pdf/1912.11570.pdf)


# Outils et jeux de donn√©es ‚öôÔ∏è

***DeepSpeed + ZeRO***

\\
Microsoft a d√©voil√©e une librairie d'optimisation pour l‚Äôentrainement appel√©e DeepSpeed. Elle est compatible avec PyTorch et peut permettre l‚Äôentrainement d'un mod√®le de 100 milliards de param√®tres. La librairie se concentre sur quatre aspects importants de l‚Äôentrainement d'un mod√®le : l'√©chelle, la vitesse, le co√ªt et la convivialit√©. DeepSpeed a √©t√© [lanc√©](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/) en m√™me temps que ZeRO. ZeRO est une technologie d'optimisation de la m√©moire qui permet de faire du deep learning distribu√© √† grande √©chelle sur GPU tout en am√©liorant le d√©bit de trois √† cinq fois plus que le meilleur syst√®me actuel.

\\
![](https://cdn-images-1.medium.com/max/800/0*MXDI1f3cSBrY5w2g.gif)

[*source*](https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/)

\\
***Une librairie pour mener des recherches rapides et efficaces sur le DL en 3D***

\\
[PyTorch3D](https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/) est une bo√Æte √† outils open-source pour la recherche sur le DL en 3D. La librairie consiste en des impl√©mentations rapides et optimis√©es d'op√©rateurs 3D et de fonctions de perte fr√©quemment utilis√©s. Elle est √©galement dot√©e d'un moteur de rendu modulaire et diff√©renciable qui permet de mener des recherches sur des entr√©es 3D complexes et de faire des pr√©visions 3D de haute qualit√©.

\\
![](https://cdn-images-1.medium.com/max/800/1*VbspKMmPBUsgpdnIkd5jYA.png)

[*source*](https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/)

\\
***Gestion de la configuration de projets de ML***

\\
Hydra est un outil pour g√©rer plus efficacement les projets de ML complexes. Il est destin√© √† aider les chercheurs de PyTorch en offrant une r√©utilisation fonctionnelle des configurations. Son principal avantage est qu'il permet au programmeur de g√©rer la configuration comme du code de composition, ce qui signifie que le fichier de configuration peut √™tre facilement √©cras√©. Hydra peut √©galement aider √† g√©rer automatiquement le r√©pertoire de travail des r√©sultats de votre projet de ML, ce qui est utile lorsque vous avez besoin de sauvegarder et d'acc√©der aux r√©sultats de plusieurs exp√©riences pour des travaux multiples. Pour en savoir plus, cliquez [ici](https://medium.com/pytorch/hydra-a-fresh-look-at-configuration-for-machine-learning-projects-50583186b710).

\\
***Une bo√Æte √† outils pour l'inf√©rence causale avec les r√©seaux bay√©siens***

\\
[CausalNex](https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html) est une bo√Æte √† outils pour "l'inf√©rence causale avec les r√©seaux bay√©siens". L'outil vise √† combiner l'apprentissage machine et le raisonnement causal pour d√©couvrir des relations structurelles dans les donn√©es. Les auteurs ont √©galement pr√©par√© un guide d'introduction sur le pourquoi et le comment de l'inf√©rence causale avec les r√©seaux bay√©siens en utilisant la librairie Python propos√©e.

\\
![](https://cdn-images-1.medium.com/max/800/1*EYwKhdnscR7ZLuNkTqCS2Q.png)

[*source*](https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html)

\\
***Google Colab Pro est maintenant disponible***

\\
Google Colab propose d√©sormais une √©dition Pro, qui offre des avantages tels qu'un acc√®s exclusif √† des GPU et TPU plus rapides, des dur√©es d'ex√©cution plus longues et plus de m√©moire.


\\
***TyDi QA: Un benchmark pour le Question/Anwsering multilingues***

\\
Google AI publie [TyDi QA](https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html), un ensemble de donn√©es multilingues qui peut encourager les chercheurs √† r√©pondre √† des questions dans des langues plus typologiquement diverses. C‚Äôest √† dire qui construisent et expriment le sens de diff√©rentes mani√®res. L'id√©e est de motiver les chercheurs √† construire des mod√®les plus robustes sur des langues typologiquement √©loign√©es, telles que l'arabe, le bengali, le cor√©en, le russe, le t√©lougou et le tha√Ø, afin de g√©n√©raliser √† encore plus de langues.

\\
![](https://cdn-images-1.medium.com/max/800/1*1dZv5you3jigdrQ2uAKzUw.png)

[*source*](https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html)

\\
***Question Answering pour Node.js***

\\
Hugging Face publie une [librairie](https://github.com/huggingface/node-question-answering) de questions/r√©ponses bas√©e sur DistilBERT. Ce mod√®le peut fonctionner en production en utilisant Node.js avec seulement 3 lignes de code. Le mod√®le tire parti de la mise en ≈ìuvre rapide de Tokenizers, et de TensorFlow.js (une biblioth√®que populaire pour l'utilisation de mod√®les d'apprentissage machine avec Javascript).

# Ethique en IA üö®

***Identifier les biais subjectifs dans les textes***

\\
Ce [podcast](https://podcasts.apple.com/us/podcast/will-ai-help-identify-bias-or-perpetuate-it-with-diyi-yang/id1435564422?i=1000464141922) pr√©sente Diyi Yang, chercheur en sciences sociales computationnelles, qui explique comment les syst√®mes d'IA peuvent aider √† identifier les biais subjectifs dans les informations textuelles. Il s'agit d'un domaine de recherche important impliquant les syst√®mes d'IA et de NLP. En particulier lorsque nous discutons de la consommation de m√©dias textuels tels que les news qui peuvent √™tre facilement encadr√©s pour biaiser les consommateurs alors qu'en r√©alit√© ils devraient viser √† √™tre plus objectifs. Du point de vue de l'application, il devient essentiel d'identifier automatiquement le biais subjectif pr√©sent dans les m√©dias textuels afin d'aider les consommateurs √† devenir plus conscients du contenu qu'ils consomment. L'√©pisode traite √©galement de la mani√®re dont l'IA peut √©galement perp√©tuer le biais.

\\
***Intelligence artificielle, valeurs et alignement***

\\
L'essor des syst√®mes d'IA et la mani√®re dont ils s‚Äôalignent sur les valeurs humaines est un domaine de recherche actif qui implique l'√©thique dans les syst√®mes d'IA. DeepMind a r√©cemment publi√© un [papier](https://deepmind.com/research/publications/Artificial-Intelligence-Values-and-Alignment) qui examine plus en profondeur les questions philosophiques entourant l'alignement de l'IA. Le rapport se concentre sur deux parties :  technique (c'est-√†-dire comment coder les valeurs qui rendent les r√©sultats des agents d'IA fiables) et normative (quels principes seraient justes √† coder dans l'IA). Le document pr√©conise une approche fond√©e sur des principes visant √† pr√©server √† pr√©server un traitement √©quitable malgr√© la diff√©rence de croyances et d'opinions.

\\
***Sur l'audit des syst√®mes d'IA***

\\
VentureBeat rapporte que Google Researchers, en collaboration avec d'autres groupes, a cr√©√© un framework appel√© SMACTR qui permet aux ing√©nieurs de v√©rifier les syst√®mes d'IA. La raison de ce travail est de combler le foss√© de responsabilit√© qui existe avec les syst√®mes d'IA actuels qui sont mis dans la nature pour √™tre utilis√©s par les consommateurs. Pour plus d‚Äôinformations, lire les deux documents suivants :  [ici](https://venturebeat.com/2020/01/30/google-researchers-release-audit-framework-to-close-ai-accountability-gap/) et [ici](https://dl.acm.org/doi/abs/10.1145/3351095.3372873).

# Articles et Blog ‚úçÔ∏è

***La distillation de mod√®le en NLP***

\\
Dans un [podcast](https://soundcloud.com/nlp-highlights/104-model-distillation-with-victor-sanh-and-thomas-wolf) de NLP Highlights, Thomas Wolf et Victor Sanh parlent de la distillation de mod√®les et de la fa√ßon dont elle peut √™tre utilis√©e comme une approche r√©alisable pour comprimer de grands mod√®les comme BERT. Ce concept est discut√© plus en d√©tail dans la m√©thode qu'ils proposent, appel√©e [DistilBERT](https://arxiv.org/abs/1910.01108), dans laquelle ils construisent des mod√®les plus petits (bas√©s sur la m√™me architecture qu'un mod√®le plus grand) pour essayer d'imiter le comportement du mod√®le plus grand. En substance, le petit mod√®le (l'√©tudiant) essaie de s'adapter √† la distribution de probabilit√© de l'enseignant.

\\
***BERT, ELMo, & GPT-2: Dans quelle mesure les repr√©sentations contextuelles des mots sont-elles contextualis√©es ?***

\\
On a beaucoup parl√© du succ√®s des m√©thodes contextualis√©es comme BERT pour aborder une grande vari√©t√© de t√¢ches complexes de NLP. Dans cet [article](https://kawine.github.io/blog/nlp/2020/02/03/contextual.html), Kawin Ethayarajh tente de r√©pondre √† la question qui consiste √† savoir comment sont contextualis√©s les mots dans les mod√®les comme BERT, ELMo et le GPT-2. Les sujets abord√©s comprennent les mesures de la contextualit√©, la sp√©cificit√© du contexte et les comparaisons entre les embeddings statiques et les repr√©sentations contextualis√©es.

\\
![](https://cdn-images-1.medium.com/max/800/0*70aIv1Fkkz4rnHgQ.png)

[*source*](https://kawine.github.io/blog/nlp/2020/02/03/contextual.html)

\\
***Sparsity in Neural Networks***

\\
Fran√ßois Lagunas, a √©crit cet [article Medium](https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70) pour discuter de son optimisme quant √† l'adoption de tenseurs clairsem√©s dans les mod√®les de r√©seaux de neurones. L'espoir est d'utiliser une forme de raret√© pour r√©duire la taille des mod√®les actuels qui, √† un moment donn√©, deviennent peu pratiques en raison de leur taille et de leur vitesse. Ce concept pourrait √™tre int√©ressant √† explorer en ML en raison de la taille m√™me des mod√®les actuels comme les Transformers. Cependant, les d√©tails de mise en ≈ìuvre ne sont pas aussi clairs du point de vue des outils de d√©veloppement disponibles, et c'est quelque chose sur lequel la communaut√© travaille d√©j√†.

\\
***Entra√Æner votre propre mod√®le linguistique***

\\
Si vous souhaitez apprendre √† entrainer un mod√®le de z√©ro, consultez ce [tutoriel](https://huggingface.co/blog/how-to-train) d‚ÄôHugging Face. Ils utilisent √©videmment leurs propres biblioth√®ques Transformers et Tokenizers pour entra√Æner le mod√®le.


\\
***Tokenizers: Comment les machines lisent***

\\
Cathal Horan a publi√© un [article](https://blog.floydhub.com/tokenization-nlp/) sur la mani√®re dont les mod√®les de NLP les plus r√©cents utilisent les tokenizers. Il explique √©galement pourquoi la tokenisation est un domaine de recherche actif, passionnant et important. L'article vous montre m√™me comment entra√Æner vos propres tokenizers en utilisant des m√©thodes de tokenisation comme SentencePiece et WordPiece.

\\
![](https://cdn-images-1.medium.com/max/800/1*Vkjw5n9Sz0Was43haVNJMg.png)

[*source*](https://blog.floydhub.com/tokenization-nlp/%27)


# Education üéì

***ML √† l'universit√© d'Amsterdam***

\\
Vous pouvez d√©sormais suivre en ligne le [cours d'apprentissage machine 2020 MLVU](https://mlvu.github.io/), qui comprend des diapositives, des [vid√©os](https://www.youtube.com/watch?v=excCZSTJEPs&feature=youtu.be) et le programme. Il s'agit d'une introduction au ML, mais il comporte √©galement d'autres sujets li√©s √† l'apprentissage approfondi, tels que les VAE et les GAN.


\\
![](https://cdn-images-1.medium.com/max/800/1*zFpU2rQL5Fby7X3boJyQNg.png)

[*source*](https://mlvu.github.io/)

\\
***Ressources math√©matiques pour le ML***

\\
Suzana Iliƒá et le Machine Learning Tokyo (MLT) ont fait un travail remarquable en termes de d√©mocratisation de l'√©ducation au ML. Par exemple, consultez ce [r√©pertoire](https://github.com/Machine-Learning-Tokyo/Math_resources) qui pr√©sente une collection de ressources en ligne gratuites pour apprendre les fondements des concepts math√©matiques utilis√©s en ML.

\\
***Introduction au Deep Learning***

\\
Suivez le cours "Introduction to Deep Learning" du MIT sur ce [site](http://introtodeeplearning.com/). De nouveaux cours seront publi√©s chaque semaine et toutes les diapositives, vid√©os et codes seront publi√©s.

\\
***Deep Learning avec PyTorch***

\\
Alfredo Canziani a publi√© les diapositives et les notebooks pour son mini-cours sur l'apprentissage profond avec PyTorch. Le d√©p√¥t contient √©galement un [site web compl√©mentaire](https://atcold.github.io/pytorch-Deep-Learning/) qui comprend des descriptions textuelles des concepts enseign√©s dans le cours.

\\
***Missing Semester of Your CS***

\\
Le "[Missing Semester of Your CS](https://missing.csail.mit.edu/)" est un cours en ligne pouvant √™tre utile aux sp√©cialistes des donn√©es ayant une formation autre que celle du d√©veloppement. Il comprend des sujets tels que les outils shell, les scripts et le contr√¥le de version. Le cours a √©t√© publi√© par des membres du corps enseignant du MIT.

\\
![](https://cdn-images-1.medium.com/max/800/1*weUnTXxmHxYf-B2DDaslvw.png)

[*source*](https://missing.csail.mit.edu/2020/shell-tools/)

\\
***Deep Learning avanc√©***

\\
La CMU a publi√© les diapositives et le programme du cours "[Advanced Deep Learning](https://andrejristeski.github.io/10707-S20/syllabus.html)" qui comprend des sujets tels que les mod√®les autor√©gressifs, les mod√®les g√©n√©rateurs et l'apprentissage autosurveill√©/pr√©dictif. Le cours s'adresse aux √©tudiants de master ou de doctorat ayant une formation avanc√©e en ML.

# Mentions sp√©ciales ‚≠êÔ∏è

Xu et ses collaborateurs (2020) ont propos√© une [m√©thode]( https://arxiv.org/abs/2002.02925) pour remplacer et compresser progressivement un mod√®le BERT en le divisant en ses composantes d'origine. Le mod√®le propos√© surpasse les autres approches de distillation sur le r√©f√©rentiel GLUE.

\\
Le cours "[Introduction √† l'apprentissage machine](https://compstat-lmu.github.io/lecture_i2ml/index.html)" couvre les bases du ML, la r√©gression supervis√©e, les for√™ts al√©atoires, le tuning des param√®tres et bien d'autres sujets fondamentaux du ML.

\\
Le mod√®le grec de BERT ([GreekBERT](https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1)) est maintenant disponible sur Transformers.


\\
Jeremy Howard publie un [article](https://arxiv.org/abs/2002.04688) d√©crivant la librairie fastai. Il s'agit d'une lecture recommand√©e aux d√©veloppeurs de logiciels qui travaillent √† la cr√©ation et √† l'am√©lioration des librairies d'apprentissage profond et de ML.

\\
Deeplearning.ai compl√®te la publication des quatre cours de TensorFlow : [Data and Deployment Specialization](https://www.coursera.org/specializations/tensorflow-data-and-deployment). Cette sp√©cialisation vise principalement √† apprendre aux d√©veloppeurs comment d√©ployer efficacement des mod√®les dans diff√©rents sc√©narios et utiliser les donn√©es de mani√®re int√©ressante.

\\
Sebastian Raschka a r√©cemment publi√© un [article](https://arxiv.org/abs/2002.04803) intitul√© "Machine Learning in Python" : Principaux d√©veloppements et tendances technologiques en mati√®re de science des donn√©es, d'apprentissage automatique et d'intelligence artificielle". Ce document est un examen complet du paysage des outils d'apprentissage machine. Il permet de comprendre les avantages de certaines librairies et les concepts utilis√©s dans l'ing√©nierie ML. En outre, un mot sur l'avenir des biblioth√®ques d'apprentissage machine bas√©es sur Python est fourni.

----------

Vous pouvez retrouver la pr√©c√©dente newsletter [ici](https://dair.ai/NLP_Newsletter_-3_-FR/)

\\
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, vous pouvez utiliser ce [formulaire](https://forms.gle/3b7Q2w2bzsXE6uYo9).

\\
[Abonnez-vous](https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
