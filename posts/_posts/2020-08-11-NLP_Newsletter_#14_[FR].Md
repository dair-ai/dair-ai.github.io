---
layout: post
title: "NLP Newsletter 14 [FR]: NLP Beyond English, Big Bird, Monitoring ML Models, Breaking into NLP, arXiv Dataset,‚Ä¶"
author: lbourdois
excerpt: "In this issue, we cover topics that range from the importance of taking NLP beyond English to resources for monitoring ML systems to a conversation on the future of conversational AI systems."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_14.png
---

![](https://cdn-images-1.medium.com/max/800/0*SfmXR6C5pvmRH2_B.png)

# Avant-propos d‚ÄôElvis

Bonjour √† tous,

\\
Bienvenue au 14√®me num√©ro de la Newsletter consacr√©e au NLP. Tout d'abord, merci de prendre le temps de lire la newsletter. Certaines choses changent dans celle-ci et c'est pour le mieux. Nous allons nous concentrer sur quelques th√®mes importants de l'apprentissage machine et du NLP, centr√©s sur trois piliers que je crois importants pour notre communaut√© : ***√©ducation***, ***recherche***, et ***technologies***. En fait, ce sont les m√™mes piliers sur lesquels nous, √† dair.ai, nous concentrons et construisons nos initiatives et nos projets. J'esp√®re que vous aimez le nouveau format car il nous permet de discuter de certains sujets importants plus en profondeur que d'habitude.

\\
Je ne peux insister davantage sur l'importance de continuer √† apprendre dans un domaine aussi rapide que l'apprentissage machine. Que vous soyez √† la pointe de la recherche ou que vous mettiez en production des mod√®les de ML √† grande √©chelle chaque jour, il est toujours possible d'apprendre quelque chose de nouveau chaque semaine. La question est de savoir comment vous gardez votre motivation pour apprendre. J'ai identifi√© cela comme une opportunit√© pour nous de nous connecter et de partager ce qui compte pour nous. C'est pourquoi j'ai cr√©√© un nouveau *groupe d'apprentissage* appel√© [Keep Learning ML](https://github.com/dair-ai/keep-learning-ml). Chaque vendredi, nous nous r√©unirons et nous nous amuserons en partageant ce que nous avons appris au cours de la semaine. Il peut s'agir d'un article de NLP ou de ML, d'un outil, d'une d√©mo, d'un point de vue philosophique, d'un probl√®me urgent, etc.

\\
Dans ce num√©ro, nous abordons des sujets qui vont de l'importance d‚Äôappliquer le NLP √† d‚Äôautres langues que l'anglais aux ressources pour la surveillance des syst√®mes de ML, en passant par une conversation sur l'avenir des syst√®mes d'IA conversationnelle.

\\
Nous remercions tout particuli√®rement [Keshaw Singh](https://twitter.com/_skeshaw) et [Manikandan Sivanesan](https://twitter.com/manisnesan) pour leur contribution significative √† cette √©dition de la lettre d'information de la NLP.

\\
*Bonne lecture*

# Top Stories
## Pr√©sentation des applications bas√©e sur le GPT-3
Cette ann√©e, OpenAI a travaill√© sur l'acc√®s de ses mod√®les d'apprentissage machine (ML) via une [API](https://openai.com/blog/openai-api/). Le processus d'acc√®s √† l'API n√©cessite une [demande formelle](https://forms.office.com/Pages/ResponsePage.aspx?id=VsqMpNrmTkioFJyEllK8s0v5E5gdyQhOuZCXNuMR8i1UQjFWVTVUVEpGNkg3U1FNRDVVRFg3U0w4Vi4u) et l'indication de votre objectif d'utilisation. Quelques d√©veloppeurs et chercheurs ont re√ßu l'acc√®s √† l'API et ont pr√©sent√© diff√©rentes applications du GPT-3.

\\
Un d√©veloppeur a construit un g√©n√©rateur de site et un autre un [g√©n√©rateur de regex](https://losslesshq.com/). Si vous souhaitez voir d'autres cas d'utilisation de GPT-3, Yaser Martinez Palenzuela a rassembl√© une collection de [d√©mos et applications](https://github.com/elyase/awesome-gpt3) qui sont aliment√©es par GPT-3. Il devient √©vident que des mod√®les comme le GPT-3 ont un √©norme potentiel pour √™tre utilis√©s dans des applications du monde r√©el, cependant, il n'est pas clair si ces applications sont s√ªres et comment traiter les pr√©jug√©s nuisibles ou les biais qui sont communs avec ce type de mod√®les qui sont g√©n√©ralement pr√©-entra√Æn√©s sur des donn√©es Internet ouvertes √† grande √©chelle.

\\
***En savoir plus üéì***

\\
Si vous souhaitez en savoir plus sur le fonctionnement du GPT-3, Jay Alammar a pr√©par√© une [s√©rie d'animations](https://jalammar.github.io/how-gpt3-works-visualizations-animations/) qui explique les √©tapes importantes de l'architecture du transformer avec des exemples et des transformations cl√©s qui ont lieu dans le mod√®le de langage du GPT-3.

\\
![Source : Jay Alammar](https://cdn-images-1.medium.com/max/800/0*mSEp2sRTqWJOcbj7.png)
*Source : [Jay Alammar](https://jalammar.github.io/how-gpt3-works-visualizations-animations/)*

\\
***Rester inform√© üéØ***

\\
Avec tout le buzz autour des technologies √©mergentes, GPT-3 en √©tant un exempel, cet article publi√© par Page Street Labs propose un cadre intuitif pour donner un sens au "battage" qui les entoure. Il s'agit notamment de mieux comprendre l'utilisation du terme "hype" lui-m√™me. Plus pr√©cis√©ment, les utilisateurs peuvent √™tre plac√©s dans l'un des quatre quadrants d'une visualisation 2x2 (voir figure ci-dessous) en fonction de leur exp√©rience directe avec certaines technologies ainsi que de la polarit√© du battage (positif/n√©gatif). La plupart des signaux utiles pour √©valuer les capacit√©s et les promesses proviennent de ceux qui ont une bonne connaissance des principes sous-jacents ou qui ont une exp√©rience de la technologie : ceux qui la cr√©ent ou qui "voient la lumi√®re" sont parmi ceux qui g√©n√®rent le buzz positif, tandis que ceux qui se trouvent de l'autre c√¥t√© mettent en garde contre les fausses alarmes. Les lecteurs sont encourag√©s √† lire l'[article original](https://pagestlabs.substack.com/p/gpt-3-and-a-typology-of-hype).

\\
![Source : Page Street Labs](https://cdn-images-1.medium.com/max/800/0*kFJsX7bzrLOf8B1P.png)
*Source : [Page Street Labs](https://pagestlabs.substack.com/p/gpt-3-and-a-typology-of-hype)*

## Jeux de donn√©es pour explorer les articles scientifiques
Plus t√¥t cette ann√©e, l'Institut Allen IA a publi√© un vaste ensemble de donn√©es d‚Äô[articles scientifiques li√©s √† la COVID-19](https://allenai.org/data/cord-19). Alors que la plupart de ces articles contenaient des √©tudes sur la COVID-19 et d'autres coronavirus, de nombreux scientifiques et chercheurs ont commenc√© √† l'utiliser pour effectuer des analyses int√©ressantes et construire des applications interactives qui permettent certaines capacit√©s de recherche s√©mantique. L'id√©e √©tait d'extraire de nouvelles informations des textes qui pourraient √™tre utilis√©es par les chercheurs et les experts dans ce domaine pour d√©couvrir des faits int√©ressants sur le virus, ce qui, dans un certain sens, acc√©l√©rerait le rythme des d√©couvertes.

\\
Dans la foul√©e, arXiv.org a [publi√©](https://blogs.cornell.edu/arxiv/2020/08/05/leveraging-machine-learning-to-fuel-new-discoveries-with-the-arxiv-dataset/) un jeu de donn√©es contenant 1,7 million d'articles dans le but de fournir des articles scientifiques - dans diff√©rents domaines tels que la biologie et l'informatique - dans un format plus accessible et lisible par les machines. L'appel √† l'action vise √† donner aux chercheurs et aux praticiens de l'apprentissage machine les moyens de cr√©er des outils pour acc√©l√©rer les nouvelles d√©couvertes √† l'aide d'applications bas√©es sur le ML, telles que l'analyse des tendances, les moteurs de recommandation de papier, la construction de graphiques de connaissances et m√™me les interfaces de recherche s√©mantique.

\\
Suite √† la publication de ce jeu de donn√©es, Elsevier a √©galement r√©cemment [publi√©](https://data.mendeley.com/datasets/zm33cdndxs/2) un corpus de 40 000 textes CC-BY contenant des articles scientifiques qui pourraient √™tre utilis√©s pour la recherche en NLP et en ML.

\\
***Appel √† l'action üí°***

\\
Chez dair.ai, nous avons lanc√© un projet dont l'objectif est d'utiliser l'ensemble de donn√©es arXiv pour explorer de nouvelles fa√ßons d'extraire des informations d'articles scientifiques afin d'alimenter de nouvelles d√©couvertes. En plus de cet effort de recherche, nous mettons sur pied une √©quipe charg√©e de cr√©er des applications bas√©es sur le NLP avec des capacit√©s de recherche s√©mantique afin de fournir √† la communaut√© une solution open-source pour trouver facilement des tendances et d'autres id√©es int√©ressantes pour se tenir inform√© des diff√©rents domaines de recherche tels que l'apprentissage machine. Consultez cette [annonce](https://github.com/dair-ai/arxiv_analysis) pour plus de d√©tails et rejoignez notre [groupe Slack](https://join.slack.com/t/dairai/shared_invite/zt-dv2dwzj7-F9HT047jIGkunNKv88lQ~g) pour plus d'informations.

## Pourquoi est-il important de surveiller les mod√®les d'apprentissage automatique ?
Imaginez un sc√©nario dans lequel nous avons construit et d√©ploy√© un syst√®me d'apprentissage machine (ML) pour nos utilisateurs. La question est maintenant de savoir comment nous pouvons garantir que le syst√®me fonctionne constamment comme pr√©vu sur une p√©riode donn√©e. Selon les exigences de tol√©rance du syst√®me, l'impact d'une d√©faillance va d'un inconv√©nient mineur √† des situations mettant la vie en danger. Les pratiques traditionnelles de gestion des performances des applications, telles que la surveillance des mesures de l'exp√©rience utilisateur (par exemple, la latence) et des ressources du syst√®me (par exemple, l'utilisation du processeur et de la m√©moire), sont √©galement applicables √† la surveillance des syst√®mes de ML. Elles sont essentielles pour identifier les modes de d√©faillance connus et mettre en place une infrastructure d'alerte pour effectuer des actions correctives. En outre, pour les syst√®mes de ML, nous devons √©galement surveiller les facteurs suivants :
- les changements dans la qualit√© des donn√©es d'entr√©e tels que les colonnes manquantes ou les entr√©es inattendues pendant le temps d'inf√©rence
- les changements dans la relation entre l'entr√©e et la sortie sur une p√©riode de temps. Cela entra√Æne une d√©gradation progressive du mod√®le due √† la modification des hypoth√®ses sous-jacentes, commun√©ment appel√©e "d√©rive conceptuelle".
- la robustesse des pr√©dictions due √† toute modification des donn√©es, des caract√©ristiques, des hyperparam√®tres, des param√®tres du mod√®le, etc... C'est ce qu'on appelle le principe CACE : * Changing Anything Changes Everything (Changer quelque chose change tout)*.
Si vous souhaitez en savoir plus sur l'importance de la surveillance des syst√®mes de blanchiment d'argent et d√©couvrir quelques exemples concrets, consultez l'[article complet](https://mlinproduction.com/why-is-it-important-to-monitor-machine-learning-models/).

\\
![Surveillance dans le cycle de vie du ML - Source de la figure](https://cdn-images-1.medium.com/max/800/0*TaJ_SWmAmU_8goRO.png)
*Surveillance dans le cycle de vie du ML - [Source de la figure](https://martinfowler.com/articles/cd4ml.html)*

\\
***En savoir plus üéì***
\\
Si vous souhaitez continuer √† vous informer sur la surveillance des syst√®mes d'apprentissage machine et sur les MLOps en g√©n√©ral, nous partageons quelques r√©f√©rences ci-dessous :
- [Applied ML](https://github.com/eugeneyan/applied-ml) est un r√©pertoire avec une liste d'articles et de blogs sur la science des donn√©es et l'apprentissage machine en production
- Cet [article](https://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/) est un guide complet sur la complexit√© et l'importance de la surveillance, et fournit des conseils pratiques sur la surveillance des syst√®mes de blanchiment d'argent.
- L'int√©gration continue est une pratique de d√©veloppement de logiciels qui consiste √† tester automatiquement chaque modification apport√©e √† la base de code. Cela permet de d√©tecter le changement granulaire qui entra√Æne l'√©chec des tests et permet √† l'√©quipe de r√©soudre le probl√®me d'int√©gration au d√©but du cycle de d√©veloppement. Dans cette [vid√©o](https://www.youtube.com/watch?v=9BgIDqAzfuA&feature=youtu.be), d√©couvrez comment cette pratique peut √™tre appliqu√©e aux projets d'apprentissage machine avec des outils tels que [Continuous Machine Learning](https://github.com/iterative/cml) (CML).

## Big Bird pour des s√©quences plus longues
![La figure montre comment Big Bird est capable de maintenir les propri√©t√©s de trois m√©canismes d'attention diff√©rents - Zaheer et al. (2020)](https://cdn-images-1.medium.com/max/800/1*LhjnhIRT8TGzFRAa63THyA.png)
*La figure montre comment Big Bird est capable de maintenir les propri√©t√©s de trois m√©canismes d'attention diff√©rents - [Zaheer et al. (2020)](https://arxiv.org/abs/2007.14062).*

\\
Il est bien connu que les mod√®les de langage bas√©s sur des transformers reposent sur le m√©canisme d'auto-attention ont une complexit√© quadratique dans le nombre de tokens. [Big Bird](https://arxiv.org/abs/2007.14062) est un mod√®le bas√© sur Transformer qui vise √† soutenir plus efficacement les t√¢ches de NLP n√©cessitant des contextes plus longs en r√©duisant la complexit√© du m√©canisme d'attention √† une complexit√© lin√©aire dans le nombre de tokens.

\\
Pourquoi est-ce important ? Le traitement et l'extraction d'informations √† partir de s√©quences plus longues sont utiles lorsqu'il s'agit de textes longs tels que des livres ou des articles scientifiques. Dans de tels cas, nous voudrions minimiser l'empreinte m√©moire, c'est pourquoi il est important de r√©duire la complexit√© de la composante du m√©canisme d'attention dans l'architecture de mod√©lisation du langage. La r√©duction de la complexit√© est importante, tout comme le fait de conserver les propri√©t√©s originales du mod√®le. La fa√ßon dont Big Bird y parvient est de consid√©rer l'auto-attention comme un graphe enti√®rement connect√© et de tirer parti des propri√©t√©s du graphe, en augmentant notamment la vitesse de circulation des informations entre les paires de n≈ìuds. Les auteurs affirment qu'avec la nouvelle attention r√©duite propos√©e, leur mod√®le peut g√©rer des s√©quences *"d'une longueur pouvant atteindre 8 fois ce qui √©tait possible auparavant avec un mat√©riel similaire "*.

\\
***En savoir plus üéì***

\\
Si vous voulez avoir plus d‚Äôinformations sur les choix de conception de Big Bird, Yannic Kilcher fournit une explication de ce mod√®le dans cette [vid√©o](https://www.youtube.com/watch?v=WVPE62Gk3EM&t=678s).

## P√©n√©trer dans l'apprentissage profond et le NLP
L'un des plus grands changements auxquels beaucoup d'entre nous ont d√ª s'habituer cette ann√©e en raison de la pand√©mie est l'id√©e d'apprendre √† distance. Cela a √©galement ouvert de nombreuses possibilit√©s d'apprentissage non seulement pour les communaut√©s locales mais aussi pour les √©tudiants du monde entier. Dans cette partie de la newsletter, nous partageons quelques ressources pour ceux qui cherchent √† se lancer dans l'apprentissage approfondi ou le NLP.

\\
***Groupe d‚Äô√©tude ¬´ Dive into Deep Learning ¬ª***

\\
Le week-end dernier, dair.ai a accueilli la premi√®re session du nouveau groupe d'√©tude sur l'apprentissage approfondi. La session a dur√© plus d'une heure et s'est concentr√©e sur un large aper√ßu de l'apprentissage approfondi. Plus de 150 personnes venant du monde entier ont particip√© √† la session en direct (voir l'enregistrement [ici](https://www.youtube.com/watch?v=xS3_b0BsSes)). La deuxi√®me session visera √† couvrir quelques pr√©liminaires tels que la probabilit√© et les statistiques, l'alg√®bre lin√©aire, et d'autres concepts importants pour l'√©tude et l'application des concepts de l'apprentissage approfondi. Si vous souhaitez vous joindre aux prochaines sessions, d√©couvrez ce groupe d'√©tude [ici](https://github.com/dair-ai/d2l-study-group).

\\
![La structure du contenu du programme d'√©tudes d'apprentissage approfondi](https://cdn-images-1.medium.com/max/800/1*nwPo0Xyi9GuEMFK12zZkVg.png)
*La structure du contenu du programme d'√©tude de l'apprentissage profond*

\\
***S'initier au NLP gr√¢ce √† deeplearning.ai***

\\
R√©cemment, deeplearning.ai a publi√© une nouvelle [sp√©cialisation ax√©e sur le NLP](https://www.deeplearning.ai/natural-language-processing-specialization/). Lors d'une r√©cente table ronde, Andrew Ng a √©t√© rejoint par des experts du domaine et a discut√© de sujets int√©ressants autour de "l'entr√©e dans le NLP". La discussion a mis l'accent sur les tendances duNLP et sur d'autres conseils pour les √©tudiants. Elvis a √©crit un [fil de discussion](https://twitter.com/omarsar0/status/1288776352460673024?s=20) sur les points qu'il a retenus de cette session, qui vont des conseils aux √©tudiants aux domaines de recherche int√©ressants et aux tendances du NLP.

\\
***LxMLS Lisbon Machine Learning School***

\\
Le LxMLS 2020 √† l'[Instituto Superior T√©cnico](http://tecnico.ulisboa.pt/en/)(IST) a eu lieu √† distance et toutes les conf√©rences ont √©t√© donn√©es et diffus√©es publiquement en ligne. Ce programme est consid√©r√© comme l'un des meilleurs programmes d'apprentissage de la NLP en Europe. Plusieurs chercheurs renomm√©s ont soit particip√© au programme dans le pass√©, soit enseign√© dans le cadre du programme. La [10e √©dition du LxMLS](http://lxmls.it.pt/2020/?page_id=19) comprenait des conf√©rences par exemple sur la mod√©lisation de donn√©es s√©quentielles ou encore l'application de l'apprentissage par renforcement dans le contexte du NLP. Vous pouvez trouver toutes [les conf√©rences](https://www.youtube.com/channel/UCkVFZWgT1jR75UvSLGP9_mw/videos) sur YouTube.

\\
***Apprentissage profond pour la vision par ordinateur***

\\
Justin Johnson a r√©cemment annonc√© qu'ils ont publi√© toutes les [conf√©rences vid√©o](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r) pour leur nouveau cours sur l'apprentissage approfondi de la vision par ordinateur. Selon Justin, il s‚Äôagit d‚Äôune √©volution du cours [CS231n](http://cs231n.stanford.edu/2019/) qui a √©t√© dispens√© √† Stanford par lui et d'autres. Tout le contenu a √©t√© actualis√© et les conf√©rences incluent maintenant de nouveaux sujets comme la vision 3D et les transformers appliqu√©s dans le contexte de la vision par ordinateur.

\\
***Rester inform√© üéØ***

\\
[NLP with Friends](https://nlpwithfriends.com/) est un effort pour rassembler les √©tudiants afin de discuter de sujets de recherche int√©ressants li√©s au NLP. Des discussions sont organis√©es chaque semaine sur Zoom afin que vous puissiez vous joindre aux sessions √† distance.

\\
***En savoir plus üéì***

\\
*Voici quelques concours et ateliers li√©s au NLP que nous avons trouv√©s utiles pour vous faire participer:*
- [***Contradictoire, mon cher Watson : D√©tecter la contradiction et l'implication dans un texte multilingue en utilisant les TPU.***](https://www.kaggle.com/c/contradictory-my-dear-watson). Il s'agit d'un concours de type "terrain de jeu" bas√© sur l'inf√©rence en langage naturel (NLI) pour d√©terminer si des paires de phrases sont li√©es. Les participants doivent cr√©er un mod√®le de NLI √† partir d'un ensemble de donn√©es comprenant des textes de 15 langues diff√©rentes.
- [***Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC)***](https://hasocfire.github.io/hasoc/2020/call_for_participation.html) fournit un forum et un d√©fi pour promouvoir la recherche multilingue sur la d√©tection des contenus probl√©matiques. Cette ann√©e, l'ensemble de donn√©es contient 10 000 tweets annot√©s en anglais, allemand et hindi. La premi√®re sous-t√¢che consiste √† d√©tecter les contenus haineux, offensants ou profanes dans le texte. La deuxi√®me sous-t√¢che est plus granulaire pour discriminer et classer les tweets. Il existe une sous-piste distincte pour le CodeMix de Dravidian (nous en avons parl√© dans notre pr√©c√©dente newsletter). La date limite d'inscription est fix√©e au 30 ao√ªt 2020.

## Pourquoi vous devriez faire du NLP sur des langues autres que l‚Äôanglais
Dans ce r√©cent [article](https://ruder.io/nlp-beyond-english), Sebastian Ruder explique pourquoi les chercheurs en NLP devraient se concentrer sur d'autres langues que l'anglais. Pour commencer, le blog souligne l'√©norme disparit√© dans la disponibilit√© des donn√©es en ligne entre une poign√©e de langues √† haute ressource (dont l'anglais, le fran√ßais, l‚Äôespagnol, ‚Ä¶) et des milliers d'autres langues. La discussion principale est centr√©e sur les facteurs qui devraient encourager davantage d'initiatives de recherche dans d'autres langues, du point de vue soci√©tal, linguistique, de l'apprentissage machine, culturel et normatif, et cognitif.

\\
![Distribution des ressources linguistiques de Joshi et al. (2020). Les groupes 5 et 4 sont des langues qui sont bien √©tudi√©es alors que les autres groupes sont largement n√©glig√©s](https://cdn-images-1.medium.com/max/800/0*61agh1MtYJRPZGDG.png)
*Distribution des ressources linguistiques de [Joshi et al. (2020)](https://arxiv.org/abs/2004.09095). Les groupes 5 et 4 sont des langues qui sont bien √©tudi√©es alors que les autres groupes sont largement n√©glig√©s.*

\\
L'un des points abord√©s est la mani√®re dont les mod√®les sp√©cifiques √† l'anglais peuvent limiter l'acc√®s √† la connaissance en raison des barri√®res linguistiques, provoquer des pr√©jug√©s et des discriminations √† l'encontre des non-anglophones, ainsi que mettre en danger une langue elle-m√™me dans des cas extr√™mes. D'un point de vue linguistique, de nombreuses langues riches en ressources sont morphologiquement pauvres, ce qui signifie que nous passons √† c√¥t√© de la capacit√© de g√©n√©ralisation en ignorant les autres langues qui peuvent aider les mod√®les √† apprendre ces informations. Consid√©rer les choses d'un point de vue ML, √©tant donn√© que la plupart des langues ont des donn√©es limit√©es disponibles, jeter beaucoup de donn√©es et esp√©rer le meilleur r√©sultat ne peut √™tre la solution. Les approches qui tiennent compte des langues et qui peuvent fonctionner avec peu de donn√©es ont plus de chances d'avoir un r√©el impact. Le blog se termine par un appel √† l'action pour de futures recherches, notamment la cr√©ation d'ensembles de donn√©es dans plusieurs langues, l'√©valuation d'une approche dans plusieurs langues et le respect de la [r√®gle de Bender](https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/).

## CoVoST V2 : D√©velopper l'ensemble de donn√©es de traduction de la parole au texte multilingue le plus vaste et le plus diversifi√©
Les ensembles de donn√©es multilingues permettent de mieux tester la robustesse des mod√®les d'apprentissage automatique qui visent √† traiter soit la mod√©lisation du langage, soit la reconnaissance vocale. Un domaine de l'apprentissage automatique qui pourrait b√©n√©ficier de ce type de donn√©es est celui des applications de traduction vocale multilingue. Ces types de mod√®les peuvent contribuer √† lever les obstacles qui sont tr√®s courants avec les outils de communication en ligne, o√π les utilisateurs proviennent de cultures diff√©rentes. Ils peuvent √©galement contribuer √† enrichir les conversations des personnes qui ne ma√Ætrisent pas certaines langues et √† amplifier leur voix en ligne. Il existe toute une s√©rie d'autres fa√ßons d'utiliser l'ensemble de donn√©es et les applications qui en d√©pendent, comme la cr√©ation de compositeurs intelligents ou d'outils de recherche plus accessibles.

\\
Facebook AI [publi√©] (https://ai.facebook.com/blog/covost-v2-expanding-the-largest-most-diverse-multilingual-speech-to-text-translation-data-set/) CoVoST V2, qu'ils consid√®rent comme le plus grand ensemble de donn√©es multilingues parole-texte disponible √† ce jour. La nouvelle version de l'ensemble de donn√©es ajoute de nouvelles langues √† la premi√®re version pr√©c√©dente, avec un total de 2900 heures de parole. Avant de la publier, les chercheurs ont v√©rifi√© la qualit√© des donn√©es et ont constat√© qu'elle variait selon des crit√®res tels que l'√¢ge, le sexe et les accents. Avec ce nouvel ensemble de donn√©es, on esp√®re qu'il favorisera la recherche en mati√®re de traduction vocale multilingue et qu'il permettra √† un seul mod√®le de prendre en charge de nombreuses paires de langues, en particulier pour les paires comportant moins de donn√©es.

\\
![Source : Blog AI de Facebook](https://cdn-images-1.medium.com/max/800/0*QMQ1t222en_RAY_i.png)
*Source : [Blog Facebook AI](https://ai.facebook.com/blog/covost-v2-expanding-the-largest-most-diverse-multilingual-speech-to-text-translation-data-set/)*

## L'avenir des syst√®mes d'IA conversationnelle
Lors d'une r√©cente [table ronde](https://www.youtube.com/watch?v=41-FNujbKac&list=PL75e0qA87dlGP51yZ0dyNup-vwu0Rlv86&index=24) sur ce que les d√©veloppeurs d'IA conversationnelle devraient savoir sur le ML et la linguistique, Vladimir Vlasov, Emily Bender, Thomas Wolf et Anna Rogers ont partag√© leurs points de vue et leurs pr√©occupations. Le consensus g√©n√©ral est que les mod√®les linguistiques actuels sont capables d'obtenir des r√©sultats remarquables dans certaines t√¢ches, mais les experts pensent que nous ne testons pas les mod√®les pour les bonnes choses. Ce n'est pas parce qu'un mod√®le linguistique pr√©-entra√Æn√© peut d√©j√† √™tre utilis√© pour construire des applications cr√©atives que cela signifie que nous avons r√©solu le probl√®me de la mod√©lisation linguistique.

\\
D'autres sujets de discussion int√©ressants ont port√© sur les moyens d'am√©liorer l'√©valuation des mod√®les linguistiques et de mieux comprendre ce que les mod√®les apprennent r√©ellement. √Ä l'heure actuelle, il est vraiment difficile de dire quels aspects de la langue ces mod√®les captent r√©ellement. Cela devient d'autant plus difficile qu'un nombre croissant de ces mod√®les pr√©-entra√Æn√©s, reposant sur des architectures diff√©rentes et construits sur des objectifs diff√©rents, continuent √† √©merger rapidement. Nous devons donc nous concentrer davantage sur la normalisation des m√©thodes d'√©valuation et nous pencher sur la question de savoir ce que ces mod√®les capturent r√©ellement et comment √©viter leur utilisation n√©faste d'un point de vue pratique, par exemple lors de la construction de syst√®mes d'IA conversationnels.

\\
N'h√©sitez pas √† consulter ce fil de discussion sur [Twitter](https://twitter.com/omarsar0/status/1291725568640245760?s=20) ou √† vous rendre directement √† la table ronde.

# Mentions sp√©ciales ‚≠êÔ∏è
***Comprendre et mettre en ≈ìuvre SimCLR en PyTorch - Un guide ELI5***

\\
Auparavant, nous avons abord√© le cadre SimCLR utilis√© pour entra√Æner des repr√©sentations visuelles riches et pour am√©liorer les performances par rapport aux m√©thodes d'apprentissage auto-supervis√© et semi-supervis√© sur ImageNet. SimCLR est bas√© sur un apprentissage contrastif qui tente d'entra√Æner un mod√®le √† [*distinguer les choses similaires et dissemblables*](https://amitness.com/2020/03/illustrated-simclr/)*.  Marcin a r√©cemment √©crit un [article d√©taill√©](https://zablo.net/blog/post/understanding-implementing-simclr-guide-eli5-pytorch/) fournissant une description et une explication du code de ce cadre en utilisant PyTorch.

\\
***L'hypoth√®se du billet de loterie***

\\
Est-il possible de trouver des sous-r√©seaux dont les performances sont similaires √† celles du r√©seau neuronal d'origine pour des t√¢ches sp√©cifiques ? En utilisant des techniques d'√©lagage, la recherche actuelle soutient que c'est effectivement possible, affirmant que la fa√ßon dont les mod√®les sont initialis√©s a beaucoup √† voir avec l'obtention de cet effet. Pour en savoir plus sur ce domaine de recherche, consultez ce [bref r√©sum√©](https://medium.com/dair-ai/the-lottery-ticket-hypothesis-7cd4eae3faaa).

\\
***NodeNet : Un r√©seau neuronal r√©gularis√© par graphique pour la classification des n≈ìuds***

\\
Les algorithmes d'apprentissage bas√©s sur des graphes utilisent efficacement les donn√©es et les informations connexes pour construire des mod√®les sup√©rieurs. L'apprentissage neural par graphes (NGL) est une de ces techniques qui utilise un algorithme d'apprentissage machine traditionnel avec une fonction de perte modifi√©e pour exploiter les bords de la structure du graphe. Ce [travail](https://arxiv.org/abs/2006.09022) propose un mod√®le utilisant NGL - NodeNet, pour r√©soudre la t√¢che de classification des n≈ìuds pour les graphes de citation. Les auteurs affirment que NodeNet permet d'obtenir des r√©sultats de pointe sur des articles avec du code pour les ensembles de donn√©es Pubmed et Citeseer.

\\
**Quand est-ce qu'un embedding contextuel vaut la peine d'√™tre utilis√© ?**

\\
Dans ce [billet de blog](https://medium.com/dair-ai/when-are-contextual-embeddings-worth-using-b509008cc325), Viktor Karlsson r√©sume un article qui traite de situations o√π il pourrait √™tre judicieux d'utiliser des embeddings contextuels (par exemple, BERT) et o√π cela ne vaut pas la peine.

\\
***Apprentissage simple et efficace du traitement du langage naturel, avec Moshe Wasserblat, Intel AI***

\\
Dans cette [conf√©rence](https://youtu.be/Bgr684dPJ6U), Moshe Wasserblat, Intel AI, pr√©sente des m√©thodes simples et efficaces d'apprentissage profond en NLP. L'orateur donne des informations sur les vecteurs d'optimisation les plus populaires et des conseils sur la distillation de BERT pour une inf√©rence beaucoup plus rapide avec une p√©nalit√© de pr√©cision durable. Les r√©sultats de l'ensemble de donn√©es [dair.ai emotion dataset](https://github.com/dair-ai/emotion_dataset) et d'autres points de r√©f√©rence populaires ont √©galement √©t√© abord√©s.

\\
***DeText : Un cadre NLP pour une compr√©hension intelligente des textes***

\\
[DeText](https://engineering.linkedin.com/blog/2020/open-sourcing-detext) est un cadre permettant de tirer parti des technologies comme BERT pour la compr√©hension des textes. DeText offre des fonctionnalit√©s qui rendent possible l'utilisation de grands mod√®les qui n√©cessitent des co√ªts de calcul √©lev√©s d√®s le d√©part. Gr√¢ce √† ce cadre, il est possible de mettre en ≈ìuvre un classement neuronal pour les syst√®mes de recherche et de recommandation.

----------

Vous pouvez retrouver la pr√©c√©dente newsletter [ici](https://dair.ai/NLP_Newsletter_-13_-FR/)

\\
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newsletter, vous pouvez utiliser ce [formulaire](https://forms.gle/3b7Q2w2bzsXE6uYo9).

\\
[Abonnez-vous](https://dair.ai/newsletter/) pour recevoir les prochains num√©ros dans votre bo√Æte mail.
