---
layout: post
title: "NLP Haber BÃ¼lteni #8 [TR]: NeRF, CORD-19, Stanza, Text Generation 101, Notebooks, SECNLP, Dreamer,â€¦"
author: harunuz
excerpt: "Bu sayÄ±, karmaÅŸÄ±k sahnelerin yeni gÃ¶rÃ¼nÃ¼mlerini sentezlemeden metin oluÅŸturma ve Ã¶ÄŸrenme aktarÄ±mÄ±na yÃ¶nelik rehberlere ve baÄŸlamsal gÃ¶mmeler ve Ã¶n-eÄŸitime tabi tutulmuÅŸ dil modelleri hakkÄ±ndaki derleme yayÄ±nlarÄ±na kadar uzanan konularÄ± kapsar."
modified:
comments: true
tags: [nlp_newsletter]
image:
  thumb: nlp_newsletter_8.png
---

![](https://cdn-images-1.medium.com/max/1200/1*SptuncVzQw49OZFlDVaQdw.png)

# dair.ai sitesinden gÃ¼ncellemeler
- TÃ¼m TL;DR ve NLP bildiri Ã¶zetlerini iÃ§eren [repo](https://github.com/dair-ai/nlp_paper_summaries)â€™ya daha iyi bir kategorizasyon ekledik.
- NLP Haber BÃ¼lteni'nin tÃ¼m sayÄ± ve Ã§evirileri artÄ±k [burada](https://github.com/dair-ai/nlp_newsletter) sÃ¼rdÃ¼rÃ¼lecek.
- Bu hafta ayrÄ±ca, veri bilimi *notebook*'larÄ±nÄ± genel olarak toplulukla kolayca paylaÅŸmaya yÃ¶nelik bir merkez olan *[Notebooks](https://github.com/dair-ai/notebooks)*'u aÃ§tÄ±k. Toplulukla paylaÅŸmak istediÄŸiniz *notebook*'larÄ±nÄ±z varsa bizimle iletiÅŸime geÃ§ebilirsiniz.
- Sinir aÄŸlarÄ±nda (Ä°ng. neural networks) metinlerle Ã§alÄ±ÅŸmayÄ± kolaylaÅŸtÄ±ran TensorFlow 2.1.0'da deneysel yeni bir Ã¶zellik olan *TextVectorization*'Ä± kullanarak Ã§ok sÄ±nÄ±flÄ± duygu sÄ±nÄ±flandÄ±rma (Ä°ng. multiclass emotion classification) yapmanÄ±n adÄ±mlarÄ±nÄ± anlatan bir *[tutorial](https://colab.research.google.com/drive/1YuL0iqxaz09qR0_2Fgyi2wQHgil_Seqg)* paylaÅŸtÄ±k.

# AraÅŸtÄ±rma ve YayÄ±nlar ğŸ“™

***BaÄŸlamsal GÃ¶mmeler ve Dil Modelleri Ä°ncelemeleri***

\\
Bu [bildiri](https://arxiv.org/abs/2003.07278v1) baÄŸlamsal gÃ¶mme (Ä°ng. contextual embedding) Ã¶ÄŸrenmesine yÃ¶nelik yaklaÅŸÄ±mlarÄ±n kolay anlaÅŸÄ±lÄ±r bir incelemesini sunmaktadÄ±r. Bildiri ayrÄ±ca, Ã¶ÄŸrenme aktarÄ±mÄ± (Ä°ng. transfer learning), model sÄ±kÄ±ÅŸtÄ±rma yÃ¶ntemleri (Ä°ng. model compression methods) ve model analizinde kendi denemelerinin deÄŸerlendirmelerini de iÃ§eriyor. [Buradaki](https://arankomatsuzaki.files.wordpress.com/2020/03/written_report.pdf)  bir baÅŸka rapor ise TransformatÃ¶r (Ä°ng. transformer) tabanlÄ± dil modellerini iyileÅŸtirmek iÃ§in kullanÄ±lan yÃ¶ntemlerin bir Ã¶zetini iÃ§eriyor. AyrÄ±ca, NLP'nin Ã¶n-eÄŸitime tabi tutulmuÅŸ (Ä°ng. pre-trained) modellerinin taksonimisine iliÅŸkin bir baÅŸka kapsamlÄ± inceleme [burada](https://arxiv.org/pdf/2003.08271.pdf) bulunabilir.

\\
![](https://cdn-images-1.medium.com/max/800/1*1jLfdem3xZ0I3EVSyOy48g.png)

[*Qiu et al., 2020*](https://arxiv.org/pdf/2003.08271.pdf)

\\
***The Grand Tour ile Sinir AÄŸlarÄ± GÃ¶rselleÅŸtirmesi***

\\
*The Grand Tour* yÃ¼ksek-boyutlu bir veri kÃ¼mesini iki boyuta yansÄ±tan doÄŸrusal bir yaklaÅŸÄ±mdÄ±r (t-SNE gibi doÄŸrusal olmayan yÃ¶ntemlerden farklÄ± olarak). Distill'de yer alan yeni bir [makale](https://distill.pub/2020/grand-tour/) (Li et al. 2020)'de bir sinir aÄŸÄ±nÄ±n eÄŸitilirkenki davranÄ±ÅŸlarÄ±nÄ± gÃ¶rselleÅŸtirmek iÃ§in Grand Tour'un yeteneklerinin kullanÄ±labileceÄŸi Ã¶neriliyor. Bu davranÄ±ÅŸlar arasÄ±nda; aÄŸÄ±rlÄ±k (Ä°ng. weight) deÄŸiÅŸimleri ve bu deÄŸiÅŸimlerin eÄŸitim sÃ¼recini nasÄ±l etkilediÄŸi, bir sinir aÄŸÄ±nda katmandan katmana iletiÅŸim ve bir sinir aÄŸÄ±na karÅŸÄ±t Ã¶rnekler verildiÄŸinde oluÅŸan etkiler bulunmaktadÄ±r.

\\
![](https://cdn-images-1.medium.com/max/800/1*XYCRZOzslb-ZRYlmtHV0Ng.png)

*Kaynak:* [*Distill*](https://distill.pub/2020/grand-tour/)

\\
***DÃ¼ÅŸÃ¼k KaynaklÄ± Ä°laÃ§ KeÅŸfi iÃ§in Meta-Ã–ÄŸrenme***

\\
Meta-Ã¶ÄŸrenmenin (Ä°ng. meta-learning), az-Ã¶rnekli Ã¶ÄŸrenme (Ä°ng. few-shot learning) baÅŸarÄ±mÄ± aÃ§Ä±sÄ±ndan derin Ã¶ÄŸrenme uygulamalarÄ±nda iyileÅŸtirme saÄŸlayabileceÄŸi birÃ§ok Ã§alÄ±ÅŸmada raporlanmaktadÄ±r. Bu da Ã¶zellikle ilaÃ§ keÅŸfinde olduÄŸu gibi sÄ±nÄ±rlÄ± veri bulunan durumlarda meta-Ã¶ÄŸrenmenin Ã§ok kullanÄ±ÅŸlÄ± olabileceÄŸini gÃ¶steriyor. YakÄ±nda zamanda yapÄ±lan bu [Ã§alÄ±ÅŸma](https://arxiv.org/abs/2003.05996)da, Model-Agnostic-Meta-Learning adÄ± verilen bir meta-Ã¶ÄŸrenme yaklaÅŸÄ±mÄ± ve benzerleri az kaynaÄŸÄ±n/Ã¶rneklemin bulunduÄŸu koÅŸullarda kimsayal Ã¶zelliklerin ve davranÄ±ÅŸlarÄ±n tahmin edilebilmesi iÃ§in denendi. SonuÃ§lar gÃ¶steriyor ki; meta-Ã¶ÄŸrenme yaklaÅŸÄ±mÄ± Ã§ok-gÃ¶revli (Ä°ng. multi-task) Ã¶n-eÄŸitime tabi tutulmuÅŸ modellerle karÅŸÄ±laÅŸtÄ±rÄ±labilir bir performans ortaya koyuyor.  

\\
***NeRF: Sahne GÃ¶steriminde GÃ¶rÃ¼nÃ¼m Sentezi iÃ§in <ins>Ne</ins>ural <ins>R</ins>adiance <ins>F</ins>ields***

\\
UC Berkeley, Google Research ve UC San Diego'dan araÅŸtÄ±rmacÄ±larÄ±n yaptÄ±ÄŸÄ± heyecan verici bir Ã§alÄ±ÅŸma, karmaÅŸÄ±k sahnelerin yeni gÃ¶rÃ¼nÃ¼mlerini sentezlemek iÃ§in bir yÃ¶ntem ([NeRF] (http://www.matthewtancik.com/nerf)) sunuyor. RGB gÃ¶rsel girdilerinin bir koleksiyonunu kullanan model, 5-boyutlu koordinatlar alÄ±yor, optimize bir sÃ¼rekli hacimsel sahne fonksiyonu (Ä°ng. continuous volumetric scene function) ortaya Ã§Ä±karmak iÃ§in *fully-connected* bir DNN'i eÄŸitiyor ve berlirli bir konumla ilgili hacim yoÄŸunluÄŸu ve gÃ¶rÃ¼nÃ¼m baÄŸÄ±mlÄ± yayÄ±lan RGB Ä±ÅŸÄ±masÄ± Ã§Ä±ktÄ±larÄ± saÄŸlÄ±yor. Ã‡Ä±kÄ±ÅŸ deÄŸerleri bir kamera Ä±ÅŸÄ±nÄ± boyunca bir araya getiriliyor ve piksel olarak oluÅŸturuluyor (render ediliyor). Bu farklÄ±laÅŸtÄ±rÄ±labilir Ã§Ä±ktÄ±lar RGB gÃ¶rsellerden elde edilen *tÃ¼m kamera Ä±ÅŸÄ±nlarÄ±ndaki hatalarÄ±n minimize edilmesiyle oluÅŸan* sahne gÃ¶sterimlerinin optimize edilmesinde kullanÄ±lÄ±yor. GÃ¶rÃ¼nÃ¼m sentezlemede en iyi performansÄ± gÃ¶steren alternatifleriyle kÄ±yaslandÄ±ÄŸÄ±nda NeRF; kalitatif ve kantitatif aÃ§Ä±dan daha iyi gÃ¶rÃ¼nÃ¼yor ve yeterli detayÄ±n olmadÄ±ÄŸÄ± gÃ¶rsellerdeki tutarsÄ±zlÄ±klarÄ± ve istenmeyen yapay titremeleri giderebiliyor.

\\
![](https://cdn-images-1.medium.com/max/800/1*E6RQL5jdtHXR98BJJREDYg.png)

\\
***Dreamer'a GiriÅŸ: DÃ¼nya Modellerini Kullanarak Ã–lÃ§eklenebilir Reinforcement (Takviyeli) Ã–ÄŸrenme***

\\
[Dreamer](https://ai.googleblog.com/2020/03/introducing-dreamer-scalable.html), zorlu gÃ¶revlerin Ã§Ã¶zÃ¼mÃ¼nde karÅŸÄ±laÅŸÄ±lan bazÄ± kÄ±sÄ±tlarÄ± aÅŸmak iÃ§in sunulan Ã¼cretsiz ve model tabanlÄ± Takviyeli Ã–ÄŸrenme (RL) (Ä°ng. reinforcement learning) ajanÄ±dÄ±r. DeepMind ve Google AI araÅŸtÄ±rmacÄ±larÄ± tarafÄ±ndan Ã¶nerilen bu RL ajanÄ±, model tahminlerini kullanan geri yayÄ±lÄ±m (Ä°ng. backpropagation) aracÄ±lÄ±ÄŸÄ± ile ileri gÃ¶rÃ¼ÅŸlÃ¼ davranÄ±ÅŸlarÄ± da Ã¶ÄŸrenebilen bir dÃ¼nya modellemek iÃ§in eÄŸitildi. SoTA sonuÃ§larÄ±, verilen gÃ¶rsel girdilere dayalÄ± 20 sÃ¼rekli kontrol gÃ¶revleri Ã¼zerinden elde ediliyor. Ek olarak, modelin veri-efektif olduÄŸu gÃ¶rÃ¼lÃ¼yor ve tahminlerini onu hesaplama-efektif hale getirecek ÅŸekilde paralel yapabiliyor. FarklÄ± hedefleri baÅŸarabilen bir ajan eÄŸitmekle ilgili Ã¼Ã§ gÃ¶rev aÅŸaÄŸÄ±daki gÃ¶sterimde Ã¶zetlenmiÅŸtir:

\\
![](https://cdn-images-1.medium.com/max/800/1*DOlPDgvNu1kpTeogcLve-A.png)

*Kaynak:* [*Google AI Blog*](https://ai.googleblog.com/2020/03/introducing-dreamer-scalable.html)


# YaratÄ±cÄ±lÄ±k, Etik ve Toplum ğŸŒ

***COVID-19 Open Research Dataset (CORD-19)***

\\
COVID-19 ile mÃ¼cadelede, dÃ¼nyanÄ±n her bir yanÄ±ndan araÅŸtÄ±rmacÄ±larÄ±n birlik olmasÄ±nÄ± ve AI kullanÄ±mÄ±nÄ± teÅŸvik etmek amacÄ±yla Allen Institute of AI, Ã¼cretsiz ve aÃ§Ä±k kaynaklÄ± olan [COVID-19 Open Research Dataset (CORD-19)](https://pages.semanticscholar.org/coronavirus-research) Ã§alÄ±ÅŸmasÄ±nÄ± yayÄ±mladÄ±. Veri seti, NLP'den ilham alan Ã§alÄ±ÅŸmalardan ve [COVID-19](https://www.who.int/emergencies/diseases/novel-coronavirus-2019) ile mÃ¼cadelede yardÄ±mcÄ± olabilecek binlerce bilimsel makaleden oluÅŸmaktadÄ±r.

\\
***SECNLP: Klinik doÄŸal dil iÅŸlemede gÃ¶mme metotlarÄ± Ã¼zerine inceleme***

\\
[SECNLP](https://www.sciencedirect.com/science/article/pii/S1532046419302436) tÄ±p alanÄ±nda geniÅŸ Ã¶lÃ§ekte kullanÄ±lan NLP tekniklerine detaylÄ± genel bakÄ±ÅŸ saÄŸlayan bir inceleme bildirisidir. Ã‡alÄ±ÅŸma Ã§oÄŸunlukla gÃ¶mme (Ä°ng. embedding) metotlarÄ±, bu metotlarÄ±n zorluklarÄ±/problemleri ve gelecekteki araÅŸtÄ±rma yÃ¶nlerinin deÄŸerlendirilmesini vurgulamaktadÄ±r.

\\
***3B Ãœretken TasarÄ±m iÃ§in Yapay Zeka (AI)***

\\
[Bu yazÄ±](https://blog.insightdatascience.com/ai-for-3d-generative-design-17503d0b3943), doÄŸal dil betimlemelerinden 3 boyutlu nesneleri oluÅŸturmakta kullanÄ±lan bir yaklaÅŸÄ±mÄ± iÃ§ermektedir. YaklaÅŸÄ±mÄ±n ana fikri, tasarÄ±mcÄ±nÄ±n tasarÄ±m sÃ¼recini hÄ±zlÄ± bir ÅŸekilde yinelemesine ve tasarÄ±m alanÄ±nÄ± daha geniÅŸ keÅŸfedebilmesine olanak saÄŸlamaktÄ±r. 3B modeller ve metin betimlemelerinden oluÅŸan tasarÄ±m alanÄ±na dair bir bilgi tabanÄ± oluÅŸturulduktan sonra iki adet otokodlayÄ±cÄ± (Ä°ng. autoencoder) (aÅŸaÄŸÄ±daki ÅŸekilde gÃ¶rÃ¼lebilir) bu bilgiyi sezgisel bir etkileÅŸime girilebilecek ÅŸekilde kodlamaktadÄ±r. Bir araya getirilen model, bir betimleme metni alÄ±p Ã¼Ã§ boyutlu bir tasarÄ±m Ã¼retebilmektedir. [Burada](https://insight2020a.streamlit.io/starstorms9/shape/) siz de deneyebilirsiniz.

\\
![](https://cdn-images-1.medium.com/max/800/0*pbBv2Wa5QX7lUufY.png)

[*Kaynak*](https://blog.insightdatascience.com/ai-for-3d-generative-design-17503d0b3943)


# AraÃ§lar ve Veri Setleri âš™ï¸

***Stanzaâ€Šâ€”â€ŠBirÃ§ok Ä°nsan Dili iÃ§in Python NLP KÃ¼tÃ¼phanesi***

\\
Stanford NLP Group, 70'ten fazla dil iÃ§in ezber bozan metin analiz araÃ§larÄ± saÄŸlayan bir Python NLP kÃ¼tÃ¼phanesi, [Stanza](https://stanfordnlp.github.io/stanza/)'yÄ± yayÄ±mladÄ±. KÃ¼tÃ¼phane, tokenizasyon (Ä°ng. tokenization), Ã§ok-kelimeli token geniÅŸletme, kelime kÃ¶kÃ¼ bulma, cÃ¼mleyi Ã¶ÄŸelerine ayÄ±rma (POS), varlÄ±k ismi tanÄ±ma (NER) (Ä°ng. named entity recognition) ve daha birÃ§ok NLP iÅŸlemi yapabilmeye olanak saÄŸlamaktadÄ±r. GPU'nun ve Ã¶n-eÄŸitime tabi tutulmuÅŸ sinir aÄŸÄ± modellerinin kullanÄ±mÄ±na destek veren PyTorch Ã¼zerine inÅŸa edilmiÅŸtir. DiÄŸer yandan, [Explosion](https://github.com/explosion/spacy-stanza) da Stanza modelleri ile spaCy iÅŸlem dizisi gibi etkileÅŸime geÃ§ilebilmeyi saÄŸlayan bir modÃ¼l geliÅŸtirdi.

\\
***GridWorld Playground***

\\
Pablo Castro, kareli bir oyun alanÄ± ortamÄ± oluÅŸturulabilecek ilginÃ§ bir [internet sitesi](https://gridworld-playground.glitch.me/) geliÅŸtirdi. OluÅŸturulan ortamda takviyeli Ã¶ÄŸrenme ajanÄ±nÄ±n GridWorld oyununu nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼ gÃ¶zlemlenebilmektedir. Oyun esnasÄ±nda gerÃ§ek zamanlÄ± olarak ajanÄ±n pozisyonu, Ã¶ÄŸrenme/ortam parametreleri deÄŸiÅŸtirilebilir ve 2 ajan arasÄ±nda deÄŸerler transfer edilebilir.

\\
![](https://cdn-images-1.medium.com/max/800/1*D1e6ixTEONl21t0UNmcaog.png)

\\
***X-Stance: DuruÅŸ Tespiti iÃ§in Ã‡ok Dilli Ã‡ok Hedefli Veri Seti***

\\
[*DuruÅŸ tespiti*](http://nlpprogress.com/english/stance_detection.html) (Ä°ng. stance detection), bir aktÃ¶rÃ¼n herhangi bir konu hakkÄ±ndaki iddiasÄ± karÅŸÄ±sÄ±nda deneÄŸin verdiÄŸi tepkinin belirlenmesidir. Sahte haberlerin deÄŸerlendirilmesinde kullanÄ±lmasÄ± amaÃ§lanmaktadÄ±r. Jannis Vamvas ve Rico Sennrich, Ä°sviÃ§re'deki seÃ§im adaylarÄ±nÄ±n yazÄ±lÄ± metinlerinden oluÅŸan [bÃ¼yÃ¼k Ã¶lÃ§ekli bir duruÅŸ tespit veri setini](https://arxiv.org/abs/2003.08385) kÄ±sa bir sÃ¼re Ã¶nce yayÄ±mladÄ±lar. Metinler Ã§ok dilli bir ÅŸekilde kullanÄ±ma hazÄ±r haldeler. Bu sayede duruÅŸ tespiti gÃ¶revinde diller-arasÄ± deÄŸerlendirmelere olanak saÄŸlanabilecek. Yazarlar, Ã§ok dilli/hedefli doÄŸal dil iÅŸleme problemlerinde ve eÄŸitim veri setinde olmayan nesneleri anlamlandÄ±rmada tatmin edici performanslara ulaÅŸan Ã§ok dilli BERT modelinin kullanÄ±lmasÄ±nÄ± da Ã¶nermektedir. Ã–zellikle farklÄ± hedeflerin Ã¶ÄŸrenilmesi zorlayÄ±cÄ± bir gÃ¶revdir. Bu yÃ¼zden yazarlar basitleÅŸtirilmiÅŸ hedefler ile veri setindeki bÃ¼tÃ¼n sorunlarÄ±n aynÄ± anda eÄŸitileceÄŸi sade bir model kullanmÄ±ÅŸlar.

\\
***Jupyter notebooklarÄ± iÃ§in bir metne ait interaktif sÄ±caklÄ±k haritalarÄ± oluÅŸturun***

\\
Andread Madsen, dil modellerinde, modelin bir sonraki kelimeyi tahmin ederken cÃ¼mlenin hangi kÄ±sÄ±mlarÄ±nÄ± kullandÄ±ÄŸÄ±nÄ± anlamaya yardÄ±mcÄ± olacak, [TextualHeatMap](https://github.com/AndreasMadsen/python-textualheatmap) adÄ±nda bir kÃ¼tÃ¼phane geliÅŸtirdi. TextualHeatMap ile Ã¼zerinde Ã§alÄ±ÅŸÄ±lan metne ait intraktif sÄ±caklÄ±k haritalarÄ± gÃ¶rselleÅŸtirilebilmektedir.

\\
![](https://cdn-images-1.medium.com/max/800/0*IY3tKkznwarnRxdo.gif)

*Kaynak:* [*textualheatmap*](https://github.com/AndreasMadsen/python-textualheatmap)


# Makaleler ve Blog gÃ¶nderileri âœï¸

***NasÄ±l metin Ã¼retilir: Transformers KÃ¼tÃ¼phanesi ile dil Ã¼retmek iÃ§in farklÄ± kod Ã§Ã¶zme metotlarÄ±nÄ±n kullanÄ±mÄ±***

\\
Huggingface, Ã¶zellikle transformatÃ¶r tabanlÄ± dil Ã¼retiminde kullanÄ±lan farklÄ± teknikleri aÃ§Ä±klayan bir [makale](https://huggingface.co/blog/how-to-generate) yayÄ±mladÄ±. Bahsedilen teknikler arasÄ±nda aÃ§gÃ¶zlÃ¼ arama (Ä°ng. greedy search), Ä±ÅŸÄ±n aramasÄ± (Ä°ng. beam search), Ã¶rnekleme (Ä°ng. sampling), en-iyi-k Ã¶rnekleme (Ä°ng. top-k sampling) ve en-iyi-p Ã¶rnekleme (top-p/nucleus sampling) yÃ¶ntemleri yer almaktadÄ±r. Bu tarz makalelerden oldukÃ§a fazla olsa da yazarlar bahsi geÃ§en tekniklerin pratik yÃ¶nlerini ve kÄ±sa kod parÃ§acÄ±klarÄ± ile nasÄ±l kullanÄ±lacaklarÄ±nÄ± aÃ§Ä±klamada oldukÃ§a zaman harcamÄ±ÅŸlar.

\\
***SÄ±fÄ±rdan RoBERTa EÄŸitimiâ€Šâ€”â€ŠKayÄ±p Rehber***

\\
Bert tarzÄ± modellerin TransformatÃ¶rler kullanÄ±larak sÄ±fÄ±rdan eÄŸitilmesine dair geniÅŸ kapsamlÄ± rehber kÄ±tlÄ±ÄŸÄ±ndan ilham alarak harekete geÃ§en Marcin Zablocki, hazÄ±rladÄ±ÄŸÄ± [detaylÄ± eÄŸitici rehberini](https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/) yayÄ±mladÄ±. Rehber, sÄ±k yapÄ±lan hatalardan kaÃ§Ä±nmak iÃ§in ipuÃ§larÄ± ile LehÃ§e dili iÃ§in bir transformatÃ¶r tabanlÄ± dil modelinin nasÄ±l eÄŸitileceÄŸini gÃ¶stermektedir. Veriyi hazÄ±rlama, Ã¶n-eÄŸitim ayarlarÄ±, tokenizasyon, eÄŸitim, eÄŸitim sÃ¼recinin izlenmesi ve modelin paylaÅŸÄ±mÄ± gibi konular Ã¼zerinde birÃ§ok Ã¶neriye de sahip.

\\
![](https://cdn-images-1.medium.com/max/800/0*PFPgjeUmzvazglqg.png)

# EÄŸitim ğŸ“

***JAX'a BaÅŸlangÄ±Ã§ (MLP, CNN & RNN)***

\\
Robert Lange, kÄ±sa bir sÃ¼re Ã¶nce JAX kullanarak nasÄ±l GRU-RNN eÄŸitilebileceÄŸini anlattÄ±ÄŸÄ± [rehberini](https://roberttlange.github.io/posts/2020/03/blog-post-10/) yayÄ±mladÄ±. Bir [Ã¶nceki haber bÃ¼lteni](https://medium.com/dair-ai/nlp-newsletter-nlp-paper-summaries-learning-to-simulate-transformers-notebooks-med7-measuring-de61fadd9db0)'nde de JAX ile ilgili kaynaklarÄ± paylaÅŸmÄ±ÅŸtÄ±k.

\\
***GeliÅŸtiriciler iÃ§in NLP: Kelime GÃ¶mmeleri***

\\
Rachael Tatman GeliÅŸtiriciler iÃ§in NLP (Ä°ng. NLP for Developers) adÄ±nÄ± verdiÄŸi ve geniÅŸ Ã¶lÃ§ekli NLP uygulamalarÄ±nÄ±n en iyi yÃ¶ntemlerini kapsayacak serisinin ilk bÃ¶lÃ¼mÃ¼nÃ¼ yayÄ±mladÄ±. [Ä°lk BÃ¶lÃ¼m](http://youtube.com/watch?v=oUpuABKoElw&feature=emb_logo), kelime gÃ¶mmelerini, gÃ¶mmelerin nasÄ±l kullanÄ±ldÄ±ÄŸÄ±nÄ± ve gerÃ§eklerken kaÃ§Ä±nÄ±lmasÄ± gereken yaygÄ±n hatalarÄ± iÃ§ermektedir.

\\
***Thomas Wolf: HuggingFace ve Ã–ÄŸrenme AktarÄ±mÄ±na GiriÅŸ***

\\
Thomas Wolf, NLP ZÃ¼rih buluÅŸmasÄ±nda Ã¶ÄŸrenme aktarÄ±mÄ± Ã¼zerine yaptÄ±ÄŸÄ± [konuÅŸmasÄ±nÄ±](ttps://www.youtube.com/watch?v=rEGB7-FlPRs&feature=youtu.be) NLP'de Ã¶ÄŸrenme aktarÄ±mÄ±na Ã§ok iyi bir giriÅŸ yaparak sundu. KonuÅŸma, NLP alanÄ±ndaki en gÃ¼ncel bÃ¼yÃ¼k geliÅŸmeleri ve HuggingFace takÄ±mÄ± ile katkÄ±da bulunan gÃ¶nÃ¼llÃ¼ler tarafÄ±ndan yayÄ±mlanan en popÃ¼ler iki kÃ¼tÃ¼phane, Transformers ve Tokenizers, Ã¼zerine genel bir bakÄ±ÅŸ iÃ§ermektedir.

\\
![](https://cdn-images-1.medium.com/max/800/1*PMZ8ptBWo4wZ432kr-FXqA.png)


# Bunlara da bir gÃ¶z atÄ±n â­ï¸

Google E-Tablolar'Ä±n Ã¼cretsiz tercÃ¼me Ã¶zelliÄŸi saÄŸladÄ±ÄŸÄ±nÄ± biliyor muydunuz? Amit Chaudhary, paylaÅŸtÄ±ÄŸÄ± [makalesinde](https://amitness.com/2020/02/back-translation-in-google-sheets/) bu Ã¶zelliÄŸi kullanarak sÄ±nÄ±rlÄ± metin derleminizi (Ä°ng. text corpus) NLP projeleriniz iÃ§in nasÄ±l Ã§oÄŸaltabileceÄŸinizi gÃ¶stermiÅŸ.

\\
New York NLP, "Vikipedi ve NLP iÃ§in Wikidata" baÅŸlÄ±klÄ± internet Ã¼zerinden yapÄ±lacak bir [buluÅŸmaya](https://www.meetup.com/NY-NLP/events/269502774/) ev sahipliÄŸi yapacak. Etkinlikte sunucu, Vikipedi'nin farklÄ± NLP projeleri ve kullanÄ±m senaryolarÄ±nda nasÄ±l kaldÄ±raÃ§ olarak kullanÄ±labileceÄŸi Ã¼zerine konuÅŸma yapacak.

\\
Lavanya Shukla PyTorch Lightning'i kullanarak bir sinir aÄŸÄ±nÄ±n hiperparametrelerinin nasÄ±l optimize edileceÄŸini anlatan bu gÃ¼zel [rehberini](ttps://app.wandb.ai/cayush/pytorchlightning/reports/Use-Pytorch-Lightning-with-Weights-%26-Biases--Vmlldzo2NjQ1Mw) yazdÄ±. AynÄ± zamanda PyTorch Lightning tarafÄ±ndan saÄŸlanan sade kod yapÄ±larÄ±nÄ±n avantajlarÄ±ndan da yararlanÄ±labilmektedir. SonuÃ§ model ve farklÄ± hiperparametrelerinin performansÄ±, eÄŸitici objeye parametre gÃ¶nderilerek Ã§aÄŸÄ±rÄ±lan WandB raporlama aracÄ±nÄ±n Ã¼rettikleri ile gÃ¶rselleÅŸtirilebilmektedir.

\\
Bir grup araÅŸtÄ±rmacÄ±, yÄ±ÄŸÄ±n normalizasyonunun (Ä°ng. batch normalizaton) farklÄ± NLP gÃ¶revlerine uygulanmÄ±ÅŸ TransformatÃ¶r tabanlÄ± modellerde performansÄ± neden kÃ¶tÃ¼ yÃ¶nde etkilediÄŸini detaylÄ± bir ÅŸekilde inceledikleri [Ã§alÄ±ÅŸmalarÄ±nÄ±](https://arxiv.org/abs/2003.07845) yayÄ±mladÄ±lar. Bulunanlara gÃ¶re, yÄ±ÄŸÄ±n normalizasyonunda ortaya Ã§Ä±kan sorunlara Ã§Ã¶zÃ¼m bulabilmek adÄ±na yazarlar, kuvvet normalizasyonu (Ä°ng. power normalization) adÄ±nÄ± verdikleri yeni bir yaklaÅŸÄ±m Ã¶nermektedirler. Bu yÃ¶ntem, birÃ§ok NLP gÃ¶revinde hem yÄ±ÄŸÄ±n hem de katman normalizasyonuna karÅŸÄ± daha Ã¼stÃ¼n performans gÃ¶stermektedir.

\\
Bu [blog gÃ¶nderisi](https://www.datasciencecentral.com/profiles/blogs/10-timeless-reference-books) makine Ã¶ÄŸrenmesine baÅŸlamak iÃ§in yararlanabileceÄŸiniz kitaplarÄ±n uzun bir listesini iÃ§ermektedir.

----------

EÄŸer NLP Haber BÃ¼lteni'nin sonraki sayÄ±larÄ±nda paylaÅŸmak istediÄŸiniz veri seti, proje, blog, rehber veya bildiri varsa ellfae@gmail.com adresine mail ya da [Twitter](https://twitter.com/omarsar0)'dan mesaj gÃ¶nderebilirsiniz.

\\
*ğŸ”–Gelen kutunuzda NLP Haber BÃ¼lteni'nin gelecek sayÄ±larÄ±nÄ± gÃ¶rmek istiyorsanÄ±z [buradan](https://dair.ai/newsletter/) abone olabilirsiniz.